{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNwHwJ7r8gxxCksaP+lgw1a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_6_25_model_development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69tNzRQpXWXG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#데이터셋 URL\n",
        "url =  'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "\n",
        "#칼럼명 정의 (데이터셋에 헤더가 없음)\n",
        "columns = [\n",
        " 'age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        " 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        " 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'\n",
        " ]\n",
        "\n",
        "# na_values 파라미터를 사용하여 '?'를 결측값으로 처리하며 데이터 로드\n",
        "df = pd.read_csv(url, header=None, names=columns, na_values='?', skipinitialspace=True)\n",
        "\n",
        "# 데이터의 첫 5행 확인\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"---데이터 정보---\")\n",
        "df.info()\n",
        "\n",
        "# 수치형 데이터의 기술 통계량 확인\n",
        "print(\"\\n--- 수치형 데이터 기술 통계량 ---\")\n",
        "print(df.describe())\n",
        "\n",
        "# 결측값 확인\n",
        "print(\"\\n---컬럼별 결측값 개수---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "8w9JolP5axo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# income 변수 분포 확인\n",
        "sns.countplot(x='income', data=df)\n",
        "plt.title('Income Distribution')\n",
        "plt.show()\n",
        "\n",
        "# 비율 확인\n",
        "income_counts = df['income'].value_counts(normalize=True)\n",
        "print(income_counts)"
      ],
      "metadata": {
        "id": "HfWZCwr3bVnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 수치형 특성 리스트\n",
        "numerical_features = ['age', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "\n",
        "# 각 수치형 특성에 대한 히스토그램과 박스 플롯 시각화\n",
        "for feature in numerical_features:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # 히스토그램\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(data=df, x=feature, kde=True)\n",
        "    plt.title(f'Histogram of {feature}')\n",
        "\n",
        "    # 박스 플롯\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(data=df, x='income', y=feature)\n",
        "    plt.title(f'Box Plot of {feature} by Income')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "pJp2wjTnbr2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 특성 리스트\n",
        "categorical_features = ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'sex']\n",
        "\n",
        "# 각 범주형 특성에 따른 소득 분포 시각화\n",
        "for feature in categorical_features:\n",
        " plt.figure(figsize=(12, 6))\n",
        " sns.countplot(data=df, y=feature, hue='income', order=df[feature].value_counts().index)\n",
        " plt.title(f'Income Distribution by {feature}')\n",
        " plt.tight_layout()\n",
        " plt.show()"
      ],
      "metadata": {
        "id": "-w-eMSE_cgXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값이 있는 범주형 컬럼에 대해 최빈값으로 대체\n",
        "for col in ['workclass', 'occupation', 'native-country']:\n",
        "    df[col].fillna(df[col].mode(), inplace=True)\n",
        "\n",
        "# 결측값 처리 확인\n",
        "print(\"\\n---컬럼별 결측값 개수 (결측값 처리 후)---\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "2dkU6oKxdE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 불필요하거나 중복되는 컬럼 제거\n",
        "df.drop(['education', 'fnlwgt'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Nzv5St2Kdc7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 목표 변수(Income)를 0과 1로 변환\n",
        "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1})\n",
        "\n",
        "# 범주형 특성을 원-핫 인코딩으로 변환\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "#변환된 데이터 확인\n",
        "print(df_encoded.head())"
      ],
      "metadata": {
        "id": "5yYH5sFMdp-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': X_train.columns,   # 82개의 컬럼\n",
        "    'importance': importances     # 각 피처의 중요도 값\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "top_n = 20\n",
        "selected_features = feature_importance_df['feature'].head(top_n).tolist()\n",
        "print(\"중요한 상위 20개 피처:\")\n",
        "print(selected_features)\n"
      ],
      "metadata": {
        "id": "jYvf5k2iSVVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 특성과 타겟 분리\n",
        "X = df_encoded.drop('income', axis=1)\n",
        "y = df_encoded['income']\n",
        "\n",
        "# 스케일러 객체 생성\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 데이터에 스케일러 적용\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 스케일링된 데이터를 다시 데이터프레임으로 변환 (칼럼명 유지를 위해)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "print(X_scaled.describe())"
      ],
      "metadata": {
        "id": "bin6jVeZeA1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습 데이터와 테스트 데이터로 분할 (7:3 비율, 클래스 비율 유지)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"학습 데이터 크기:\", X_train.shape)\n",
        "print(\"테스트 데이터 크기:\", X_test.shape)"
      ],
      "metadata": {
        "id": "QPWDutJ9fVdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#로지스틱 회귀 모델 객체 생성 및 학습\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# 생성된 데이터에 대한 예측\n",
        "y_pred_lr = log_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "BtQ52f6_jj56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 결정 트리 모델 객체 생성 및 학습\n",
        "# max_depth를 설정하여 과적합을 방지할 수 있음 (여기서는 기본값 사용)\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터에 대한 예측\n",
        "y_pred_dt = dt_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "eMPkSGahjxeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 랜덤 포레스트 모델 객체 생성 및 학습\n",
        "# n_estimators는 생성할 트리의 개수를 의미함\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터에 대한 예측\n",
        "y_pred_rf = rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "1PE6djzTkGSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#  각 모델에 대한 혼동 행렬 계산\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# 혼동 행렬 시각화 (예시: 랜덤 포레스트)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix for Random Forest')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "36t8ghYtkfSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))  # 1행 3열\n",
        "\n",
        "# Logistic Regression\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix for Logistic Regression')\n",
        "axes[0].set_xlabel('Predicted Labels')\n",
        "axes[0].set_ylabel('True Labels')\n",
        "\n",
        "# Decision Tree\n",
        "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix for Decision Trees')\n",
        "axes[1].set_xlabel('Predicted Labels')\n",
        "axes[1].set_ylabel('')\n",
        "\n",
        "# Random Forest\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[2])\n",
        "axes[2].set_title('Confusion Matrix for Random Forest')\n",
        "axes[2].set_xlabel('Predicted Labels')\n",
        "axes[2].set_ylabel('')  # y label 생략\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WlPrydQjrsu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#로지스틱 회귀 분류 리포트\n",
        "print(\"--- Logistic Regression Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# 결정 트리 분류 리포트\n",
        "print(\"\\n--- Decision Tree Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "# 랜덤 포레스트 분류 리포트\n",
        "print(\"\\n--- Random Forest Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "TL72HXlSnoBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 각 모델의 예측 확률 계산 (Positive 클래스에 대한 확률)\n",
        "prob_lr = log_reg.predict_proba(X_test)[:, 1]\n",
        "prob_dt = dt_clf.predict_proba(X_test)[:, 1]\n",
        "prob_rf = rf_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ROC 곡선 계산\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, prob_lr)\n",
        "fpr_dt, tpr_dt, _ = roc_curve(y_test, prob_dt)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, prob_rf)\n",
        "\n",
        "# AUC 계산\n",
        "auc_lr = auc(fpr_lr, tpr_lr)\n",
        "auc_dt = auc(fpr_dt, tpr_dt)\n",
        "auc_rf = auc(fpr_rf, tpr_rf)\n",
        "\n",
        "# ROC 곡선 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.2f})')\n",
        "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.2f})')\n",
        "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})')\n",
        "\n",
        "# Random Chance (대각선)\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BaIn7pxFoVKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# 결정 트리 시각화를 위한 DOT 데이터 생성 (트리 깊이를 3으로 제한하여 가독성 확보)\n",
        "# class_names에 특수 문자가 포함되어 있어 오류가 발생할 수 있으므로, 유효한 문자열로 대체.\n",
        "dot_data = export_graphviz(dt_clf,\n",
        "                           max_depth=3,\n",
        "                           out_file=None,\n",
        "                           feature_names=X_train.columns,\n",
        "                           class_names=['less_than_50K', 'greater_than_50K'], # 특수 문자 제거\n",
        "                           filled=True,\n",
        "                           rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Graphviz를 사용하여 시각화\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"adult_decision_tree\") # PDF 파일로 저장\n",
        "graph"
      ],
      "metadata": {
        "id": "sPPbrn7RpxOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트 모델로부터 특성 중요도 추출\n",
        "# 100개의 트리에서 평균적으로 어떤 변수가 중요한지 보고 싶음.\n",
        "\n",
        "importances = rf_clf.feature_importances_\n",
        "\n",
        "# 특성 중요도를 데이터프레임으로 변환\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': importances\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# 특성 중요도 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance_df.head(15)) # 상위 15개만 표시\n",
        "plt.title('Top 15 Feature Importances from Random Forest')\n",
        "plt.show()\n",
        "\n",
        "# 특성 중요도 표\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "id": "5KcY3vndqytI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 향후 연구 방향\n",
        "- 하이퍼파라미터 튜닝\n",
        "- 다른 알고리즘 탐색:XGBoost, LightGBM과 같은 그래디언트 부스팅(Gradient Boosting) 계열의 알고리즘이나 서포트 벡터 머신(Support Vector Machine, SVM) 등 다른 강력한 분류 알고리즘을 적용하여 성능을 비교\n",
        "- 피드백 로프 구축: 모델 해석 → 특성 공학 → 모델 재학습 → 재평가의 반복적인 과정\n"
      ],
      "metadata": {
        "id": "qeQem3e7w4eG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6qpVsPJyGDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "445f0dbe"
      },
      "source": [
        "# 랜덤 포레스트 특성 중요도 결과 사용 (feature_importance_df는 cell 5KcY3vndqytI에서 생성됨)\n",
        "# 상위 20개 특성 선택\n",
        "top_n = 20\n",
        "selected_features = feature_importance_df['feature'].head(top_n).tolist()\n",
        "\n",
        "print(f\"선택된 상위 {top_n}개 특성:\")\n",
        "print(selected_features)\n",
        "\n",
        "# 선택된 특성들로 학습 및 테스트 데이터셋 구성\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n",
        "\n",
        "print(\"\\n선택된 특성으로 구성된 학습 데이터 크기:\", X_train_selected.shape)\n",
        "print(\"선택된 특성으로 구성된 테스트 데이터 크기:\", X_test_selected.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc00f6de"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 로지스틱 회귀 모델 재학습\n",
        "log_reg_selected = LogisticRegression(random_state=42)\n",
        "log_reg_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "# 결정 트리 모델 재학습\n",
        "dt_clf_selected = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "# 랜덤 포레스트 모델 재학습\n",
        "rf_clf_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf_selected.fit(X_train_selected, y_train)\n",
        "\n",
        "print(\"모델 재학습 완료.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67858dd9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# 재학습된 모델로 예측 수행\n",
        "y_pred_lr_selected = log_reg_selected.predict(X_test_selected)\n",
        "y_pred_dt_selected = dt_clf_selected.predict(X_test_selected)\n",
        "y_pred_rf_selected = rf_clf_selected.predict(X_test_selected)\n",
        "\n",
        "# 각 모델에 대한 혼동 행렬 계산\n",
        "cm_lr_selected = confusion_matrix(y_test, y_pred_lr_selected)\n",
        "cm_dt_selected = confusion_matrix(y_test, y_pred_dt_selected)\n",
        "cm_rf_selected = confusion_matrix(y_test, y_pred_rf_selected)\n",
        "\n",
        "# 각 모델에 대한 분류 리포트 출력\n",
        "print(\"--- Logistic Regression (Selected Features) Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_lr_selected))\n",
        "\n",
        "print(\"\\n--- Decision Tree (Selected Features) Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_dt_selected))\n",
        "\n",
        "print(\"\\n--- Random Forest (Selected Features) Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_rf_selected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32edd5e0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming confusion matrices cm_lr_selected, cm_dt_selected, and cm_rf_selected have been calculated\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))  # 1행 3열\n",
        "\n",
        "# Logistic Regression (Selected Features)\n",
        "sns.heatmap(cm_lr_selected, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix for Logistic Regression (Selected Features)')\n",
        "axes[0].set_xlabel('Predicted Labels')\n",
        "axes[0].set_ylabel('True Labels')\n",
        "\n",
        "# Decision Tree (Selected Features)\n",
        "sns.heatmap(cm_dt_selected, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix for Decision Trees (Selected Features)')\n",
        "axes[1].set_xlabel('Predicted Labels')\n",
        "axes[1].set_ylabel('')  # y label 생략\n",
        "\n",
        "# Random Forest (Selected Features)\n",
        "sns.heatmap(cm_rf_selected, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[2])\n",
        "axes[2].set_title('Confusion Matrix for Random Forest (Selected Features)')\n",
        "axes[2].set_xlabel('Predicted Labels')\n",
        "axes[2].set_ylabel('')  # y label 생략\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3a304f6"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# 1. 모델 생성\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 2. 파라미터 공간 축소\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['sqrt', 'log2'],  # 'auto'는 deprecated\n",
        "    'max_depth': [10, 30, 50, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'bootstrap': [True]  # False 제외 (대부분 True 사용): True면 각 tree를 학습시킬 때 최대 max_samples로 전달한 숫자만큼의 데이터 셋을 구축한다. False면 모든 decision tree를 만들 때 전체 데이터를 사용\n",
        "}\n",
        "\n",
        "# 3. RandomizedSearchCV 설정\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # 20개의 조합만 샘플링\n",
        "    cv=3,       # 3-fold cross-validation\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1   # 병렬 처리\n",
        ")\n",
        "\n",
        "# 4. 모델 튜닝 수행\n",
        "random_search.fit(X_train_selected, y_train)\n",
        "\n",
        "# 5. 결과 출력\n",
        "print(\"최적 하이퍼파라미터:\", random_search.best_params_)\n",
        "print(\"최적 모델 성능 (교차 검증 평균 정확도):\", random_search.best_score_)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 학습된 데이터셋 기준\n",
        "# X_train_selected, y_train → 학습 데이터\n",
        "# X_test_selected, y_test → 테스트 데이터\n",
        "# 여기선 테스트 데이터로 평가\n",
        "\n",
        "# 모델들 생성\n",
        "logistic = LogisticRegression(max_iter=1000)\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "tuned_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    max_features='log2',\n",
        "    max_depth=50,\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 학습\n",
        "logistic.fit(X_train_selected, y_train)\n",
        "decision_tree.fit(X_train_selected, y_train)\n",
        "tuned_rf.fit(X_train_selected, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred_log = logistic.predict(X_test_selected)\n",
        "y_pred_tree = decision_tree.predict(X_test_selected)\n",
        "y_pred_rf = tuned_rf.predict(X_test_selected)\n",
        "\n",
        "# 혼동 행렬\n",
        "cm_log = confusion_matrix(y_test, y_pred_log)\n",
        "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(18, 5))\n",
        "\n",
        "models = ['Logistic Regression', 'Decision Trees', 'Random Forest (Tuned)']\n",
        "cms = [cm_log, cm_tree, cm_rf]\n",
        "\n",
        "for i, cm in enumerate(cms):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title(f'Confusion Matrix for {models[i]}')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HOKEo_UF9GQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 튜닝된 랜덤 포레스트 모델의 분류 리포트 출력\n",
        "print(\"--- Tuned Random Forest Classification Report ---\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "0qlvgv9A-QwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RandomForestClassifier를 활용해 랜덤 포레스트의 하이퍼파라미터를 튜닝.\n",
        "트리 개수(n_estimators), 최대 깊이(max_depth), 분할 조건(min_samples_split, min_samples_leaf) 등 총 6개의 파라미터로 탐색했고,\n",
        "각 조합에 대해 교차 검증을 수행하여 가장 성능이 좋은 설정을 선택함.\n",
        "그 결과 모델의 정확도를 약 82%에서 86%로 향상.\n",
        "특히 양성클래스에 대한 예측 성능(f1-score)도 함께 개선함\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],        # 트리 개수\n",
        "    'max_depth': [30, 50, None],           # 트리 최대 깊이\n",
        "    'min_samples_split': [2, 5],           # 분할 최소 샘플 수\n",
        "    'min_samples_leaf': [1, 2],            # 리프 노드 최소 샘플 수\n",
        "    'max_features': ['sqrt', 'log2'],      # 분할 시 사용할 특성 수\n",
        "    'bootstrap': [True]                    # 복원 추출 여부\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XhQEP3JT-2XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 모델 정의\n",
        "logistic = LogisticRegression(max_iter=1000)\n",
        "tree = DecisionTreeClassifier(random_state=42)\n",
        "tuned_rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    max_features='log2',\n",
        "    max_depth=50,\n",
        "    bootstrap=True,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 학습\n",
        "logistic.fit(X_train_selected, y_train)\n",
        "tree.fit(X_train_selected, y_train)\n",
        "tuned_rf.fit(X_train_selected, y_train)\n",
        "\n",
        "# 예측 확률\n",
        "y_score_log = logistic.predict_proba(X_test_selected)[:, 1]\n",
        "y_score_tree = tree.predict_proba(X_test_selected)[:, 1]\n",
        "y_score_rf = tuned_rf.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "# ROC Curve\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_score_log)\n",
        "fpr_tree, tpr_tree, _ = roc_curve(y_test, y_score_tree)\n",
        "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_score_rf)\n",
        "\n",
        "# AUC 계산\n",
        "auc_log = auc(fpr_log, tpr_log)\n",
        "auc_tree = auc(fpr_tree, tpr_tree)\n",
        "auc_rf = auc(fpr_rf, tpr_rf)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_log, tpr_log, label=f\"Tuned Logistic Regression (AUC = {auc_log:.2f})\")\n",
        "plt.plot(fpr_tree, tpr_tree, label=f\"Tuned Decision Tree (AUC = {auc_tree:.2f})\")\n",
        "plt.plot(fpr_rf, tpr_rf, label=f\"Tuned Random Forest (AUC = {auc_rf:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Tuned Model ROC Curve Comparison\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vwTq9qBdAJGl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}