{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyODPRuR4kb84xpkZt9JzI3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_08_Haar_Cascade%EC%96%BC%EA%B5%B4%EC%9D%B8%EC%8B%9D_%EC%97%B0%EA%B2%B0%EC%9A%94%EC%86%8C%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NS9UESh49kIb"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python numpy matplotlib ffmpeg-python --quiet\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ffmpeg\n",
        "import os\n",
        "from IPython.display import HTML, Video\n",
        "print(\"OpenCV version:\", cv.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml -O haarcascade_frontalface_default.xml\n",
        "if not os.path.exists('haarcascade_frontalface_default.xml'):\n",
        "    print(\"Cascade XML download failed!\")\n",
        "else:\n",
        "    print(\"Cascade XML downloaded successfully.\")"
      ],
      "metadata": {
        "id": "Wys4CKQP9sOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg -O lena.jpg\n",
        "if not os.path.exists('lena.jpg'):\n",
        "    print(\"lena.jpg download failed. Please upload an image.\")\n",
        "else:\n",
        "    print(\"lena.jpg downloaded.\")"
      ],
      "metadata": {
        "id": "OZnX0QAS9wUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "# 테스트 이미지 불러오기\n",
        "img_path = 'lena.jpg'  # 혹은 본인이 업로드한 이미지 경로\n",
        "img = cv.imread(img_path)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"Image not found: \"+img_path)\n",
        "# 그레이스케일 변환\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "# 얼굴 검출\n",
        "faces = face_cascade.detectMultiScale(\n",
        "    gray,\n",
        "    scaleFactor=1.1,  # 이미지 피라미드 스케일\n",
        "    minNeighbors=5,   # 얼굴로 판정하기 위한 최소 이웃\n",
        "    minSize=(30, 30)  # 얼굴로 볼 수 있는 최소 크기\n",
        ")\n",
        "print(f\"Detected faces: {len(faces)}\")\n",
        "# 얼굴 위치에 사각형 그리기\n",
        "for (x, y, w, h) in faces:\n",
        "    cv.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "# Matplotlib으로 시각화\n",
        "plt.figure(figsize=(6,6))\n",
        "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "plt.imshow(img_rgb)\n",
        "plt.title('Face Detection Result')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i5i91vHp9xyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 동영상/웹캠 기반 얼굴 인식\n"
      ],
      "metadata": {
        "id": "uF2c-PHP98RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 예시 영상 다운로드 (얼굴이 있는 영상 샘플)\n",
        "# OpenCV 4.x 버전 저장소에 face-detection-video.webm 샘플이 있으므로 이를 사용.\n",
        "!wget -q https://videos.pexels.com/video-files/5125919/5125919-sd_960_506_30fps.mp4 -O face_sample.mp4\n",
        "if not os.path.exists('face_sample.mp4'):\n",
        "    print(\"Sample video download failed!\")\n",
        "else:\n",
        "    print(\"Sample video downloaded.\")\n"
      ],
      "metadata": {
        "id": "3t5mVPGg904L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv.VideoCapture('face_sample.mp4')\n",
        "#cap = cv.VideoCapture('james.mp4')\n",
        "if not cap.isOpened():\n",
        "    print(\"Cannot open video!\")\n",
        "else:\n",
        "    # 동영상을 저장할 VideoWriter 설정\n",
        "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "    width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps    = cap.get(cv.CAP_PROP_FPS)\n",
        "    if fps <= 0:\n",
        "        fps = 25  # 혹시 0으로 읽히면 임의로 25로 설정\n",
        "    out = cv.VideoWriter('face_detect_out.avi', fourcc, fps, (width, height))\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(\n",
        "            gray,\n",
        "            scaleFactor=1.1,\n",
        "            minNeighbors=5,\n",
        "            minSize=(30, 30)\n",
        "        )\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        out.write(frame)  # 결과 프레임을 파일로 저장\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Video face detection done. Saved as face_detect_out.avi\")\n",
        "    # Colab에서 결과 영상을 확인하기 위해 mp4 변환\n",
        "    !ffmpeg -y -loglevel error -i face_detect_out.avi -vcodec libx264 face_detect_out.mp4\n",
        "    if os.path.exists('face_detect_out.mp4'):\n",
        "        display(Video('face_detect_out.mp4', embed=True))\n",
        "    else:\n",
        "        print(\"MP4 conversion failed.\")\n"
      ],
      "metadata": {
        "id": "VrzVf5u49_vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connected Component Analysis (연결 요소 분석)"
      ],
      "metadata": {
        "id": "7JK1SI7h-0Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# 빈 검정 이미지 생성\n",
        "img = np.zeros((400, 400), dtype=np.uint8)\n",
        "# 다양한 도형 추가\n",
        "cv2.rectangle(img, (50, 50), (150, 150), 255, -1)  # 사각형\n",
        "True\n",
        "cv2.circle(img, (300, 100), 50, 255, -1)           # 원\n",
        "cv2.ellipse(img, (100, 300), (50, 25), 0, 0, 360, 255, -1) # 타원\n",
        "cv2.rectangle(img, (250, 250), (350, 350), 255, -1) # 추가 사각형\n",
        "# 결과 이미지 표시\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.title('Shapes for Connected Component Analysis')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "# 이미지 저장하기\n",
        "cv2.imwrite('shapes.png', img)\n"
      ],
      "metadata": {
        "id": "z02cUbCh-Cxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# 간단히 shapes.png 같은 이미지 다운로드 (혹은 직접 업로드)\n",
        "#!wget -q https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEinbMTeQJBoDNjR0N2weYbq9_2KmB8f922nqDeCskUls7Dm\n",
        "img_path = '귀여움.jpg'\n",
        "if not os.path.exists(img_path):\n",
        "    print(f\"{img_path} not found. Please upload or replace path.\")\n",
        "else:\n",
        "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
        "    if img is None:\n",
        "        print(f\"Could not read {img_path}. Please check the file.\")\n",
        "    else:\n",
        "        # 그레이스케일\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        # 간단히 이진화 (Threshold)\n",
        "        # 오츠 자동 임계값 등 사용 가능\n",
        "        ret, bin_img = cv.threshold(gray, 127, 255, cv.THRESH_BINARY_INV)\n",
        "        # 연결 요소 분석\n",
        "        num_labels, labels, stats, centroids = cv.connectedComponentsWithStats(bin_img, connectivity=4)\n",
        "        print(f\"Detected labels (including background): {num_labels}\")\n",
        "        # stats.shape = (num_labels, 5)  -> [ [x, y, w, h, area], ... ]\n",
        "        # centroids.shape = (num_labels, 2)\n",
        "        # 시각화 위해 레이블 별로 임의 색상 입힐 수 있음\n",
        "        # label 0은 배경\n",
        "        label_colors = np.zeros((num_labels, 3), dtype=np.uint8)\n",
        "        for i in range(1, num_labels):\n",
        "            # 배경 제외, 임의 색\n",
        "            label_colors[i] = np.random.randint(0, 255, size=3)\n",
        "        # label map -> color\n",
        "        out_img = np.zeros((bin_img.shape[0], bin_img.shape[1], 3), dtype=np.uint8)\n",
        "        for r in range(bin_img.shape[0]):\n",
        "            for c in range(bin_img.shape[1]):\n",
        "                lb = labels[r, c]\n",
        "                out_img[r, c] = label_colors[lb]\n",
        "        # (옵션) 필터링 예시: area가 너무 작은 blob은 제거\n",
        "        min_area = 60\n",
        "        # 결과 이미지를 복사\n",
        "        filtered_img = out_img.copy()\n",
        "        for i in range(1, num_labels):\n",
        "            area_i = stats[i, cv.CC_STAT_AREA]\n",
        "            if area_i < min_area:\n",
        "                # 해당 레이블을 배경색(0,0,0)으로 만듦\n",
        "                # 혹은 실제 bin_img등을 바꿀 수도 있음\n",
        "                filtered_img[labels==i] = (0,0,0)\n",
        "        # 시각화\n",
        "        plt.figure(figsize=(12,6))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title('Original')\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title('Connected Components')\n",
        "        plt.imshow(out_img[..., ::-1])  # BGR -> RGB\n",
        "        plt.axis('off')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.title('Filtered (area>=50)')\n",
        "        plt.imshow(filtered_img[..., ::-1])\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print(\"\\nStats Info:\")\n",
        "        for i in range(num_labels):\n",
        "            x, y, w, h, area = stats[i]\n",
        "            cx, cy = centroids[i]\n",
        "            print(f\"Label={i}, BBox=({x},{y},{w},{h}), Area={area}, Centroid=({cx:.1f},{cy:.1f})\")"
      ],
      "metadata": {
        "id": "7tM2mPyvFsTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# 이전 단계에서 만든 이미지 로드\n",
        "img = cv2.imread('귀여움.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if img is None:\n",
        "    print(\"Could not read 귀여움.jpg. Please check the file and ensure it's uploaded.\")\n",
        "else:\n",
        "    # 연결 요소 분석 수행\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img)\n",
        "    print(\"연결된 구성 요소(Connected Components)의 개수:\", num_labels - 1)  # 배경 제외\n",
        "    # 각 구성 요소의 정보 출력\n",
        "    for i in range(1, num_labels):  # 배경(0번)을 제외하고 시작\n",
        "        print(f\"Component {i}:\")\n",
        "        print(f\" - 면적(Area): {stats[i, cv2.CC_STAT_AREA]}\")\n",
        "        print(f\" - Bounding Box: (x: {stats[i, cv2.CC_STAT_LEFT]}, \"\n",
        "              f\"y: {stats[i, cv2.CC_STAT_TOP]}, \"\n",
        "              f\"w: {stats[i, cv2.CC_STAT_WIDTH]}, \"\n",
        "              f\"h: {stats[i, cv2.CC_STAT_HEIGHT]})\")\n",
        "        print(f\" - 중심점(Centroid): {centroids[i]}\")\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(labels, cmap='nipy_spectral')\n",
        "    plt.title('Connected Components')\n",
        "    plt.axis('off')\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "d8gcfUbhFxD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 다른 바이너리 이미지(예: 영상에 임계값을 적용한 결과)로 연결 요소 분석을 시도해보세요.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 # cv2를 다시 임포트합니다.\n",
        "\n",
        "# '귀여움.jpg' 이미지 로드\n",
        "img_path = '귀여움.jpg'\n",
        "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "if img is None:\n",
        "    print(f\"Could not read {img_path}. Please check the file and ensure it's uploaded.\")\n",
        "else:\n",
        "    # 그레이스케일 변환\n",
        "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # 이진화 (Threshold) - 필요에 따라 임계값 또는 임계값 방법을 변경할 수 있습니다.\n",
        "    # 여기서는 간단한 고정 임계값(127)을 사용하고, 검은색 객체를 흰색 배경에서 분리하기 위해 THRESH_BINARY_INV를 사용합니다.\n",
        "    ret, binary_img = cv2.threshold(gray_img, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "    # 이진 이미지 시각화\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(binary_img, cmap='gray')\n",
        "    plt.title(f'Binary Image from {img_path}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    # 연결 요소 분석\n",
        "    num_labels_new, labels_new, stats_new, centroids_new = cv2.connectedComponentsWithStats(binary_img, connectivity=8) # connectivity=8 사용\n",
        "\n",
        "    print(f\"\\n'{img_path}' 이미지에서 검출된 레이블 (배경 포함): {num_labels_new}\")\n",
        "\n",
        "    # 배경을 제외한 연결 요소 개수\n",
        "    print(f\"배경 제외 연결된 구성 요소(Connected Components)의 개수: {num_labels_new - 1}\")\n",
        "\n",
        "    # 각 구성 요소 정보 출력 및 시각화 준비\n",
        "    # 원본 컬러 이미지를 복사하여 텍스트와 BBox를 그립니다.\n",
        "    output_img_new_colored = img.copy()\n",
        "\n",
        "    # 배경 제외하고 임의 색상 생성 (컴포넌트 영역 색칠용)\n",
        "    label_colors_new = np.random.randint(0, 255, size=(num_labels_new, 3), dtype=np.uint8)\n",
        "    label_colors_new[0] = [0, 0, 0] # 배경은 검은색\n",
        "\n",
        "    # 연결 요소 영역을 색상으로 표시할 이미지 (옵션)\n",
        "    colored_components_img = np.zeros_like(output_img_new_colored)\n",
        "\n",
        "\n",
        "    print(\"\\nStats Info (using '귀여움.jpg'):\")\n",
        "    for i in range(1, num_labels_new): # 배경 (label 0) 제외\n",
        "        x, y, w, h, area = stats_new[i]\n",
        "        cx, cy = centroids_new[i]\n",
        "\n",
        "        print(f\"Label={i}, BBox=({x},{y},{w},{h}), Area={area}, Centroid=({cx:.1f},{cy:.1f})\")\n",
        "\n",
        "        # 결과 이미지에 Bounding box 그리기\n",
        "        cv2.rectangle(output_img_new_colored, (x, y), (x + w, y + h), (0, 255, 0), 2) # 초록색 BBox\n",
        "\n",
        "        # 결과 이미지에 중심점 그리기\n",
        "        cv2.circle(output_img_new_colored, (int(cx), int(cy)), 5, (255, 0, 0), -1) # 파란색 중심점\n",
        "\n",
        "        # (옵션) 연결 요소 영역을 색상으로 채우기\n",
        "        colored_components_img[labels_new == i] = label_colors_new[i]\n",
        "\n",
        "\n",
        "    # 결과 시각화 (원본 + BBox/Centroid)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(f'Original Image with Components ({img_path})')\n",
        "    plt.imshow(output_img_new_colored[..., ::-1]) # BGR to RGB\n",
        "    plt.axis('off')\n",
        "\n",
        "    # (옵션) 연결 요소 색칠 이미지 시각화\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Connected Components (Colored)')\n",
        "    plt.imshow(colored_components_img[..., ::-1]) # BGR to RGB\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 레이블 맵만 별도로 시각화 (색상맵 사용)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(labels_new, cmap='nipy_spectral') # 레이블 값 자체를 색상맵으로 표현\n",
        "    plt.title(f'Connected Components Label Map ({img_path})')\n",
        "    plt.axis('off')\n",
        "    plt.colorbar(label='Component Label')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # (옵션) 필터링 예시: 특정 면적 이상인 컴포넌트만 표시\n",
        "    min_area_filter = 100 # 예시 필터링 기준\n",
        "    filtered_output_img = np.zeros_like(output_img_new_colored) # 원본 컬러 이미지 크기로 초기화\n",
        "    filtered_labels_count = 0\n",
        "\n",
        "    print(f\"\\nFiltering with conditions: Area >= {min_area_filter}\")\n",
        "\n",
        "    for i in range(1, num_labels_new):\n",
        "        x, y, w, h, area = stats_new[i]\n",
        "        cx, cy = centroids_new[i]\n",
        "\n",
        "        if area >= min_area_filter:\n",
        "            # 필터링된 컴포넌트의 Bounding Box와 중심점을 결과 이미지에 그립니다.\n",
        "            cv2.rectangle(filtered_output_img, (x, y), (x + w, y + h), (0, 255, 0), 2) # 초록색 BBox\n",
        "            cv2.circle(filtered_output_img, (int(cx), int(cy)), 5, (255, 0, 0), -1) # 파란색 중심점\n",
        "\n",
        "            filtered_labels_count += 1\n",
        "            # 필터링된 컴포넌트 정보 다시 출력\n",
        "            print(f\"Filtered Component {i}: BBox=({x},{y},{w},{h}), Area={area}, Centroid=({cx:.1f},{cy:.1f})\")\n",
        "\n",
        "\n",
        "    if filtered_labels_count > 0:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.title(f'Filtered Components (Area >= {min_area_filter}) on {img_path}')\n",
        "        plt.imshow(filtered_output_img[..., ::-1]) # BGR to RGB\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(f\"필터링 후 남은 연결된 구성 요소 개수: {filtered_labels_count}\")\n",
        "    else:\n",
        "        print(f\"면적이 {min_area_filter} 이상인 연결된 구성 요소가 없습니다.\")"
      ],
      "metadata": {
        "id": "26FlfRLcF147"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 연결성: connectivity=8 로 바꾸고 결과가 달라지는지 확인해보세요.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# 이전 단계에서 만든 이미지 로드\n",
        "img = cv2.imread('귀여움.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if img is None:\n",
        "    print(\"Could not read 귀여움.jpg. Please check the file and ensure it's uploaded.\")\n",
        "else:\n",
        "    # 연결 요소 분석 수행 (connectivity=8 사용)\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=8)\n",
        "\n",
        "    print(\"연결된 구성 요소(Connected Components)의 개수 (connectivity=8):\", num_labels - 1)  # 배경 제외\n",
        "\n",
        "    # 각 구성 요소의 정보 출력\n",
        "    print(\"\\nStats Info (connectivity=8):\")\n",
        "    for i in range(1, num_labels):  # 배경(0번)을 제외하고 시작\n",
        "        print(f\"Component {i}:\")\n",
        "        print(f\" - 면적(Area): {stats[i, cv2.CC_STAT_AREA]}\")\n",
        "        print(f\" - Bounding Box: (x: {stats[i, cv2.CC_STAT_LEFT]}, \"\n",
        "              f\"y: {stats[i, cv2.CC_STAT_TOP]}, \"\n",
        "              f\"w: {stats[i, cv2.CC_STAT_WIDTH]}, \"\n",
        "              f\"h: {stats[i, cv2.CC_STAT_HEIGHT]})\")\n",
        "        print(f\" - 중심점(Centroid): {centroids[i]}\")\n",
        "\n",
        "    # 시각화\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(labels, cmap='nipy_spectral')\n",
        "    plt.title('Connected Components (connectivity=8)')\n",
        "    plt.axis('off')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "    # 이전 코드와의 결과 비교\n",
        "    # connectivity=4일 때와 connectivity=8일 때의 연결 요소 개수 및 stats 값을 비교하여 결과가 달라지는지 확인합니다.\n",
        "    # 일반적으로 8-connectivity는 대각선으로 인접한 픽셀도 같은 연결 요소로 간주하므로, 4-connectivity보다 연결 요소의 개수가 적거나 같게 나옵니다.\n",
        "    # 현재 'shapes.png' 이미지의 경우, 사각형, 원, 타원 등은 4-connectivity와 8-connectivity 모두 동일하게 분리된 객체로 인식될 가능성이 높습니다.\n",
        "    # 하지만 만약 대각선으로만 연결된 픽셀들이 있다면, connectivity=8일 때 하나의 연결 요소로 합쳐지게 되어 connectivity=4일 때와 결과가 달라질 수 있습니다.\n",
        "\n",
        "    print(\"\\nNote: Compare the number of components and stats with the connectivity=4 result above to see the difference.\")\n",
        "    print(\"For the '귀여움.jpg' image, the difference will depend on the nature of the shapes and connections within the image.\")\n",
        "    print(\"Differences are more apparent in images with diagonally connected pixels or noisy boundaries.\")"
      ],
      "metadata": {
        "id": "U5k8YC81GAjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 필터링: stats 의 다양한 정보(예: 너비, 높이, aspect ratio 등)를 사용해 조건부 필터링을 적용해보세요.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# 다양한 stats 정보를 사용하여 조건부 필터링 적용 예시\n",
        "# stats 배열은 각 컴포넌트의 [x, y, width, height, area] 정보를 담고 있습니다.\n",
        "\n",
        "print(\"\\nApplying various filtering conditions based on stats:\")\n",
        "\n",
        "# 이전 단계에서 사용한 이미지와 분석 결과를 로드합니다.\n",
        "# 여기서는 귀여움.jpg 이미지와 그 분석 결과 (num_labels, labels, stats, centroids)를 사용합니다.\n",
        "img = cv2.imread('귀여움.jpg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "if img is None:\n",
        "    print(\"Could not read 귀여움.jpg. Please check the file and ensure it's uploaded.\")\n",
        "else:\n",
        "    # 연결 요소 분석 수행 (이전 단계에서 수행한 결과가 없으면 다시 수행)\n",
        "    num_labels_new, labels_new, stats_new, centroids_new = cv2.connectedComponentsWithStats(img, connectivity=8) # connectivity=8 사용\n",
        "\n",
        "    # 필터링 조건을 정의합니다.\n",
        "    min_area_filter = 500  # 최소 면적\n",
        "    min_width_filter = 50  # 최소 너비\n",
        "    max_height_filter = 150 # 최대 높이\n",
        "    min_aspect_ratio = 0.8 # 최소 가로/세로 비율 (정사각형에 가까운 형태)\n",
        "    max_aspect_ratio = 1.2 # 최대 가로/세로 비율\n",
        "\n",
        "    # 텍스트를 그릴 이미지 준비 (필터링 결과를 보여줄 이미지)\n",
        "    # 원본 바이너리 이미지를 3채널 컬러로 변환하여 사용합니다.\n",
        "    filtered_output_img_complex = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    filtered_labels_count_complex = 0\n",
        "\n",
        "    print(f\"\\nFiltering with conditions: Area >= {min_area_filter}, Width >= {min_width_filter}, Height <= {max_height_filter}, Aspect Ratio between {min_aspect_ratio:.1f} and {max_aspect_ratio:.1f}\")\n",
        "\n",
        "    for i in range(1, num_labels_new): # 배경 (label 0) 제외\n",
        "        x, y, w, h, area = stats_new[i]\n",
        "        cx, cy = centroids_new[i]\n",
        "\n",
        "        # Aspect Ratio 계산 (Divide by zero 방지)\n",
        "        aspect_ratio = w / h if h != 0 else 0\n",
        "\n",
        "        # 필터링 조건 확인\n",
        "        is_large_enough_area = area >= min_area_filter\n",
        "        is_wide_enough = w >= min_width_filter\n",
        "        is_short_enough = h <= max_height_filter\n",
        "        is_aspect_ratio_ok = (aspect_ratio >= min_aspect_ratio) and (aspect_ratio <= max_aspect_ratio) if h != 0 else False # 높이가 0인 경우 비율 체크 제외\n",
        "\n",
        "        # 모든 조건을 만족하는 경우 필터링된 이미지에 추가\n",
        "        if is_large_enough_area and is_wide_enough and is_short_enough and is_aspect_ratio_ok:\n",
        "            # 해당 컴포넌트를 원본 이미지에 빨간색으로 표시 (예시)\n",
        "            filtered_output_img_complex[labels_new == i] = (0, 0, 255) # BGR: Red\n",
        "            filtered_labels_count_complex += 1\n",
        "            # 필터링된 컴포넌트 정보 다시 출력\n",
        "            print(f\"Filtered Component {i} (Complex Filter): BBox=({x},{y},{w},{h}), Area={area}, Aspect Ratio={aspect_ratio:.2f}, Centroid=({cx:.1f},{cy:.1f})\")\n",
        "\n",
        "    if filtered_labels_count_complex > 0:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.title('Filtered Components (Complex Conditions)')\n",
        "        plt.imshow(filtered_output_img_complex[..., ::-1]) # BGR to RGB\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(f\"복합 필터링 후 남은 연결된 구성 요소 개수: {filtered_labels_count_complex}\")\n",
        "    else:\n",
        "        print(\"복합 필터링 조건을 만족하는 연결된 구성 요소가 없습니다.\")\n",
        "\n",
        "    # 다른 필터링 예시: 특정 y좌표 범위에 있는 컴포넌트만 필터링\n",
        "    min_y_filter = 200\n",
        "    max_y_filter = 400 # 이미지 하단에 있는 컴포넌트\n",
        "\n",
        "    filtered_output_img_y = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) # 새로운 필터링 결과 이미지 초기화\n",
        "    filtered_labels_count_y = 0\n",
        "\n",
        "    print(f\"\\nFiltering with conditions: Y coordinate (Top) between {min_y_filter} and {max_y_filter}\")\n",
        "\n",
        "    for i in range(1, num_labels_new):\n",
        "        x, y, w, h, area = stats_new[i]\n",
        "        cx, cy = centroids_new[i]\n",
        "\n",
        "        # Y 좌표 조건 확인 (컴포넌트의 상단 y좌표 사용)\n",
        "        is_in_y_range = (y >= min_y_filter) and (y <= max_y_filter)\n",
        "\n",
        "        if is_in_y_range:\n",
        "             filtered_output_img_y[labels_new == i] = (0, 255, 0) # BGR: Green\n",
        "             filtered_labels_count_y += 1\n",
        "             print(f\"Filtered Component {i} (Y-Range Filter): BBox=({x},{y},{w},{h}), Area={area}, Centroid=({cx:.1f},{cy:.1f})\")\n",
        "\n",
        "    if filtered_labels_count_y > 0:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.title(f'Filtered Components (Y between {min_y_filter} and {max_y_filter})')\n",
        "        plt.imshow(filtered_output_img_y[..., ::-1]) # BGR to RGB\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "        print(f\"Y좌표 범위 필터링 후 남은 연결된 구성 요소 개수: {filtered_labels_count_y}\")\n",
        "    else:\n",
        "        print(f\"Y좌표 범위 ({min_y_filter}~{max_y_filter}) 내에 있는 연결된 구성 요소가 없습니다.\")"
      ],
      "metadata": {
        "id": "1RaPRxRfGG_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 4. 중심 좌표를 이용해, 각 레이블 위치에 텍스트 표시를 해보는 것도 좋습니다 ( cv.putText ).\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 # cv2를 다시 임포트합니다.\n",
        "# 중심 좌표를 이용해, 각 레이블 위치에 텍스트 표시를 해보는 것도 좋습니다 ( cv.putText ).\n",
        "\n",
        "# 이전 단계에서 사용한 이미지와 분석 결과를 사용합니다.\n",
        "# 여기서는 귀여움.jpg 이미지와 그 분석 결과 (num_labels, labels, stats, centroids)를 사용합니다.\n",
        "img_path = '귀여움.jpg'\n",
        "img = cv2.imread(img_path, cv2.IMREAD_COLOR) # 컬러 이미지로 로드\n",
        "\n",
        "if img is None:\n",
        "    print(f\"Could not read {img_path}. Please check the file and ensure it's uploaded.\")\n",
        "else:\n",
        "    # 연결 요소 분석을 위해 그레이스케일 및 이진화가 필요할 수 있습니다.\n",
        "    # 이 예제에서는 원본 컬러 이미지에 결과를 그릴 것이므로, 연결 요소 분석은 그레이스케일/이진화된 이미지에서 수행합니다.\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, bin_img = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV) # 이진화 (필요에 따라 임계값 조절)\n",
        "\n",
        "\n",
        "    # 연결 요소 분석 수행 (이전 단계에서 수행한 결과가 없으면 다시 수행)\n",
        "    num_labels_new, labels_new, stats_new, centroids_new = cv2.connectedComponentsWithStats(bin_img, connectivity=8) # 이진 이미지에 대해 분석 수행\n",
        "\n",
        "\n",
        "    # 텍스트를 그릴 이미지 준비 (원본 컬러 이미지에 그립니다.)\n",
        "    img_with_text = img.copy()\n",
        "\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 0.5\n",
        "    font_color = (0, 0, 255)  # 파란색 (BGR 순서)\n",
        "    thickness = 1\n",
        "\n",
        "    print(\"\\nDisplaying centroid coordinates and label numbers on components:\")\n",
        "\n",
        "    # 배경 (label 0)을 제외하고 각 연결 요소에 텍스트를 표시합니다.\n",
        "    for i in range(1, num_labels_new):\n",
        "        x, y, w, h, area = stats_new[i]\n",
        "        cx, cy = centroids_new[i]\n",
        "\n",
        "\n",
        "        # 중심 좌표 근처에 텍스트를 그립니다.\n",
        "        # putText 위치는 텍스트의 좌측 하단 기준입니다.\n",
        "        # 중심점 (cx, cy)에 정확히 찍기보다는, 약간 조정하여 텍스트가 컴포넌트 내부에 위치하도록 할 수 있습니다.\n",
        "        # 여기서는 간단히 Bounding Box의 좌측 상단 근처에 레이블 ID를 표시합니다.\n",
        "        text_str = f\"{i}\" #f\"({cx:.0f},{cy:.0f})\" # 레이블 번호나 좌표 등을 표시할 수 있습니다.\n",
        "        # 텍스트 위치를 BBox의 좌측 상단 근처로 조정\n",
        "        text_position = (x, y - 5) # BBox 상단에서 약간 위로 이동\n",
        "\n",
        "\n",
        "        # 텍스트가 너무 작거나 컴포넌트가 너무 작으면 그리지 않을 수도 있습니다.\n",
        "        if w > 5 and h > 5: # 간단한 크기 필터링 (너무 작은 노이즈 제외)\n",
        "           # 텍스트가 이미지 경계를 벗어나지 않도록 위치 조정\n",
        "           text_position = (max(0, text_position[0]), max(10, text_position[1])) # x, y 최소값 제한\n",
        "\n",
        "           # 이미지에 텍스트 그리기\n",
        "           cv2.putText(img_with_text, text_str, text_position, font, font_scale, font_color, thickness, cv2.LINE_AA)\n",
        "\n",
        "           # (옵션) Bounding Box 그리기\n",
        "           cv2.rectangle(img_with_text, (x, y), (x+w, y+h), (255, 0, 0), 1) # 빨간색 BBox\n",
        "\n",
        "           # (옵션) 중심점 표시\n",
        "           #cv2.circle(img_with_text, (int(cx), int(cy)), 3, (0, 255, 0), -1) # 초록색 중심점\n",
        "\n",
        "    # 결과 이미지 시각화\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img_with_text[..., ::-1])  # BGR to RGB\n",
        "    plt.title(f'Components with Labels on {img_path}')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Cj6ZRLSoGbB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7803adf1"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "img_path = '귀여움.jpg'\n",
        "\n",
        "if not os.path.exists(img_path):\n",
        "    print(f\"{img_path} not found. Please upload the image.\")\n",
        "else:\n",
        "    img = cv.imread(img_path, cv.IMREAD_COLOR)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Could not read {img_path}. Please check the file.\")\n",
        "    else:\n",
        "        # 그레이스케일 변환\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # 이진화 (Threshold) - 필요에 따라 임계값 또는 임계값 방법을 변경할 수 있습니다.\n",
        "        # THRESH_BINARY_INV는 검은색 배경에 흰색 객체를 만들 때 유용합니다.\n",
        "        # 귀여움.jpg 이미지 특성에 맞게 임계값(예: 127)을 조절하거나 다른 방법(THRESH_BINARY, THRESH_OTSU 등)을 시도해 볼 수 있습니다.\n",
        "        ret, bin_img = cv.threshold(gray, 127, 255, cv.THRESH_BINARY_INV)\n",
        "\n",
        "        # 연결 요소 분석\n",
        "        # connectivity=8 사용 (대각선 포함)\n",
        "        num_labels, labels, stats, centroids = cv.connectedComponentsWithStats(bin_img, connectivity=8)\n",
        "\n",
        "        print(f\"Detected labels (including background): {num_labels}\")\n",
        "\n",
        "        # 시각화 위해 레이블 별로 임의 색상 입힐 수 있음\n",
        "        # label 0은 배경\n",
        "        label_colors = np.zeros((num_labels, 3), dtype=np.uint8)\n",
        "        # 배경 제외, 임의 색상 생성\n",
        "        for i in range(1, num_labels):\n",
        "            label_colors[i] = np.random.randint(0, 255, size=3)\n",
        "\n",
        "        # label map -> color image\n",
        "        out_img_colored = np.zeros((bin_img.shape[0], bin_img.shape[1], 3), dtype=np.uint8)\n",
        "        for r in range(bin_img.shape[0]):\n",
        "            for c in range(bin_img.shape[1]):\n",
        "                lb = labels[r, c]\n",
        "                out_img_colored[r, c] = label_colors[lb]\n",
        "\n",
        "        # 원본 이미지 위에 경계 상자 그리기 (옵션)\n",
        "        img_with_bbox = img.copy()\n",
        "        # 중심점 표시 (옵션)\n",
        "        # img_with_centroids = img.copy()\n",
        "\n",
        "        print(\"\\nStats Info:\")\n",
        "        for i in range(1, num_labels): # 배경 (label 0) 제외\n",
        "            x, y, w, h, area = stats[i]\n",
        "            cx, cy = centroids[i]\n",
        "\n",
        "            print(f\"Label={i}, BBox=({x},{y},{w},{h}), Area={area}, Centroid=({cx:.1f},{cy:.1f})\")\n",
        "\n",
        "            # 원본 이미지 위에 경계 상자 그리기\n",
        "            cv.rectangle(img_with_bbox, (x, y), (x+w, y+h), (0, 255, 0), 2) # 초록색 경계 상자\n",
        "\n",
        "            # 중심점 표시 (옵션)\n",
        "            # cv.circle(img_with_centroids, (int(cx), int(cy)), 5, (255, 0, 0), -1) # 파란색 중심점\n",
        "\n",
        "            # (옵션) 컴포넌트 레이블 텍스트 추가\n",
        "            # text_str = f\"{i}\"\n",
        "            # text_position = (x, y - 5)\n",
        "            # cv.putText(img_with_bbox, text_str, text_position, cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv.LINE_AA)\n",
        "\n",
        "\n",
        "        # 시각화\n",
        "        plt.figure(figsize=(18, 6)) # 전체 Figure 크기 조정\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Original Image')\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Connected Components (Colored)')\n",
        "        # OpenCV는 BGR 순서, Matplotlib은 RGB 순서이므로 색상 채널 순서 변경\n",
        "        plt.imshow(out_img_colored[..., ::-1])\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title('Original with Bounding Boxes')\n",
        "        # OpenCV는 BGR 순서, Matplotlib은 RGB 순서이므로 색상 채널 순서 변경\n",
        "        plt.imshow(img_with_bbox[..., ::-1])\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # (옵션) 이진 이미지 시각화 (디버깅용)\n",
        "        # plt.figure(figsize=(6,6))\n",
        "        # plt.imshow(bin_img, cmap='gray')\n",
        "        # plt.title('Binary Image')\n",
        "        # plt.axis('off')\n",
        "        # plt.show()\n",
        "\n",
        "        # (옵션) 레이블 맵만 시각화 (컴포넌트 구별 확인용)\n",
        "        # plt.figure(figsize=(6,6))\n",
        "        # plt.imshow(labels, cmap='nipy_spectral')\n",
        "        # plt.title('Label Map')\n",
        "        # plt.axis('off')\n",
        "        # plt.colorbar()\n",
        "        # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
