{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMJ0m/jMHQAZuzlAD1w15Kc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_09_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background Subtraction"
      ],
      "metadata": {
        "id": "Yhktnp-zod7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-contrib-python numpy matplotlib ffmpeg-python --quiet\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ffmpeg\n",
        "import os\n",
        "from IPython.display import HTML, Video\n",
        "print(\"OpenCV version:\", cv.__version__)\n"
      ],
      "metadata": {
        "id": "XHckYMnuojNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOG(Mixture of Gaussians)"
      ],
      "metadata": {
        "id": "d7cdoeQgo_77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O sample\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/4.x/samples/data/vtest.avi -O sample_video.avi\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "fgbg_mog2 = cv.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
        "fgbg_knn = cv.createBackgroundSubtractorKNN(history=500, dist2Threshold=400.0, detectShadows=True)\n",
        "cap = cv.VideoCapture('sample_video.avi')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    # 동영상을 저장할 VideoWriter\n",
        "    width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps    = cap.get(cv.CAP_PROP_FPS)\n",
        "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv.VideoWriter('bgsub_output.avi', fourcc, fps if fps>0 else 30, (width*3, height))\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        fgmask_mog2_ = fgbg_mog2.apply(frame)\n",
        "        fgmask_knn_  = fgbg_knn.apply(frame)\n",
        "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3,3))\n",
        "        fgmask_mog2_ = cv.morphologyEx(fgmask_mog2_, cv.MORPH_OPEN, kernel)\n",
        "        fgmask_knn_  = cv.morphologyEx(fgmask_knn_,  cv.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Apply the MOG2 mask to the original frame to show only the foreground\n",
        "        foreground_mog2 = cv.bitwise_and(frame, frame, mask=fgmask_mog2_)\n",
        "\n",
        "        # 시각화를 위해 세 프레임을 가로로 붙여서 저장\n",
        "        # 원본 / MOG2 배경 제거된 영상 / KNN 마스크\n",
        "        mask_knn_color  = cv.cvtColor(fgmask_knn_,  cv.COLOR_GRAY2BGR)\n",
        "        concat_frame = cv.hconcat([frame, foreground_mog2, mask_knn_color])\n",
        "        out.write(concat_frame)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Done. Saved as bgsub_output.avi\")\n",
        "    # Colab에서 보기 위해 mp4 변환\n",
        "    !ffmpeg -y -i bgsub_output.avi -vcodec libx264 bgsub_output.mp4\n",
        "    if os.path.exists('bgsub_output.mp4'):\n",
        "        from IPython.display import Video\n",
        "        display(Video('bgsub_output.mp4', embed=True))\n",
        "    else:\n",
        "        print(\"mp4 파일 생성 실패!\")"
      ],
      "metadata": {
        "id": "2HldrfqKotVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving Object Trackiing (객체 추적)"
      ],
      "metadata": {
        "id": "-TVeIhqQpNlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the first frame!\")\n",
        "        cap.release()\n",
        "    else:\n",
        "        h, w, _ = frame.shape\n",
        "        x, y, w_box, h_box = int(w/2 - 50), int(h/2 - 30), 100, 60\n",
        "        track_window = (x, y, w_box, h_box)\n",
        "        # 초기 ROI 히스토그램 계산\n",
        "        roi = frame[y:y+h_box, x:x+w_box]\n",
        "        hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "        mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255))\n",
        "        roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180, 256], [0,180, 0,256])\n",
        "        cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "        term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "        # 결과 저장용\n",
        "        fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv.VideoWriter('mean_cam_output.avi', fourcc, 30, (w, h))\n",
        "        while True:\n",
        "            ret, frame2 = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "            hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "            back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "            # 1) Meanshift\n",
        "            ret_ms, ms_box = cv.meanShift(back_proj, track_window, term_crit)\n",
        "            x_ms, y_ms, w_ms, h_ms = ms_box\n",
        "            cv.rectangle(frame2, (x_ms, y_ms), (x_ms+w_ms, y_ms+h_ms), (255,0,0), 2)\n",
        "            # 2) Camshift\n",
        "            ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "            pts = cv.boxPoints(ret_cs)\n",
        "            #pts = np.int0(pts)\n",
        "            pts = pts.astype(int)\n",
        "            cv.polylines(frame2, [pts], True, (0,255,0), 2)\n",
        "            # Camshift가 갱신한 window로 업데이트\n",
        "            track_window = cs_box\n",
        "            out.write(frame2)\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(\"Done. Saved as mean_cam_output.avi\")\n",
        "        # Colab에서 보기 위해 mp4 변환\n",
        "        !ffmpeg -y -i mean_cam_output.avi -vcodec libx264 mean_cam_output.mp4\n",
        "        if os.path.exists('mean_cam_output.mp4'):\n",
        "            from IPython.display import Video\n",
        "            display(Video('mean_cam_output.mp4', embed=True))\n",
        "        else:\n",
        "            print(\"mp4 파일 생성 실패!\")"
      ],
      "metadata": {
        "id": "napX9zN1pD9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 비디오 다운로드\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "    exit()\n",
        "\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    print(\"Failed to read the first frame!\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "h, w, _ = frame.shape\n",
        "\n",
        "# ✅ 초기 ROI 수동 조정: 앞쪽 하얀 자동차에 맞춤\n",
        "x, y, w_box, h_box = 270, 200, 90, 60\n",
        "track_window = (x, y, w_box, h_box)\n",
        "\n",
        "# 초기 ROI 히스토그램 계산\n",
        "roi = frame[y:y+h_box, x:x+w_box]\n",
        "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255))\n",
        "roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180, 256], [0,180, 0,256])\n",
        "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "\n",
        "# 결과 저장용\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "out = cv.VideoWriter('mean_cam_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "while True:\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "    back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "\n",
        "    # MeanShift (Optional)\n",
        "    ret_ms, ms_box = cv.meanShift(back_proj, track_window, term_crit)\n",
        "    x_ms, y_ms, w_ms, h_ms = ms_box\n",
        "    cv.rectangle(frame2, (x_ms, y_ms), (x_ms + w_ms, y_ms + h_ms), (255, 0, 0), 2)\n",
        "\n",
        "    # CamShift\n",
        "    ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "    pts = cv.boxPoints(ret_cs)\n",
        "    pts = pts.astype(int)\n",
        "    cv.polylines(frame2, [pts], True, (0, 255, 0), 2)\n",
        "\n",
        "    # 추적 영역 업데이트\n",
        "    track_window = cs_box\n",
        "    out.write(frame2)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"✅ 추적 완료: mean_cam_output.avi 저장됨\")\n",
        "\n",
        "# mp4 변환 및 출력\n",
        "!ffmpeg -y -i mean_cam_output.avi -vcodec libx264 mean_cam_output.mp4\n",
        "if os.path.exists('mean_cam_output.mp4'):\n",
        "    from IPython.display import Video\n",
        "    display(Video('mean_cam_output.mp4', embed=True))\n",
        "else:\n",
        "    print(\"mp4 파일 생성 실패!\")\n"
      ],
      "metadata": {
        "id": "2V6kOcBR0Du5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KCF (Kernelized Correlation Filters)\n"
      ],
      "metadata": {
        "id": "zpMmvST7t322"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MIL Tracker 예시 (MOSSE 대신 사용)\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "# Use MIL tracker\n",
        "tracker = cv.TrackerMIL_create()\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the first frame!\")\n",
        "        cap.release()\n",
        "    else:\n",
        "        h, w, _ = frame.shape\n",
        "        # 초기 바운딩 박스 (수동 설정 또는 객체 검출 결과 사용)\n",
        "        init_bbox = (int(w/2 - 50), int(h/2 - 30), 100, 60)\n",
        "        # 트래커 초기화\n",
        "        ok = tracker.init(frame, init_bbox)\n",
        "\n",
        "        if not ok:\n",
        "             print(\"Failed to initialize tracker\")\n",
        "             cap.release()\n",
        "        else:\n",
        "            fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "            out = cv.VideoWriter('mil_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "            while True:\n",
        "                ret, frame2 = cap.read()\n",
        "\n",
        "                if not ret:\n",
        "                    break\n",
        "                # 트래커 업데이트\n",
        "                ok, bbox = tracker.update(frame2)\n",
        "\n",
        "                # 결과 그리기\n",
        "                if ok:\n",
        "                    (x, y, w_box, h_box) = [int(v) for v in bbox]\n",
        "                    cv.rectangle(frame2, (x,y), (x+w_box, y+h_box), (0,255,255), 2)\n",
        "                else:\n",
        "                    cv.putText(frame2, \"Tracking Failure\", (50,80), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
        "                out.write(frame2)\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            print(\"Done. Saved as mil_output.avi\")\n",
        "            # Colab에서 보기 위해 mp4 변환\n",
        "            !ffmpeg -y -i mil_output.avi -vcodec libx264 mil_output.mp4\n",
        "            import os\n",
        "            if os.path.exists('mil_output.mp4'):\n",
        "                from IPython.display import Video\n",
        "                display(Video('mil_output.mp4', embed=True))\n",
        "            else:\n",
        "                print(\"mp4 파일 생성 실패!\")"
      ],
      "metadata": {
        "id": "TQ7m23x8tota"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "print(\"버전:\", cv.__version__)\n",
        "\n",
        "try:\n",
        "    tracker = cv.TrackerKCF_create()\n",
        "    print(\"✅ TrackerKCF 생성 성공!\")\n",
        "except AttributeError:\n",
        "    try:\n",
        "        tracker = cv.legacy.TrackerKCF_create()\n",
        "        print(\"✅ legacy.TrackerKCF 생성 성공!\")\n",
        "    except AttributeError:\n",
        "        print(\"❌ TrackerKCF는 현재 설치된 OpenCV에 없음. 'opencv-contrib-python' 설치 필요!\")\n"
      ],
      "metadata": {
        "id": "desnrqSrt_Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57219c6e"
      },
      "source": [
        "import cv2 as cv\n",
        "print(dir(cv.legacy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba49c683"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 1. 모델 파일 다운로드 (working links from a different source)\n",
        "# Using links from https://github.com/djmv/mobilenet_ssd_opencv\n",
        "!wget -O mobilenet.prototxt https://raw.githubusercontent.com/djmv/mobilenet_ssd_opencv/master/MobileNetSSD_deploy.prototxt\n",
        "!wget -O mobilenet.caffemodel https://raw.githubusercontent.com/djmv/mobilenet_ssd_opencv/master/MobileNetSSD_deploy.caffemodel\n",
        "\n",
        "# 2. 모델 로드 확인\n",
        "net = cv.dnn.readNetFromCaffe(\"mobilenet.prototxt\", \"mobilenet.caffemodel\")\n",
        "if net.empty():\n",
        "    raise Exception(\"❌ 모델 로딩 실패! 파일이 비어 있거나 손상됨.\")\n",
        "else:\n",
        "    print(\"✅ 모델 로딩 성공!\")\n",
        "\n",
        "\n",
        "# 3. 클래스 정의\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# 4. 비디오 불러오기\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture(\"traffic\")\n",
        "if not cap.isOpened():\n",
        "    raise Exception(\"❌ 비디오 열기 실패\")\n",
        "else:\n",
        "    print(\"✅ 비디오 열기 성공!\")\n",
        "\n",
        "# 5. 객체 탐지 루프 (for Colab display)\n",
        "# Use IPython.display for showing frames in Colab instead of cv.imshow\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv.CAP_PROP_FPS)\n",
        "out = cv.VideoWriter('detection_output.avi', fourcc, fps if fps > 0 else 30, (width, height))\n",
        "\n",
        "\n",
        "print(\"🚀 객체 탐지 시작...\")\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        h, w = frame.shape[:2]\n",
        "        # MobileNet-SSD expects 300x300 input\n",
        "        blob = cv.dnn.blobFromImage(cv.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "        net.setInput(blob)\n",
        "        detections = net.forward()\n",
        "\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = detections[0, 0, i, 2]\n",
        "            # Filter detections by confidence and class (only 'car' in this case)\n",
        "            if confidence > 0.5: # Confidence threshold\n",
        "                idx = int(detections[0, 0, i, 1])\n",
        "                # Ensure the index is within the bounds of the CLASSES list\n",
        "                if idx < len(CLASSES):\n",
        "                    label = CLASSES[idx]\n",
        "                    # Only draw bounding boxes for 'car'\n",
        "                    if label == \"car\":\n",
        "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
        "                        cv.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green bounding box\n",
        "                        # Display label and confidence\n",
        "                        label_text = f\"{label}: {confidence:.2f}\"\n",
        "                        cv.putText(frame, label_text, (x1, y1 - 5),\n",
        "                                   cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        # Write the frame with detections to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "        # Display the frame in Colab (optional, can be slow)\n",
        "        # cv2_imshow(frame)\n",
        "        # if cv.waitKey(1) & 0xFF == 27: # Press 'Esc' to exit\n",
        "        #     break\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    # cv.destroyAllWindows() # Not needed for cv2_imshow\n",
        "\n",
        "    print(\"✅ 객체 탐지 완료!\")\n",
        "    print(\"Done. Saved as detection_output.avi\")\n",
        "\n",
        "    # Colab에서 보기 위해 mp4 변환\n",
        "    !ffmpeg -y -i detection_output.avi -vcodec libx264 detection_output.mp4\n",
        "\n",
        "    import os\n",
        "    if os.path.exists('detection_output.mp4'):\n",
        "        from IPython.display import Video\n",
        "        display(Video('detection_output.mp4', embed=True))\n",
        "    else:\n",
        "        print(\"mp4 파일 생성 실패!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f36d96b"
      },
      "source": [
        "import cv2 as cv\n",
        "print(dir(cv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec6d2f99"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Ensure 'mobilenet.prototxt' and 'mobilenet.caffemodel' are uploaded to your Colab session storage\n",
        "try:\n",
        "    net = cv.dnn.readNetFromCaffe(\"mobilenet.prototxt\", \"mobilenet.caffemodel\")\n",
        "    if net.empty():\n",
        "        raise Exception(\"❌ 모델 로딩 실패! 파일이 비어 있거나 손상됨. 파일이 올바르게 업로드되었는지 확인하세요.\")\n",
        "    else:\n",
        "        print(\"✅ 모델 로딩 성공!\")\n",
        "except cv.error as e:\n",
        "    print(f\"❌ OpenCV 에러 발생: {e}\")\n",
        "    print(\"모델 파일을 찾거나 로드하는 데 문제가 발생했습니다. 파일 이름과 경로를 확인하세요.\")\n",
        "    # Exit or handle the error appropriately if model loading fails\n",
        "    exit() # Exit the cell execution\n",
        "\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# 비디오 열기\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture('traffic')\n",
        "ret, frame = cap.read()\n",
        "\n",
        "if not ret:\n",
        "    print(\"❌ 첫 프레임 로딩 실패\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# 자동차 검출 (using the loaded model)\n",
        "blob = cv.dnn.blobFromImage(cv.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "cars = []\n",
        "(h, w) = frame.shape[:2]\n",
        "for i in range(detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    # Filter detections by confidence and class (only 'car' in this case)\n",
        "    if confidence > 0.5: # You can adjust this confidence threshold\n",
        "        idx = int(detections[0, 0, i, 1])\n",
        "        # Ensure the index is within the bounds of the CLASSES list\n",
        "        if idx < len(CLASSES):\n",
        "            label = CLASSES[idx]\n",
        "            # Only consider 'car' detections\n",
        "            if label == \"car\":\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (x, y, x2, y2) = box.astype(\"int\")\n",
        "                cars.append((x, y, x2 - x, y2 - y)) # Store bounding box as (x, y, width, height)\n",
        "\n",
        "# Check if any cars were detected\n",
        "if not cars:\n",
        "    print(\"🚫 첫 프레임에서 자동차 객체를 검출하지 못했습니다. 추적을 시작할 수 없습니다.\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# Use the first detected car's bounding box to initialize tracking\n",
        "track_window = cars[0]\n",
        "x, y, w_box, h_box = track_window\n",
        "\n",
        "# Calculate the histogram of the ROI for CamShift\n",
        "roi = frame[y:y+h_box, x:x+w_box]\n",
        "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255)) # Adjust mask as needed\n",
        "roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180,256], [0,180,0,256])\n",
        "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "# Set termination criteria for CamShift\n",
        "term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "\n",
        "# Setup VideoWriter for output\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "out = cv.VideoWriter('detection_tracking_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "print(\"🚀 객체 추적 시작 (검출 결과 기반)...\")\n",
        "# Tracking loop\n",
        "while True:\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "    back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "\n",
        "    # Apply CamShift\n",
        "    ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "\n",
        "    # Draw the tracking box\n",
        "    pts = cv.boxPoints(ret_cs)\n",
        "    pts = pts.astype(int)\n",
        "    cv.polylines(frame2, [pts], True, (0, 255, 0), 2) # Green box for tracking\n",
        "\n",
        "    # Update the tracking window for the next frame\n",
        "    track_window = cs_box\n",
        "\n",
        "    out.write(frame2)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"✅ 객체 추적 완료!\")\n",
        "print(\"Done. Saved as detection_tracking_output.avi\")\n",
        "\n",
        "# Convert to MP4 for Colab display\n",
        "!ffmpeg -y -i detection_tracking_output.avi -vcodec libx264 detection_tracking_output.mp4\n",
        "\n",
        "import os\n",
        "if os.path.exists('detection_tracking_output.mp4'):\n",
        "    from IPython.display import Video\n",
        "    display(Video('detection_tracking_output.mp4', embed=True))\n",
        "else:\n",
        "    print(\"mp4 파일 생성 실패!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6114b6f7"
      },
      "source": [
        "import cv2 as cv\n",
        "# List all attributes in cv2 that contain \"Tracker\"\n",
        "tracker_attributes = [attr for attr in dir(cv) if \"Tracker\" in attr]\n",
        "print(tracker_attributes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hough Line Transform"
      ],
      "metadata": {
        "id": "2CWjrFSgfAf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제: Sudoku 이미지에 대한 Hough Transform\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# sudoku.png 다운로드\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/samples/data/sudoku.png -O sudoku.png\n",
        "if not os.path.exists('sudoku.png'):\n",
        "    print(\"sudoku.png not found.\")\n",
        "else:\n",
        "    # 1) 이미지 읽기\n",
        "    img = cv.imread('sudoku.png')\n",
        "    if img is None:\n",
        "        print(\"Could not read sudoku image.\")\n",
        "    else:\n",
        "        # 2) 그레이스케일 & Canny 에지\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        edges = cv.Canny(gray, 50, 150, apertureSize=3)\n",
        "        # 3) 표준 HoughLines\n",
        "        lines = cv.HoughLines(edges, 1, np.pi/180, 200)\n",
        "        img_hough = img.copy()\n",
        "        if lines is not None:\n",
        "            for i in range(len(lines)):\n",
        "                rho = lines[i][0][0]\n",
        "                theta = lines[i][0][1]\n",
        "                a = np.cos(theta)\n",
        "                b = np.sin(theta)\n",
        "                x0 = a * rho\n",
        "                y0 = b * rho\n",
        "                scale = 1000\n",
        "                x1 = int(x0 + scale * (-b))\n",
        "                y1 = int(y0 + scale * (a))\n",
        "                x2 = int(x0 - scale * (-b))\n",
        "                y2 = int(y0 - scale * (a))\n",
        "                cv.line(img_hough, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "        # 4) 확률적 HoughLinesP\n",
        "        linesP = cv.HoughLinesP(edges, 1, np.pi/180, 80, minLineLength=50, maxLineGap=10)\n",
        "        img_houghP = img.copy()\n",
        "        if linesP is not None:\n",
        "            for i in range(len(linesP)):\n",
        "                x1, y1, x2, y2 = linesP[i][0]\n",
        "                cv.line(img_houghP, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        # 5) 시각화\n",
        "        plt.figure(figsize=(15,8))\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.title('Original')\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.title('Canny Edges')\n",
        "        plt.imshow(edges, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,3)\n",
        "        plt.title('HoughLines (Standard)')\n",
        "        plt.imshow(cv.cvtColor(img_hough, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,4)\n",
        "        plt.title('HoughLinesP (Probabilistic)')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print('Done!')"
      ],
      "metadata": {
        "id": "ArlrFO21gMlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 추가 실험 : 모폴로지(Morphology) 등\n"
      ],
      "metadata": {
        "id": "sGBVJEMmgVi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 추가 실험 코드 셀 : Morphology + Hough\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# 여기서는 sudoku.png 재사용 해봄\n",
        "img2 = cv.imread('sudoku.png')\n",
        "if img2 is None:\n",
        "    print('No image found for morphological test.')\n",
        "else:\n",
        "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
        "    # 모폴로지 연산 : closing (이건 효과적인 것을 찾아볼 것)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    closed = cv.morphologyEx(gray2, cv.MORPH_CLOSE, kernel)\n",
        "    # Canny 에지 검출\n",
        "    edges2 = cv.Canny(closed, 50, 150)\n",
        "    # HoughLinesP 수행\n",
        "    lines2P = cv.HoughLinesP(edges2, 1, np.pi/180, 80, minLineLength=50, maxLineGap=10)\n",
        "    img_result = img2.copy()\n",
        "    if lines2P is not None:\n",
        "        for i in range(len(lines2P)):\n",
        "            x1, y1, x2, y2 = lines2P[i][0]\n",
        "            cv.line(img_result, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "    # 시각화\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
        "    axs[0].imshow(cv.cvtColor(gray2, cv.COLOR_BGR2RGB))\n",
        "    axs[0].set_title('Original Gray')\n",
        "    axs[0].axis('off')\n",
        "    axs[1].imshow(closed, cmap='gray')\n",
        "    axs[1].set_title('Morphology Closed')\n",
        "    axs[1].axis('off')\n",
        "    axs[2].imshow(cv.cvtColor(img_result, cv.COLOR_BGR2RGB))\n",
        "    axs[2].set_title('HoughLinesP after Morphology')\n",
        "    axs[2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ipMILt6ygN2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: . 다른 이미지 실험\n",
        "# 도로, 건축물, 철로 등 직선이 많은 이미지를 고르고 cv.HoughLines / cv.HoughLinesP 를 적용.\n",
        "# Canny 파라미터 및 Hough 파라미터( threshold , minLineLength , maxLineGap ) 등을 변경해 가며 결과를 비교.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "# 사용할 이미지 파일 이름 지정\n",
        "image_file = 'building.jpg'\n",
        "# image_file = 'railway.jpg' # 만약 철로 이미지를 사용하려면 이 줄 활성화\n",
        "\n",
        "if not os.path.exists(image_file):\n",
        "    print(f\"{image_file} not found. Please upload {image_file} to your Colab session storage.\")\n",
        "else:\n",
        "    # 이미지 읽기\n",
        "    img_orig = cv.imread(image_file)\n",
        "\n",
        "    if img_orig is None:\n",
        "        print(f\"Could not read {image_file}.\")\n",
        "    else:\n",
        "        # 그레이스케일 변환\n",
        "        gray = cv.cvtColor(img_orig, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Canny 에지 검출 파라미터\n",
        "        canny_threshold1 = 50\n",
        "        canny_threshold2 = 150\n",
        "        canny_aperture_size = 3\n",
        "\n",
        "        # Canny 에지 검출\n",
        "        edges = cv.Canny(gray, canny_threshold1, canny_threshold2, apertureSize=canny_aperture_size)\n",
        "\n",
        "        # HoughLinesP 파라미터 (확률적 허프 변환)\n",
        "        hough_rho = 1\n",
        "        hough_theta = np.pi / 180\n",
        "        hough_threshold = 100 # 직선으로 간주할 최소 교차점 수\n",
        "        hough_min_line_length = 50 # 검출될 최소 직선 길이\n",
        "        hough_max_line_gap = 10   # 직선으로 간주할 최대 직선 간격\n",
        "\n",
        "        # HoughLinesP 적용\n",
        "        linesP = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold,\n",
        "                                minLineLength=hough_min_line_length,\n",
        "                                maxLineGap=hough_max_line_gap)\n",
        "\n",
        "        img_houghP = img_orig.copy()\n",
        "\n",
        "        # 검출된 직선 그리기\n",
        "        if linesP is not None:\n",
        "            print(f\"Detected {len(linesP)} lines using HoughLinesP.\")\n",
        "            for i in range(len(linesP)):\n",
        "                x1, y1, x2, y2 = linesP[i][0]\n",
        "                cv.line(img_houghP, (x1, y1), (x2, y2), (0, 255, 0), 2) # 초록색 선\n",
        "\n",
        "        # 결과 시각화\n",
        "        plt.figure(figsize=(18, 6))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Original Image')\n",
        "        plt.imshow(cv.cvtColor(img_orig, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Canny Edges')\n",
        "        plt.imshow(edges, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title('HoughLinesP Result')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n--- Parameter Tuning Example ---\")\n",
        "        # 파라미터 변경 예시: threshold를 낮춰 더 많은 직선 검출\n",
        "        hough_threshold_low = 50\n",
        "        linesP_low_thresh = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold_low,\n",
        "                                          minLineLength=hough_min_line_length,\n",
        "                                          maxLineGap=hough_max_line_gap)\n",
        "        img_houghP_low_thresh = img_orig.copy()\n",
        "        if linesP_low_thresh is not None:\n",
        "             print(f\"Detected {len(linesP_low_thresh)} lines with lower threshold ({hough_threshold_low}).\")\n",
        "             for i in range(len(linesP_low_thresh)):\n",
        "                x1, y1, x2, y2 = linesP_low_thresh[i][0]\n",
        "                cv.line(img_houghP_low_thresh, (x1, y1), (x2, y2), (255, 0, 0), 2) # 파란색 선\n",
        "\n",
        "        # 파라미터 변경 예시: minLineLength를 늘려 짧은 직선 제외\n",
        "        hough_min_line_length_long = 100\n",
        "        linesP_long_length = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold,\n",
        "                                           minLineLength=hough_min_line_length_long,\n",
        "                                           maxLineGap=hough_max_line_gap)\n",
        "        img_houghP_long_length = img_orig.copy()\n",
        "        if linesP_long_length is not None:\n",
        "             print(f\"Detected {len(linesP_long_length)} lines with longer minLineLength ({hough_min_line_length_long}).\")\n",
        "             for i in range(len(linesP_long_length)):\n",
        "                x1, y1, x2, y2 = linesP_long_length[i][0]\n",
        "                cv.line(img_houghP_long_length, (x1, y1), (x2, y2), (0, 0, 255), 2) # 빨간색 선\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f'HoughLinesP (Threshold={hough_threshold})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f'HoughLinesP (Threshold={hough_threshold_low})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_low_thresh, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f'HoughLinesP (minLineLength={hough_min_line_length_long})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_long_length, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Canny 파라미터 변경 예시: 높은 임계값 사용\n",
        "        canny_threshold1_high = 100\n",
        "        canny_threshold2_high = 200\n",
        "        edges_high_thresh = cv.Canny(gray, canny_threshold1_high, canny_threshold2_high, apertureSize=canny_aperture_size)\n",
        "\n",
        "        linesP_high_canny = cv.HoughLinesP(edges_high_thresh, hough_rho, hough_theta, hough_threshold,\n",
        "                                          minLineLength=hough_min_line_length,\n",
        "                                          maxLineGap=hough_max_line_gap)\n",
        "\n",
        "        img_houghP_high_canny = img_orig.copy()\n",
        "        if linesP_high_canny is not None:\n",
        "             print(f\"Detected {len(linesP_high_canny)} lines with higher Canny thresholds ({canny_threshold1_high}, {canny_threshold2_high}).\")\n",
        "             for i in range(len(linesP_high_canny)):\n",
        "                x1, y1, x2, y2 = linesP_high_canny[i][0]\n",
        "                cv.line(img_houghP_high_canny, (x1, y1), (x2, y2), (0, 255, 255), 2) # 노란색 선\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f'Canny Edges (Thresholds={canny_threshold1_high}, {canny_threshold2_high})')\n",
        "        plt.imshow(edges_high_thresh, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('HoughLinesP after High Canny')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_high_canny, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "sstcM3IGgYV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AzWIkR96g-Gj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
