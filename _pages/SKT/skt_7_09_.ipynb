{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMJ0m/jMHQAZuzlAD1w15Kc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_09_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background Subtraction"
      ],
      "metadata": {
        "id": "Yhktnp-zod7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-contrib-python numpy matplotlib ffmpeg-python --quiet\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ffmpeg\n",
        "import os\n",
        "from IPython.display import HTML, Video\n",
        "print(\"OpenCV version:\", cv.__version__)\n"
      ],
      "metadata": {
        "id": "XHckYMnuojNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MOG(Mixture of Gaussians)"
      ],
      "metadata": {
        "id": "d7cdoeQgo_77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O sample\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/4.x/samples/data/vtest.avi -O sample_video.avi\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "fgbg_mog2 = cv.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
        "fgbg_knn = cv.createBackgroundSubtractorKNN(history=500, dist2Threshold=400.0, detectShadows=True)\n",
        "cap = cv.VideoCapture('sample_video.avi')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    # ë™ì˜ìƒì„ ì €ìž¥í•  VideoWriter\n",
        "    width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps    = cap.get(cv.CAP_PROP_FPS)\n",
        "    fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv.VideoWriter('bgsub_output.avi', fourcc, fps if fps>0 else 30, (width*3, height))\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        fgmask_mog2_ = fgbg_mog2.apply(frame)\n",
        "        fgmask_knn_  = fgbg_knn.apply(frame)\n",
        "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (3,3))\n",
        "        fgmask_mog2_ = cv.morphologyEx(fgmask_mog2_, cv.MORPH_OPEN, kernel)\n",
        "        fgmask_knn_  = cv.morphologyEx(fgmask_knn_,  cv.MORPH_OPEN, kernel)\n",
        "\n",
        "        # Apply the MOG2 mask to the original frame to show only the foreground\n",
        "        foreground_mog2 = cv.bitwise_and(frame, frame, mask=fgmask_mog2_)\n",
        "\n",
        "        # ì‹œê°í™”ë¥¼ ìœ„í•´ ì„¸ í”„ë ˆìž„ì„ ê°€ë¡œë¡œ ë¶™ì—¬ì„œ ì €ìž¥\n",
        "        # ì›ë³¸ / MOG2 ë°°ê²½ ì œê±°ëœ ì˜ìƒ / KNN ë§ˆìŠ¤í¬\n",
        "        mask_knn_color  = cv.cvtColor(fgmask_knn_,  cv.COLOR_GRAY2BGR)\n",
        "        concat_frame = cv.hconcat([frame, foreground_mog2, mask_knn_color])\n",
        "        out.write(concat_frame)\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Done. Saved as bgsub_output.avi\")\n",
        "    # Colabì—ì„œ ë³´ê¸° ìœ„í•´ mp4 ë³€í™˜\n",
        "    !ffmpeg -y -i bgsub_output.avi -vcodec libx264 bgsub_output.mp4\n",
        "    if os.path.exists('bgsub_output.mp4'):\n",
        "        from IPython.display import Video\n",
        "        display(Video('bgsub_output.mp4', embed=True))\n",
        "    else:\n",
        "        print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")"
      ],
      "metadata": {
        "id": "2HldrfqKotVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Moving Object Trackiing (ê°ì²´ ì¶”ì )"
      ],
      "metadata": {
        "id": "-TVeIhqQpNlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the first frame!\")\n",
        "        cap.release()\n",
        "    else:\n",
        "        h, w, _ = frame.shape\n",
        "        x, y, w_box, h_box = int(w/2 - 50), int(h/2 - 30), 100, 60\n",
        "        track_window = (x, y, w_box, h_box)\n",
        "        # ì´ˆê¸° ROI ížˆìŠ¤í† ê·¸ëž¨ ê³„ì‚°\n",
        "        roi = frame[y:y+h_box, x:x+w_box]\n",
        "        hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "        mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255))\n",
        "        roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180, 256], [0,180, 0,256])\n",
        "        cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "        term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "        # ê²°ê³¼ ì €ìž¥ìš©\n",
        "        fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "        out = cv.VideoWriter('mean_cam_output.avi', fourcc, 30, (w, h))\n",
        "        while True:\n",
        "            ret, frame2 = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "            hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "            back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "            # 1) Meanshift\n",
        "            ret_ms, ms_box = cv.meanShift(back_proj, track_window, term_crit)\n",
        "            x_ms, y_ms, w_ms, h_ms = ms_box\n",
        "            cv.rectangle(frame2, (x_ms, y_ms), (x_ms+w_ms, y_ms+h_ms), (255,0,0), 2)\n",
        "            # 2) Camshift\n",
        "            ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "            pts = cv.boxPoints(ret_cs)\n",
        "            #pts = np.int0(pts)\n",
        "            pts = pts.astype(int)\n",
        "            cv.polylines(frame2, [pts], True, (0,255,0), 2)\n",
        "            # Camshiftê°€ ê°±ì‹ í•œ windowë¡œ ì—…ë°ì´íŠ¸\n",
        "            track_window = cs_box\n",
        "            out.write(frame2)\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(\"Done. Saved as mean_cam_output.avi\")\n",
        "        # Colabì—ì„œ ë³´ê¸° ìœ„í•´ mp4 ë³€í™˜\n",
        "        !ffmpeg -y -i mean_cam_output.avi -vcodec libx264 mean_cam_output.mp4\n",
        "        if os.path.exists('mean_cam_output.mp4'):\n",
        "            from IPython.display import Video\n",
        "            display(Video('mean_cam_output.mp4', embed=True))\n",
        "        else:\n",
        "            print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")"
      ],
      "metadata": {
        "id": "napX9zN1pD9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "    exit()\n",
        "\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    print(\"Failed to read the first frame!\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "h, w, _ = frame.shape\n",
        "\n",
        "# âœ… ì´ˆê¸° ROI ìˆ˜ë™ ì¡°ì •: ì•žìª½ í•˜ì–€ ìžë™ì°¨ì— ë§žì¶¤\n",
        "x, y, w_box, h_box = 270, 200, 90, 60\n",
        "track_window = (x, y, w_box, h_box)\n",
        "\n",
        "# ì´ˆê¸° ROI ížˆìŠ¤í† ê·¸ëž¨ ê³„ì‚°\n",
        "roi = frame[y:y+h_box, x:x+w_box]\n",
        "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255))\n",
        "roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180, 256], [0,180, 0,256])\n",
        "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "\n",
        "# ê²°ê³¼ ì €ìž¥ìš©\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "out = cv.VideoWriter('mean_cam_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "while True:\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "    back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "\n",
        "    # MeanShift (Optional)\n",
        "    ret_ms, ms_box = cv.meanShift(back_proj, track_window, term_crit)\n",
        "    x_ms, y_ms, w_ms, h_ms = ms_box\n",
        "    cv.rectangle(frame2, (x_ms, y_ms), (x_ms + w_ms, y_ms + h_ms), (255, 0, 0), 2)\n",
        "\n",
        "    # CamShift\n",
        "    ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "    pts = cv.boxPoints(ret_cs)\n",
        "    pts = pts.astype(int)\n",
        "    cv.polylines(frame2, [pts], True, (0, 255, 0), 2)\n",
        "\n",
        "    # ì¶”ì  ì˜ì—­ ì—…ë°ì´íŠ¸\n",
        "    track_window = cs_box\n",
        "    out.write(frame2)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"âœ… ì¶”ì  ì™„ë£Œ: mean_cam_output.avi ì €ìž¥ë¨\")\n",
        "\n",
        "# mp4 ë³€í™˜ ë° ì¶œë ¥\n",
        "!ffmpeg -y -i mean_cam_output.avi -vcodec libx264 mean_cam_output.mp4\n",
        "if os.path.exists('mean_cam_output.mp4'):\n",
        "    from IPython.display import Video\n",
        "    display(Video('mean_cam_output.mp4', embed=True))\n",
        "else:\n",
        "    print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")\n"
      ],
      "metadata": {
        "id": "2V6kOcBR0Du5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KCF (Kernelized Correlation Filters)\n"
      ],
      "metadata": {
        "id": "zpMmvST7t322"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MIL Tracker ì˜ˆì‹œ (MOSSE ëŒ€ì‹  ì‚¬ìš©)\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "# Use MIL tracker\n",
        "tracker = cv.TrackerMIL_create()\n",
        "cap = cv.VideoCapture('traffic')\n",
        "if not cap.isOpened():\n",
        "    print(\"Video open failed!\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Failed to read the first frame!\")\n",
        "        cap.release()\n",
        "    else:\n",
        "        h, w, _ = frame.shape\n",
        "        # ì´ˆê¸° ë°”ìš´ë”© ë°•ìŠ¤ (ìˆ˜ë™ ì„¤ì • ë˜ëŠ” ê°ì²´ ê²€ì¶œ ê²°ê³¼ ì‚¬ìš©)\n",
        "        init_bbox = (int(w/2 - 50), int(h/2 - 30), 100, 60)\n",
        "        # íŠ¸ëž˜ì»¤ ì´ˆê¸°í™”\n",
        "        ok = tracker.init(frame, init_bbox)\n",
        "\n",
        "        if not ok:\n",
        "             print(\"Failed to initialize tracker\")\n",
        "             cap.release()\n",
        "        else:\n",
        "            fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "            out = cv.VideoWriter('mil_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "            while True:\n",
        "                ret, frame2 = cap.read()\n",
        "\n",
        "                if not ret:\n",
        "                    break\n",
        "                # íŠ¸ëž˜ì»¤ ì—…ë°ì´íŠ¸\n",
        "                ok, bbox = tracker.update(frame2)\n",
        "\n",
        "                # ê²°ê³¼ ê·¸ë¦¬ê¸°\n",
        "                if ok:\n",
        "                    (x, y, w_box, h_box) = [int(v) for v in bbox]\n",
        "                    cv.rectangle(frame2, (x,y), (x+w_box, y+h_box), (0,255,255), 2)\n",
        "                else:\n",
        "                    cv.putText(frame2, \"Tracking Failure\", (50,80), cv.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
        "                out.write(frame2)\n",
        "            cap.release()\n",
        "            out.release()\n",
        "            print(\"Done. Saved as mil_output.avi\")\n",
        "            # Colabì—ì„œ ë³´ê¸° ìœ„í•´ mp4 ë³€í™˜\n",
        "            !ffmpeg -y -i mil_output.avi -vcodec libx264 mil_output.mp4\n",
        "            import os\n",
        "            if os.path.exists('mil_output.mp4'):\n",
        "                from IPython.display import Video\n",
        "                display(Video('mil_output.mp4', embed=True))\n",
        "            else:\n",
        "                print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")"
      ],
      "metadata": {
        "id": "TQ7m23x8tota"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "print(\"ë²„ì „:\", cv.__version__)\n",
        "\n",
        "try:\n",
        "    tracker = cv.TrackerKCF_create()\n",
        "    print(\"âœ… TrackerKCF ìƒì„± ì„±ê³µ!\")\n",
        "except AttributeError:\n",
        "    try:\n",
        "        tracker = cv.legacy.TrackerKCF_create()\n",
        "        print(\"âœ… legacy.TrackerKCF ìƒì„± ì„±ê³µ!\")\n",
        "    except AttributeError:\n",
        "        print(\"âŒ TrackerKCFëŠ” í˜„ìž¬ ì„¤ì¹˜ëœ OpenCVì— ì—†ìŒ. 'opencv-contrib-python' ì„¤ì¹˜ í•„ìš”!\")\n"
      ],
      "metadata": {
        "id": "desnrqSrt_Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57219c6e"
      },
      "source": [
        "import cv2 as cv\n",
        "print(dir(cv.legacy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba49c683"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 1. ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (working links from a different source)\n",
        "# Using links from https://github.com/djmv/mobilenet_ssd_opencv\n",
        "!wget -O mobilenet.prototxt https://raw.githubusercontent.com/djmv/mobilenet_ssd_opencv/master/MobileNetSSD_deploy.prototxt\n",
        "!wget -O mobilenet.caffemodel https://raw.githubusercontent.com/djmv/mobilenet_ssd_opencv/master/MobileNetSSD_deploy.caffemodel\n",
        "\n",
        "# 2. ëª¨ë¸ ë¡œë“œ í™•ì¸\n",
        "net = cv.dnn.readNetFromCaffe(\"mobilenet.prototxt\", \"mobilenet.caffemodel\")\n",
        "if net.empty():\n",
        "    raise Exception(\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨! íŒŒì¼ì´ ë¹„ì–´ ìžˆê±°ë‚˜ ì†ìƒë¨.\")\n",
        "else:\n",
        "    print(\"âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ!\")\n",
        "\n",
        "\n",
        "# 3. í´ëž˜ìŠ¤ ì •ì˜\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# 4. ë¹„ë””ì˜¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture(\"traffic\")\n",
        "if not cap.isOpened():\n",
        "    raise Exception(\"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨\")\n",
        "else:\n",
        "    print(\"âœ… ë¹„ë””ì˜¤ ì—´ê¸° ì„±ê³µ!\")\n",
        "\n",
        "# 5. ê°ì²´ íƒì§€ ë£¨í”„ (for Colab display)\n",
        "# Use IPython.display for showing frames in Colab instead of cv.imshow\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "width  = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv.CAP_PROP_FPS)\n",
        "out = cv.VideoWriter('detection_output.avi', fourcc, fps if fps > 0 else 30, (width, height))\n",
        "\n",
        "\n",
        "print(\"ðŸš€ ê°ì²´ íƒì§€ ì‹œìž‘...\")\n",
        "try:\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        h, w = frame.shape[:2]\n",
        "        # MobileNet-SSD expects 300x300 input\n",
        "        blob = cv.dnn.blobFromImage(cv.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "        net.setInput(blob)\n",
        "        detections = net.forward()\n",
        "\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = detections[0, 0, i, 2]\n",
        "            # Filter detections by confidence and class (only 'car' in this case)\n",
        "            if confidence > 0.5: # Confidence threshold\n",
        "                idx = int(detections[0, 0, i, 1])\n",
        "                # Ensure the index is within the bounds of the CLASSES list\n",
        "                if idx < len(CLASSES):\n",
        "                    label = CLASSES[idx]\n",
        "                    # Only draw bounding boxes for 'car'\n",
        "                    if label == \"car\":\n",
        "                        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                        (x1, y1, x2, y2) = box.astype(\"int\")\n",
        "                        cv.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2) # Green bounding box\n",
        "                        # Display label and confidence\n",
        "                        label_text = f\"{label}: {confidence:.2f}\"\n",
        "                        cv.putText(frame, label_text, (x1, y1 - 5),\n",
        "                                   cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
        "\n",
        "        # Write the frame with detections to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "        # Display the frame in Colab (optional, can be slow)\n",
        "        # cv2_imshow(frame)\n",
        "        # if cv.waitKey(1) & 0xFF == 27: # Press 'Esc' to exit\n",
        "        #     break\n",
        "\n",
        "finally:\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    # cv.destroyAllWindows() # Not needed for cv2_imshow\n",
        "\n",
        "    print(\"âœ… ê°ì²´ íƒì§€ ì™„ë£Œ!\")\n",
        "    print(\"Done. Saved as detection_output.avi\")\n",
        "\n",
        "    # Colabì—ì„œ ë³´ê¸° ìœ„í•´ mp4 ë³€í™˜\n",
        "    !ffmpeg -y -i detection_output.avi -vcodec libx264 detection_output.mp4\n",
        "\n",
        "    import os\n",
        "    if os.path.exists('detection_output.mp4'):\n",
        "        from IPython.display import Video\n",
        "        display(Video('detection_output.mp4', embed=True))\n",
        "    else:\n",
        "        print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f36d96b"
      },
      "source": [
        "import cv2 as cv\n",
        "print(dir(cv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec6d2f99"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Ensure 'mobilenet.prototxt' and 'mobilenet.caffemodel' are uploaded to your Colab session storage\n",
        "try:\n",
        "    net = cv.dnn.readNetFromCaffe(\"mobilenet.prototxt\", \"mobilenet.caffemodel\")\n",
        "    if net.empty():\n",
        "        raise Exception(\"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨! íŒŒì¼ì´ ë¹„ì–´ ìžˆê±°ë‚˜ ì†ìƒë¨. íŒŒì¼ì´ ì˜¬ë°”ë¥´ê²Œ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "    else:\n",
        "        print(\"âœ… ëª¨ë¸ ë¡œë”© ì„±ê³µ!\")\n",
        "except cv.error as e:\n",
        "    print(f\"âŒ OpenCV ì—ëŸ¬ ë°œìƒ: {e}\")\n",
        "    print(\"ëª¨ë¸ íŒŒì¼ì„ ì°¾ê±°ë‚˜ ë¡œë“œí•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ê³¼ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "    # Exit or handle the error appropriately if model loading fails\n",
        "    exit() # Exit the cell execution\n",
        "\n",
        "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
        "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
        "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n",
        "           \"sofa\", \"train\", \"tvmonitor\"]\n",
        "\n",
        "# ë¹„ë””ì˜¤ ì—´ê¸°\n",
        "!wget -q https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -O traffic\n",
        "\n",
        "cap = cv.VideoCapture('traffic')\n",
        "ret, frame = cap.read()\n",
        "\n",
        "if not ret:\n",
        "    print(\"âŒ ì²« í”„ë ˆìž„ ë¡œë”© ì‹¤íŒ¨\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# ìžë™ì°¨ ê²€ì¶œ (using the loaded model)\n",
        "blob = cv.dnn.blobFromImage(cv.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "cars = []\n",
        "(h, w) = frame.shape[:2]\n",
        "for i in range(detections.shape[2]):\n",
        "    confidence = detections[0, 0, i, 2]\n",
        "    # Filter detections by confidence and class (only 'car' in this case)\n",
        "    if confidence > 0.5: # You can adjust this confidence threshold\n",
        "        idx = int(detections[0, 0, i, 1])\n",
        "        # Ensure the index is within the bounds of the CLASSES list\n",
        "        if idx < len(CLASSES):\n",
        "            label = CLASSES[idx]\n",
        "            # Only consider 'car' detections\n",
        "            if label == \"car\":\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (x, y, x2, y2) = box.astype(\"int\")\n",
        "                cars.append((x, y, x2 - x, y2 - y)) # Store bounding box as (x, y, width, height)\n",
        "\n",
        "# Check if any cars were detected\n",
        "if not cars:\n",
        "    print(\"ðŸš« ì²« í”„ë ˆìž„ì—ì„œ ìžë™ì°¨ ê°ì²´ë¥¼ ê²€ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¶”ì ì„ ì‹œìž‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    cap.release()\n",
        "    exit()\n",
        "\n",
        "# Use the first detected car's bounding box to initialize tracking\n",
        "track_window = cars[0]\n",
        "x, y, w_box, h_box = track_window\n",
        "\n",
        "# Calculate the histogram of the ROI for CamShift\n",
        "roi = frame[y:y+h_box, x:x+w_box]\n",
        "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
        "mask_roi = cv.inRange(hsv_roi, (0, 60, 32), (180, 255, 255)) # Adjust mask as needed\n",
        "roi_hist = cv.calcHist([hsv_roi], [0,1], mask_roi, [180,256], [0,180,0,256])\n",
        "cv.normalize(roi_hist, roi_hist, 0, 255, cv.NORM_MINMAX)\n",
        "\n",
        "# Set termination criteria for CamShift\n",
        "term_crit = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1)\n",
        "\n",
        "# Setup VideoWriter for output\n",
        "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
        "out = cv.VideoWriter('detection_tracking_output.avi', fourcc, 30, (w, h))\n",
        "\n",
        "print(\"ðŸš€ ê°ì²´ ì¶”ì  ì‹œìž‘ (ê²€ì¶œ ê²°ê³¼ ê¸°ë°˜)...\")\n",
        "# Tracking loop\n",
        "while True:\n",
        "    ret, frame2 = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    hsv = cv.cvtColor(frame2, cv.COLOR_BGR2HSV)\n",
        "    back_proj = cv.calcBackProject([hsv], [0,1], roi_hist, [0,180, 0,256], 1)\n",
        "\n",
        "    # Apply CamShift\n",
        "    ret_cs, cs_box = cv.CamShift(back_proj, track_window, term_crit)\n",
        "\n",
        "    # Draw the tracking box\n",
        "    pts = cv.boxPoints(ret_cs)\n",
        "    pts = pts.astype(int)\n",
        "    cv.polylines(frame2, [pts], True, (0, 255, 0), 2) # Green box for tracking\n",
        "\n",
        "    # Update the tracking window for the next frame\n",
        "    track_window = cs_box\n",
        "\n",
        "    out.write(frame2)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "print(\"âœ… ê°ì²´ ì¶”ì  ì™„ë£Œ!\")\n",
        "print(\"Done. Saved as detection_tracking_output.avi\")\n",
        "\n",
        "# Convert to MP4 for Colab display\n",
        "!ffmpeg -y -i detection_tracking_output.avi -vcodec libx264 detection_tracking_output.mp4\n",
        "\n",
        "import os\n",
        "if os.path.exists('detection_tracking_output.mp4'):\n",
        "    from IPython.display import Video\n",
        "    display(Video('detection_tracking_output.mp4', embed=True))\n",
        "else:\n",
        "    print(\"mp4 íŒŒì¼ ìƒì„± ì‹¤íŒ¨!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6114b6f7"
      },
      "source": [
        "import cv2 as cv\n",
        "# List all attributes in cv2 that contain \"Tracker\"\n",
        "tracker_attributes = [attr for attr in dir(cv) if \"Tracker\" in attr]\n",
        "print(tracker_attributes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hough Line Transform"
      ],
      "metadata": {
        "id": "2CWjrFSgfAf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì œ: Sudoku ì´ë¯¸ì§€ì— ëŒ€í•œ Hough Transform\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# sudoku.png ë‹¤ìš´ë¡œë“œ\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/samples/data/sudoku.png -O sudoku.png\n",
        "if not os.path.exists('sudoku.png'):\n",
        "    print(\"sudoku.png not found.\")\n",
        "else:\n",
        "    # 1) ì´ë¯¸ì§€ ì½ê¸°\n",
        "    img = cv.imread('sudoku.png')\n",
        "    if img is None:\n",
        "        print(\"Could not read sudoku image.\")\n",
        "    else:\n",
        "        # 2) ê·¸ë ˆì´ìŠ¤ì¼€ì¼ & Canny ì—ì§€\n",
        "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "        edges = cv.Canny(gray, 50, 150, apertureSize=3)\n",
        "        # 3) í‘œì¤€ HoughLines\n",
        "        lines = cv.HoughLines(edges, 1, np.pi/180, 200)\n",
        "        img_hough = img.copy()\n",
        "        if lines is not None:\n",
        "            for i in range(len(lines)):\n",
        "                rho = lines[i][0][0]\n",
        "                theta = lines[i][0][1]\n",
        "                a = np.cos(theta)\n",
        "                b = np.sin(theta)\n",
        "                x0 = a * rho\n",
        "                y0 = b * rho\n",
        "                scale = 1000\n",
        "                x1 = int(x0 + scale * (-b))\n",
        "                y1 = int(y0 + scale * (a))\n",
        "                x2 = int(x0 - scale * (-b))\n",
        "                y2 = int(y0 - scale * (a))\n",
        "                cv.line(img_hough, (x1, y1), (x2, y2), (0,0,255), 2)\n",
        "        # 4) í™•ë¥ ì  HoughLinesP\n",
        "        linesP = cv.HoughLinesP(edges, 1, np.pi/180, 80, minLineLength=50, maxLineGap=10)\n",
        "        img_houghP = img.copy()\n",
        "        if linesP is not None:\n",
        "            for i in range(len(linesP)):\n",
        "                x1, y1, x2, y2 = linesP[i][0]\n",
        "                cv.line(img_houghP, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "        # 5) ì‹œê°í™”\n",
        "        plt.figure(figsize=(15,8))\n",
        "        plt.subplot(2,2,1)\n",
        "        plt.title('Original')\n",
        "        plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,2)\n",
        "        plt.title('Canny Edges')\n",
        "        plt.imshow(edges, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,3)\n",
        "        plt.title('HoughLines (Standard)')\n",
        "        plt.imshow(cv.cvtColor(img_hough, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.subplot(2,2,4)\n",
        "        plt.title('HoughLinesP (Probabilistic)')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        print('Done!')"
      ],
      "metadata": {
        "id": "ArlrFO21gMlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì¶”ê°€ ì‹¤í—˜ : ëª¨í´ë¡œì§€(Morphology) ë“±\n"
      ],
      "metadata": {
        "id": "sGBVJEMmgVi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¶”ê°€ ì‹¤í—˜ ì½”ë“œ ì…€ : Morphology + Hough\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# ì—¬ê¸°ì„œëŠ” sudoku.png ìž¬ì‚¬ìš© í•´ë´„\n",
        "img2 = cv.imread('sudoku.png')\n",
        "if img2 is None:\n",
        "    print('No image found for morphological test.')\n",
        "else:\n",
        "    gray2 = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
        "    # ëª¨í´ë¡œì§€ ì—°ì‚° : closing (ì´ê±´ íš¨ê³¼ì ì¸ ê²ƒì„ ì°¾ì•„ë³¼ ê²ƒ)\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    closed = cv.morphologyEx(gray2, cv.MORPH_CLOSE, kernel)\n",
        "    # Canny ì—ì§€ ê²€ì¶œ\n",
        "    edges2 = cv.Canny(closed, 50, 150)\n",
        "    # HoughLinesP ìˆ˜í–‰\n",
        "    lines2P = cv.HoughLinesP(edges2, 1, np.pi/180, 80, minLineLength=50, maxLineGap=10)\n",
        "    img_result = img2.copy()\n",
        "    if lines2P is not None:\n",
        "        for i in range(len(lines2P)):\n",
        "            x1, y1, x2, y2 = lines2P[i][0]\n",
        "            cv.line(img_result, (x1,y1), (x2,y2), (0,255,0), 2)\n",
        "    # ì‹œê°í™”\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
        "    axs[0].imshow(cv.cvtColor(gray2, cv.COLOR_BGR2RGB))\n",
        "    axs[0].set_title('Original Gray')\n",
        "    axs[0].axis('off')\n",
        "    axs[1].imshow(closed, cmap='gray')\n",
        "    axs[1].set_title('Morphology Closed')\n",
        "    axs[1].axis('off')\n",
        "    axs[2].imshow(cv.cvtColor(img_result, cv.COLOR_BGR2RGB))\n",
        "    axs[2].set_title('HoughLinesP after Morphology')\n",
        "    axs[2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ipMILt6ygN2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: . ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‹¤í—˜\n",
        "# ë„ë¡œ, ê±´ì¶•ë¬¼, ì² ë¡œ ë“± ì§ì„ ì´ ë§Žì€ ì´ë¯¸ì§€ë¥¼ ê³ ë¥´ê³  cv.HoughLines / cv.HoughLinesP ë¥¼ ì ìš©.\n",
        "# Canny íŒŒë¼ë¯¸í„° ë° Hough íŒŒë¼ë¯¸í„°( threshold , minLineLength , maxLineGap ) ë“±ì„ ë³€ê²½í•´ ê°€ë©° ê²°ê³¼ë¥¼ ë¹„êµ.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "\n",
        "# ì‚¬ìš©í•  ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ ì§€ì •\n",
        "image_file = 'building.jpg'\n",
        "# image_file = 'railway.jpg' # ë§Œì•½ ì² ë¡œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì´ ì¤„ í™œì„±í™”\n",
        "\n",
        "if not os.path.exists(image_file):\n",
        "    print(f\"{image_file} not found. Please upload {image_file} to your Colab session storage.\")\n",
        "else:\n",
        "    # ì´ë¯¸ì§€ ì½ê¸°\n",
        "    img_orig = cv.imread(image_file)\n",
        "\n",
        "    if img_orig is None:\n",
        "        print(f\"Could not read {image_file}.\")\n",
        "    else:\n",
        "        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜\n",
        "        gray = cv.cvtColor(img_orig, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Canny ì—ì§€ ê²€ì¶œ íŒŒë¼ë¯¸í„°\n",
        "        canny_threshold1 = 50\n",
        "        canny_threshold2 = 150\n",
        "        canny_aperture_size = 3\n",
        "\n",
        "        # Canny ì—ì§€ ê²€ì¶œ\n",
        "        edges = cv.Canny(gray, canny_threshold1, canny_threshold2, apertureSize=canny_aperture_size)\n",
        "\n",
        "        # HoughLinesP íŒŒë¼ë¯¸í„° (í™•ë¥ ì  í—ˆí”„ ë³€í™˜)\n",
        "        hough_rho = 1\n",
        "        hough_theta = np.pi / 180\n",
        "        hough_threshold = 100 # ì§ì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ êµì°¨ì  ìˆ˜\n",
        "        hough_min_line_length = 50 # ê²€ì¶œë  ìµœì†Œ ì§ì„  ê¸¸ì´\n",
        "        hough_max_line_gap = 10   # ì§ì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœëŒ€ ì§ì„  ê°„ê²©\n",
        "\n",
        "        # HoughLinesP ì ìš©\n",
        "        linesP = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold,\n",
        "                                minLineLength=hough_min_line_length,\n",
        "                                maxLineGap=hough_max_line_gap)\n",
        "\n",
        "        img_houghP = img_orig.copy()\n",
        "\n",
        "        # ê²€ì¶œëœ ì§ì„  ê·¸ë¦¬ê¸°\n",
        "        if linesP is not None:\n",
        "            print(f\"Detected {len(linesP)} lines using HoughLinesP.\")\n",
        "            for i in range(len(linesP)):\n",
        "                x1, y1, x2, y2 = linesP[i][0]\n",
        "                cv.line(img_houghP, (x1, y1), (x2, y2), (0, 255, 0), 2) # ì´ˆë¡ìƒ‰ ì„ \n",
        "\n",
        "        # ê²°ê³¼ ì‹œê°í™”\n",
        "        plt.figure(figsize=(18, 6))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title('Original Image')\n",
        "        plt.imshow(cv.cvtColor(img_orig, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title('Canny Edges')\n",
        "        plt.imshow(edges, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title('HoughLinesP Result')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\n--- Parameter Tuning Example ---\")\n",
        "        # íŒŒë¼ë¯¸í„° ë³€ê²½ ì˜ˆì‹œ: thresholdë¥¼ ë‚®ì¶° ë” ë§Žì€ ì§ì„  ê²€ì¶œ\n",
        "        hough_threshold_low = 50\n",
        "        linesP_low_thresh = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold_low,\n",
        "                                          minLineLength=hough_min_line_length,\n",
        "                                          maxLineGap=hough_max_line_gap)\n",
        "        img_houghP_low_thresh = img_orig.copy()\n",
        "        if linesP_low_thresh is not None:\n",
        "             print(f\"Detected {len(linesP_low_thresh)} lines with lower threshold ({hough_threshold_low}).\")\n",
        "             for i in range(len(linesP_low_thresh)):\n",
        "                x1, y1, x2, y2 = linesP_low_thresh[i][0]\n",
        "                cv.line(img_houghP_low_thresh, (x1, y1), (x2, y2), (255, 0, 0), 2) # íŒŒëž€ìƒ‰ ì„ \n",
        "\n",
        "        # íŒŒë¼ë¯¸í„° ë³€ê²½ ì˜ˆì‹œ: minLineLengthë¥¼ ëŠ˜ë ¤ ì§§ì€ ì§ì„  ì œì™¸\n",
        "        hough_min_line_length_long = 100\n",
        "        linesP_long_length = cv.HoughLinesP(edges, hough_rho, hough_theta, hough_threshold,\n",
        "                                           minLineLength=hough_min_line_length_long,\n",
        "                                           maxLineGap=hough_max_line_gap)\n",
        "        img_houghP_long_length = img_orig.copy()\n",
        "        if linesP_long_length is not None:\n",
        "             print(f\"Detected {len(linesP_long_length)} lines with longer minLineLength ({hough_min_line_length_long}).\")\n",
        "             for i in range(len(linesP_long_length)):\n",
        "                x1, y1, x2, y2 = linesP_long_length[i][0]\n",
        "                cv.line(img_houghP_long_length, (x1, y1), (x2, y2), (0, 0, 255), 2) # ë¹¨ê°„ìƒ‰ ì„ \n",
        "\n",
        "\n",
        "        plt.figure(figsize=(18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f'HoughLinesP (Threshold={hough_threshold})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f'HoughLinesP (Threshold={hough_threshold_low})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_low_thresh, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f'HoughLinesP (minLineLength={hough_min_line_length_long})')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_long_length, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Canny íŒŒë¼ë¯¸í„° ë³€ê²½ ì˜ˆì‹œ: ë†’ì€ ìž„ê³„ê°’ ì‚¬ìš©\n",
        "        canny_threshold1_high = 100\n",
        "        canny_threshold2_high = 200\n",
        "        edges_high_thresh = cv.Canny(gray, canny_threshold1_high, canny_threshold2_high, apertureSize=canny_aperture_size)\n",
        "\n",
        "        linesP_high_canny = cv.HoughLinesP(edges_high_thresh, hough_rho, hough_theta, hough_threshold,\n",
        "                                          minLineLength=hough_min_line_length,\n",
        "                                          maxLineGap=hough_max_line_gap)\n",
        "\n",
        "        img_houghP_high_canny = img_orig.copy()\n",
        "        if linesP_high_canny is not None:\n",
        "             print(f\"Detected {len(linesP_high_canny)} lines with higher Canny thresholds ({canny_threshold1_high}, {canny_threshold2_high}).\")\n",
        "             for i in range(len(linesP_high_canny)):\n",
        "                x1, y1, x2, y2 = linesP_high_canny[i][0]\n",
        "                cv.line(img_houghP_high_canny, (x1, y1), (x2, y2), (0, 255, 255), 2) # ë…¸ëž€ìƒ‰ ì„ \n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f'Canny Edges (Thresholds={canny_threshold1_high}, {canny_threshold2_high})')\n",
        "        plt.imshow(edges_high_thresh, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title('HoughLinesP after High Canny')\n",
        "        plt.imshow(cv.cvtColor(img_houghP_high_canny, cv.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "sstcM3IGgYV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AzWIkR96g-Gj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
