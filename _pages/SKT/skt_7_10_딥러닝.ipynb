{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOMSQLKXQo9b2rYgOEHDXsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_10_%EB%94%A5%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WdEsEqdu2uy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models # íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” ì´ë¯¸ì§€ ë¶„ì•¼ì— íŠ¹í™”ëœ ëª¨ë¸ë“¤ì„ ë¶ˆëŸ¬ì˜´\n",
        "# ë¯¸ë¦¬ í•™ìŠµë˜ì§€ ì•Šì€(ëœë¤ ì´ˆê¸°í™”) ResNet-50\n",
        "resnet50 = models.resnet50(pretrained=False)\n",
        "# pretrained=Falseë¡œ ì„¤ì •í•˜ë©´, ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ê°€ ë¬´ì‘ìœ„ë¡œ ì´ˆê¸°í™”ë˜ì–´ ìˆì–´,\n",
        "# ì¦‰, ì•„ì§ í•™ìŠµì´ ì „í˜€ ë˜ì§€ ì•Šì€ ìƒíƒœì´ë¯€ë¡œ, ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•™ìŠµ(train)í•´ì•¼ í•¨\n",
        "# ë¯¸ë¦¬ í•™ìŠµëœ(pretrained) ResNet-50\n",
        "resnet50_pretrained = models.resnet50(pretrained=True)\n",
        "# pretrained=Trueë¡œ ì„¤ì •í•˜ë©´, ImageNet ë°ì´í„°ì…‹(ëŒ€ëµ 100ë§Œ ì¥ ì´ìƒì˜ ì´ë¯¸ì§€, 1000ê°œ í´ë˜ìŠ¤)ìœ¼ë¡œ ë¯¸ë¦¬ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ë¶ˆëŸ¬ì˜´\n",
        "# ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´, ì ì€ ë°ì´í„°ë¡œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ì–»ì„ ê°€ëŠ¥ì„±ì´ ë†’ì•„ì§. ì´ë¯¸ â€˜ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ íŠ¹ì§•â€™ì„ ì˜ í•™ìŠµí•˜ê³  ìˆê¸° ë•Œë¬¸\n",
        "# ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ìˆ˜ì • (ì˜ˆ: í´ë˜ìŠ¤ ìˆ˜ 10ê°œë¡œ ë³€ê²½)\n",
        "num_features = resnet50.fc.in_features\n",
        "resnet50.fc = nn.Linear(num_features, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bottleneck ë¸”ë¡ ì§ì ‘ êµ¬í˜„í•˜ê¸°\n"
      ],
      "metadata": {
        "id": "zQyXb9IxvECx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn # ì‹ ê²½ë§ ë„¤íŠ¸ì›Œí¬(ë ˆì´ì–´, ì†ì‹¤ í•¨ìˆ˜ ë“±)ë¥¼ êµ¬ì„±í•˜ëŠ” ê¸°ë³¸ ëª¨ë“ˆ\n",
        "import torch.nn.functional as F # PyTorchì—ì„œ ìì£¼ ì“°ëŠ” í•¨ìˆ˜ë“¤(functional API). ì˜ˆ: F.relu, F.conv2d ë“±.\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4  # Bottleneck í™•ì¥ ë°°ìˆ˜ (ë§ˆì§€ë§‰ 1x1 Convë¥¼ í†µí•´ ì±„ë„ ìˆ˜ë¥¼ 4ë°°ë¡œ í™•ì¥í•œë‹¤ëŠ” ì„¤ì •ê°’)\n",
        "    # in_channels: ë¸”ë¡ì˜ ì…ë ¥ íŠ¹ì§• ë§µ(feature map)ì˜ ì±„ë„ ìˆ˜. (ì´ì „ ë¸”ë¡ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜)\n",
        "    # out_channels: 1x1ê³¼ 3x3ë¥¼ ì²˜ë¦¬í•œ í›„, ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œ í™•ì¥ë˜ê¸° ì „ ê¸°ë³¸ ì±„ë„ ìˆ˜.\n",
        "    # stride: í•©ì„±ê³±ì˜ ë³´í­. ë³´í†µì€ 1ì´ì§€ë§Œ, ë¸”ë¡ì— ë”°ë¼ 2ë¡œ ì„¤ì •ë˜ì–´ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ëŠ” ì—­í• ì„ í•  ìˆ˜ë„ ìˆìŒ.\n",
        "    # downsample: skip connectionì—ì„œ ì…ë ¥(identity)ì˜ ì°¨ì›ì„ ë§ì¶°ì£¼ê¸° ìœ„í•œ ì¶”ê°€ ëª¨ë“ˆ(í•©ì„±ê³±+BN ë“±)ì´ ë“¤ì–´ê°ˆ ìˆ˜ ìˆìŒ.\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        # ë¶€ëª¨ í´ë˜ìŠ¤(nn.Module)ì˜ ì´ˆê¸°í™” ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ í•„ìš”í•œ ë‚´ë¶€ êµ¬ì¡°ë¥¼ ì„¤ì •\n",
        "        # 1x1 Conv\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        # bias=False: í•©ì„±ê³± í›„ì— BatchNormì„ ë°”ë¡œ ì“°ë©´, í•©ì„±ê³±ì˜ biasê°€ ë¶ˆí•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•˜ì—¬ ìƒëµí•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels) # Batch Normalizationìœ¼ë¡œ í•™ìŠµì„ ì•ˆì •í™”í•˜ê³ , í•™ìŠµ ì†ë„ë¥¼ ë†’ì—¬ì¤€ë‹¤. ì™œ?\n",
        "        # 3x3 Conv\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        # 1x1 Conv (ì±„ë„ í™•ì¥, ì¶œë ¥ ì±„ë„ì„ out_channels * expansion(ê¸°ë³¸ 4ë°°)ë¡œ í™•ì¥)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
        "                               kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "        # ResNetì˜ Bottleneck êµ¬ì¡°ëŠ” ì´ë ‡ê²Œ ì²« ë²ˆì§¸ 1x1 Convì—ì„œ ì±„ë„ì„ ì¤„ì˜€ë‹¤ê°€(ì—°ì‚°ëŸ‰ ê°ì†Œ íš¨ê³¼),\n",
        "        # 3x3ì—ì„œ íŠ¹ì§• ì¶”ì¶œ í›„, ë§ˆì§€ë§‰ì— ë‹¤ì‹œ 1x1 Convë¡œ ì±„ë„ì„ í™•ì¥\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        # skip connectionì—ì„œ ì…ë ¥ xì™€ ì¶œë ¥ outì˜ ì°¨ì›(ì±„ë„ ìˆ˜ ë° ê°€ë¡œ/ì„¸ë¡œ í¬ê¸°)ì´ ë‹¤ë¥¼ ê²½ìš°,\n",
        "        # ì´ ê°’ì´ í•©ì„±ê³±+BN ëª¨ë“ˆ ë“±ì´ ë˜ì–´ identityë¥¼ ë³€í™˜í•´ ì¤Œ.\n",
        "        # (ì˜ˆë¥¼ ë“¤ì–´ ë¸”ë¡ì˜ stride=2ë¡œ í¬ê¸°ê°€ ì ˆë°˜ì´ ë˜ë©´, identityë„ í¬ê¸°ë¥¼ ë§ì¶°ì•¼ í•˜ê¸° ë•Œë¬¸)\n",
        "    def forward(self, x): # ë¸”ë¡ì—ì„œ ì…ë ¥ xê°€ ë“¤ì–´ì™”ì„ ë•Œ, ì–´ë–¤ ê³„ì‚°ì„ í• ì§€ ì •ì˜\n",
        "        identity = x # skip connectionì— ì‚¬ìš©í•  ì›ë³¸ ì…ë ¥ì„ identityë¼ëŠ” ë³€ìˆ˜ì— ì ì‹œ ì €ì¥\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        # downsampleì´ ìˆìœ¼ë©´ skip connectionì˜ ì°¨ì›ì„ ë§ì¶¤\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity # skip connection(ì”ì°¨ ì—°ê²°)\n",
        "        # ResNetì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” ì…ë ¥(x)ì„ ì¶œë ¥ì— ë”í•´ ëª¨ë¸ì´ ì”ì°¨(residual) ë§Œì„ í•™ìŠµí•˜ë„ë¡ í•œ ê²ƒ\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "DCOXOae3vKDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ Bottleneck ì½”ë“œëŠ” ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì±„ë„ì„ ì¤„ì˜€ë‹¤ê°€(conv1), íŠ¹ì§•ì„ ë½‘ê³ (conv2), ë‹¤ì‹œ ì±„ë„ì„ ëŠ˜ë¦° ë‹¤ìŒ(conv3), ë§ˆì§€ë§‰ì— ì›ë˜ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ë”í•´ì£¼ëŠ”(residual connection) ê³¼ì •ì„ ê±°ì¹˜ëŠ” ì‘ì€ ì‹ ê²½ë§ ë¸”ë¡ì„ ë§Œë“  *ê²ƒ*"
      ],
      "metadata": {
        "id": "9EW0NqTu-JUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ë‹¤ìŒì— Batch Normalization(ë°°ì¹˜ ì •ê·œí™”)ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ\n",
        ": ì‹ ê²½ë§ì€ ì—¬ëŸ¬ ì¸µ(ë ˆì´ì–´)ì„ ìŒ“ì•„ì„œ ë§Œë“­ë‹ˆë‹¤. ê° ì¸µì€ ì´ì „ ì¸µì˜ ì¶œë ¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ ê³„ì‚°ì„ í•©ë‹ˆë‹¤.\n",
        "í•™ìŠµ ê³¼ì •ì—ì„œ ê° ì¸µì˜ íŒŒë¼ë¯¸í„°(ê°€ì¤‘ì¹˜, í¸í–¥)ëŠ” ê³„ì† ë³€í•©ë‹ˆë‹¤.\n",
        "ë¬¸ì œëŠ” ì´ì „ ì¸µì˜ íŒŒë¼ë¯¸í„°ê°€ ë³€í•˜ë©´, í˜„ì¬ ì¸µìœ¼ë¡œ ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ ë°ì´í„°ì˜ ë¶„í¬(í‰ê· , ë¶„ì‚° ë“±)ê°€ ê³„ì† ë°”ë€Œê²Œ ë©ë‹ˆë‹¤. ì´ê²Œ ë§ˆì¹˜ ë°ì´í„°ì˜ 'ê³µë³€ëŸ‰'ì´ ë³€í•˜ëŠ” ê²ƒ ê°™ë‹¤ê³  í•´ì„œ 'ë‚´ë¶€ ê³µë³€ëŸ‰ ë³€í™”'ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.\n",
        "ì´ë ‡ê²Œ ì¸µë§ˆë‹¤ ì…ë ¥ ë°ì´í„°ì˜ ë¶„í¬ê°€ ê³„ì† ë°”ë€Œë©´, í˜„ì¬ ì¸µì€ ë§¤ë²ˆ ìƒˆë¡œìš´ ë¶„í¬ì— ë§ì¶°ì„œ í•™ìŠµì„ í•´ì•¼ í•˜ë¯€ë¡œ í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§€ê³ , í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§€ê±°ë‚˜ ì‹¬ì§€ì–´ ìˆ˜ë ´í•˜ì§€ ëª»í•˜ëŠ” ê²½ìš°ë„ ìƒê¹ë‹ˆë‹¤.\n",
        "\n",
        "--> ê²°ë¡ ì ìœ¼ë¡œ, ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ë‹¤ìŒì— Batch Normalizationì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì˜ ê²°ê³¼ë¥¼ ì•ˆì •í™”ì‹œì¼œì„œ, ë‹¤ìŒ ë ˆì´ì–´ê°€ ë” ì¼ê´€ëœ ë°ì´í„°ë¥¼ ë°›ì•„ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ ë•ê¸° ìœ„í•¨"
      ],
      "metadata": {
        "id": "t5ugic55-sq0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet-50 ì „ì²´ êµ¬ì¡° êµ¬í˜„"
      ],
      "metadata": {
        "id": "k-P5YTCh8HFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyResNet50(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(MyResNet50, self).__init__()\n",
        "        # ì´ˆê¸° Stem (ë³´í†µ ResNetì—ì„œëŠ” ì²« ë²ˆì§¸ 7x7 Conv + MaxPoolì„ ê±°ì³ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë¹ ë¥´ê²Œ ì¤„ì´ëŠ” ê³¼ì •ì„ Stemì´ë¼ê³  ë¶€ë¦„)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # inplanes(í˜„ì¬ ë¸”ë¡ì˜ ì…ë ¥ ì±„ë„ ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” ë³€ìˆ˜) ì„¤ì •\n",
        "        # ì²˜ìŒì—ëŠ” 64(Stemì˜ ì¶œë ¥ ì±„ë„)ë¡œ ì„¤ì •.\n",
        "        self.inplanes = 64\n",
        "        # ë ˆì´ì–´ êµ¬ì„±\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64,  3, stride=1)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
        "        self.layer3 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
        "        self.layer4 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
        "        # ë¶„ë¥˜ê¸°(Head) ë¶€ë¶„\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) # ì…ë ¥ Feature Mapì˜ í¬ê¸°ì™€ ìƒê´€ì—†ì´ (1, 1) í¬ê¸°ë¡œ ë§Œë“¦\n",
        "        self.fc = nn.Linear(512 * Bottleneck.expansion, num_classes)\n",
        "    def _make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        # stride!=1ì´ê±°ë‚˜, ì±„ë„ ìˆ˜ê°€ ë§ì§€ ì•Šìœ¼ë©´ ë‹¤ìš´ìƒ˜í”Œ êµ¬ì„±\n",
        "        # ë‹¤ìš´ìƒ˜í”Œ(downsample): strideê°€ 2ê°€ ë˜ë©´(ë˜ëŠ” ì±„ë„ ìˆ˜ê°€ ë‹¬ë¼ì§€ë©´),\n",
        "        # skip connectionì—ì„œ ì…ë ¥ xì™€ ì¶œë ¥ì˜ í¬ê¸°ë¥¼ ë§ì¶°ì¤˜ì•¼ í•¨\n",
        "        # downsampleì€ 1x1 Convì™€ BNìœ¼ë¡œ êµ¬ì„±ë˜ë©°, strideë¥¼ ì¡°ì ˆí•´ ê³µê°„ í¬ê¸°ë¥¼ ì¤„ì´ê±°ë‚˜, ì±„ë„ ìˆ˜ë¥¼ ë§ì¶°ì¤Œ\n",
        "        if stride != 1 or self.inplanes != out_channels * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, out_channels * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels * block.expansion)\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, out_channels, stride, downsample)) # ì…ë ¥ì´ ì¤„ì–´ë“¤ê±°ë‚˜ ì±„ë„ì´ ë³€ê²½ë˜ëŠ” ì§€ì \n",
        "        self.inplanes = out_channels * block.expansion # self.inplanesë¥¼ ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ ë¸”ë¡ì˜ ì¶œë ¥ ì±„ë„)\n",
        "        # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1 ì´ë¯€ë¡œ downsample ì—†ì´ ì´ì–´ì§\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, out_channels))\n",
        "        return nn.Sequential(*layers) # ë§ˆì§€ë§‰ì— nn.Sequential(*layers)ë¡œ ë¬¶ì–´ í•˜ë‚˜ì˜ í° ë ˆì´ì–´ë¡œ ë°˜í™˜\n",
        "    def forward(self, x):\n",
        "        # Stem\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "          # 4ê°œì˜ ë ˆì´ì–´\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # ë¶„ë¥˜\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "# ëª¨ë¸ ì˜ˆì‹œ ìƒì„± (ìµœì¢… ì¶œë ¥)\n",
        "model = MyResNet50(num_classes=1000)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "tuh704jbvQmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet Model\n"
      ],
      "metadata": {
        "id": "LX8lCNJORcdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.draw import disk, rectangle"
      ],
      "metadata": {
        "id": "IfmN9Rkn8Kva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate an image with shapes and labels\n",
        "def create_image_with_shapes_and_labels(image_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Creates a dummy RGB image with shapes (circle, rectangle) and corresponding labels.\n",
        "    Args:\n",
        "        image_size (tuple): Size of the image (H, W).\n",
        "    Returns:\n",
        "        torch.Tensor: RGB image tensor (3, H, W).\n",
        "        torch.Tensor: Label tensor (H, W) with classes 0 (background), 1 (circle), 2 (rectangle).\n",
        "    \"\"\"\n",
        "    image = np.zeros((*image_size, 3), dtype=np.float32)  # ë†’ì´ Ã— ë„ˆë¹„ Ã— RGB(3ì±„ë„)ë¡œ ëœ ê²€ì •ìƒ‰ ë¹ˆ ì´ë¯¸ì§€ ìƒì„±\n",
        "    label = np.zeros(image_size, dtype=np.int64)  # ê°™ì€ í¬ê¸°ì˜ ë¼ë²¨(ì •ë‹µ) ë°°ì—´ë„ ë§Œë“¦. ì´ˆê¸°ê°’ì€ ì „ë¶€ ë°°ê²½ (0)\n",
        "    # Draw a circle\n",
        "    rr, cc = disk((64, 64), 40)\n",
        "    image[rr, cc, 0] = 1.0  # Red circle\n",
        "    label[rr, cc] = 1  # Class 1: Circle\n",
        "    # Draw a rectangle\n",
        "    start = (120, 120)\n",
        "    extent = (50, 80)\n",
        "    rr, cc = rectangle(start=start, extent=extent)\n",
        "    image[rr, cc, 1] = 1.0  # Green rectangle\n",
        "    label[rr, cc] = 2  # Class 2: Rectangle\n",
        "    # Normalize to range [0, 1] - ì´ë¯¸ì§€ ì •ê·œí™”\n",
        "    image = (image - image.min()) / (image.max() - image.min())\n",
        "    return torch.tensor(image).permute(2, 0, 1), torch.tensor(label)  # (C, H, W), (H, W)"
      ],
      "metadata": {
        "id": "fI9XV-_LRg2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a basic double convolution block\n",
        "def double_conv(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False), # íŒ¨ë”©ì´ 1ì´ë¼ì„œ ì´ë¯¸ì§€ í¬ê¸°ëŠ” ìœ ì§€ë¨\n",
        "        nn.BatchNorm2d(out_channels),# ì¶œë ¥ ì±„ë„ë³„ë¡œ ì •ê·œí™”í•´ì¤Œ â†’ í•™ìŠµ ì•ˆì •í™”, ì†ë„ í–¥ìƒ\n",
        "\n",
        "\n",
        "        nn.ReLU(inplace=True),# ë¹„ì„ í˜•ì„± ë¶€ì—¬\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(inplace=True), # ì¶œë ¥ ì±„ë„ ìˆ˜ë¥¼ ìœ ì§€í•˜ë©´ì„œ í•œ ë²ˆ ë” íŠ¹ì§•ì„ ë½‘ì•„ëƒ„ (ì´ì¤‘ ì»¨ë³¼ë£¨ì…˜ìœ¼ë¡œ ë” ê¹Šì€ íŠ¹ì„± ì¶”ì¶œ ê°€ëŠ¥)\n",
        "    )\n"
      ],
      "metadata": {
        "id": "dmOlQarPRiOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê²°ê³¼ì ìœ¼ë¡œ ì´ ë¸”ë¡ì€?<br>\n",
        "3Ã—3 conv 2ë²ˆ â†’ receptive fieldê°€ ì»¤ì§ (ê°„ì ‘ì ìœ¼ë¡œ 5Ã—5 íš¨ê³¼)<br>\n",
        "\n",
        "BatchNorm + ReLU 2ë²ˆ â†’ ì•ˆì •ì ì´ê³  í‘œí˜„ë ¥ ìˆëŠ” íŠ¹ì§• ìƒì„±<br>\n",
        "\n",
        "U-Netì—ì„œ ë°˜ë³µ ì‚¬ìš©ë˜ë©°, Encoderì™€ Decoder ëª¨ë‘ì— í•µì‹¬ êµ¬ì„± ìš”ì†Œ<br>"
      ],
      "metadata": {
        "id": "X7Qc1PnooP1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the U-Net model\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        # Encoder - ì±„ë„ ìˆ˜ë¥¼ ì ì  ëŠ˜ë ¤ê°€ë©° ê¹Šì€ íŠ¹ì§• ì¶”ì¶œ\n",
        "        self.enc1 = double_conv(in_channels, 64)\n",
        "        self.enc2 = double_conv(64, 128)\n",
        "        self.enc3 = double_conv(128, 256)\n",
        "        self.enc4 = double_conv(256, 512)\n",
        "\n",
        "        # Bottleneck - ê°€ì¥ ê¹Šì€ íŠ¹ì§• ì¶”ì¶œ êµ¬ê°„ (ì´ë¯¸ì§€ í¬ê¸° ê°€ì¥ ì‘ìŒ)\n",
        "        # U-Net ì¤‘ì•™ - ì±„ë„ ìˆ˜ê°€ ê°€ì¥ í¼\n",
        "        self.bottleneck = double_conv(512, 1024)\n",
        "\n",
        "        # Decoder - Encoderì˜ ì¶œë ¥ì„ catìœ¼ë¡œ ì´ì–´ë¶™ì—¬ ê²½ê³„ ë³´ì¡´ + ì´í›„ ë‹¤ì‹œ double_convë¡œ ì •ì œ\n",
        "        # ConvTranspose2d: ì—…ìƒ˜í”Œë§ (í•´ìƒë„ 2ë°° ì¦ê°€)\n",
        "        # double_conv: í•©ì¹œ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì •ì œ (ì¡ìŒ ì œê±°, ê²½ê³„ ë³´ì¡´)\n",
        "        # torch.cat(enc, dec): ê°™ì€ ë ˆë²¨ì˜ ì¸ì½”ë” ì¶œë ¥ê³¼ í•©ì¹¨\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = double_conv(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = double_conv(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = double_conv(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = double_conv(128, 64)\n",
        "\n",
        "        # Output layer - ë§ˆì§€ë§‰ ì±„ë„ ìˆ˜ë¥¼ í´ë˜ìŠ¤ ìˆ˜ë¡œ ì¤„ì„ (ì˜ˆ: 3ê°œì˜ í´ë˜ìŠ¤ë¼ë©´ 3 ì±„ë„)\n",
        "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Encoder - Poolingìœ¼ë¡œ í•´ìƒë„ëŠ” ì¤„ì´ê³ , ì±„ë„ì€ ì¦ê°€\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(nn.MaxPool2d(kernel_size=2)(enc1))\n",
        "        enc3 = self.enc3(nn.MaxPool2d(kernel_size=2)(enc2))\n",
        "        enc4 = self.enc4(nn.MaxPool2d(kernel_size=2)(enc3))\n",
        "           # Bottleneck\n",
        "        bottleneck = self.bottleneck(nn.MaxPool2d(kernel_size=2)(enc4))\n",
        "\n",
        "        # Decoder - ì—…ìƒ˜í”Œë§ (ConvTranspose2d) â†’ ì¸ì½”ë”ì˜ ê°™ì€ ë‹¨ê³„ì™€ concat -> ê²½ê³„ ì •ë³´ ë³µì›, ë” ì„¸ë°€í•œ ê²°ê³¼ ìƒì„±\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat((enc4, dec4), dim=1) # upconv4: Transposed Convolutionì„ ì‚¬ìš©í•´ ì—…ìƒ˜í”Œë§ (í¬ê¸° 2ë°°ë¡œ í‚¤ì›€)\n",
        "        dec4 = self.dec4(dec4) # torch.cat: ì¸ì½”ë”(enc4)ì˜ ì¶œë ¥ê³¼ ë””ì½”ë”(dec4)ë¥¼ ì±„ë„ ë°©í–¥ìœ¼ë¡œ ì´ì–´ ë¶™ì„\n",
        "        dec3 = self.upconv3(dec4) # dec4: double_conv ë¸”ë¡ìœ¼ë¡œ íŠ¹ì§• ë‹¤ì‹œ ì •ë¦¬ (ê²½ê³„ ë³´ì¡´ + ì±„ë„ ì¶•ì†Œ)\n",
        "        dec3 = torch.cat((enc3, dec3), dim=1)\n",
        "        dec3 = self.dec3(dec3)\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat((enc2, dec2), dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat((enc1, dec1), dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "\n",
        "        # Output - í”½ì…€ë§ˆë‹¤ í´ë˜ìŠ¤ score ì˜ˆì¸¡ â†’ ìµœì¢… ë§ˆìŠ¤í¬ ê²°ê³¼\n",
        "        out = self.out_conv(dec1)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "XPI3QQ4qRjqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "â‘  Encoder (ì¸ì½”ë”)\tì´ë¯¸ì§€ë¥¼ ì ì  ì‘ê²Œ ë§Œë“¤ë©´ì„œ íŠ¹ì§• ì¶”ì¶œ <br>\n",
        "â‘¡ Bottleneck (ì¤‘ì•™ í†µë¡œ)\tì •ë³´ ì••ì¶• êµ¬ê°„ (íŠ¹ì§• ìš”ì•½) <br>\n",
        "â‘¢ Decoder (ë””ì½”ë”)\tì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì›ë˜ í¬ê¸°ë¡œ ë³µì› (í”½ì…€ë³„ ì˜ˆì¸¡) <br>\n",
        "\n",
        "### ğŸ”½ ë””ì½”ë” ë ˆì´ì–´ 4 (ê°€ì¥ ê¹Šì€ ì¸µë¶€í„° ë³µì› ì‹œì‘)\n",
        "dec4 = self.upconv4(bottleneck)  # 1024 â†’ 512 ì±„ë„ë¡œ ì—…ìƒ˜í”Œë§ (ê³µê°„ í¬ê¸° 2ë°°) <br>\n",
        "dec4 = torch.cat((enc4, dec4), dim=1)  # enc4ì™€ ì—°ê²°: ì±„ë„ 512 + 512 â†’ 1024 <br>\n",
        "dec4 = self.dec4(dec4)  # 1024 â†’ 512 ì±„ë„ë¡œ ë‹¤ì‹œ ì •ë¦¬<br>\n"
      ],
      "metadata": {
        "id": "yGoom0e1T4fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train_model(model, optimizer, criterion, num_epochs, input_image, ground_truth):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad() # ì´ì „ stepì—ì„œ ê³„ì‚°ëœ gradient ì´ˆê¸°í™”\n",
        "        # Forward pass\n",
        "        outputs = model(input_image) #ì´ë¯¸ì§€ ì…ë ¥ â†’ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë§ˆìŠ¤í¬ outputs ìƒì„±\n",
        "        loss = criterion(outputs, ground_truth.unsqueeze(0))  # ground_truthì— .unsqueeze(0)ì„ ì ìš©í•´ ë°°ì¹˜ ì°¨ì› (1, H, W)ë¡œ ë§Œë“¦\n",
        "        # Backward pass - ì†ì‹¤ì„ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¡œ ë¯¸ë¶„\n",
        "        loss.backward()\n",
        "        optimizer.step() # ê³„ì‚°ëœ gradientë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ í•œ ë²ˆ ì—…ë°ì´íŠ¸\n",
        "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "    print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "GLp3GgPERlUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of results\n",
        "def visualize_results(input_image, output_prediction, ground_truth=None):\n",
        "    # ë°°ì¹˜ ì°¨ì› ì œê±° (squeeze()) â†’ (3, H, W)\n",
        "    # ì±„ë„ ìˆœì„œ ë³€ê²½ (permute) â†’ (H, W, 3) â†’ ì´ë¯¸ì§€ë¡œ ë³´ì´ê²Œ í•¨\n",
        "    # cpu().numpy()ë¡œ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜\n",
        "    input_image = input_image.squeeze().permute(1, 2, 0).cpu().numpy()  # Convert to HWC\n",
        "\n",
        "    # argmaxë¡œ ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ -> ê° í”½ì…€ì— ëŒ€í•´ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ í´ë˜ìŠ¤ ë²ˆí˜¸ë§Œ ì¶”ì¶œ\n",
        "    output_prediction = torch.argmax(output_prediction, dim=1).squeeze().cpu().numpy()  # Convert to label map\n",
        "    if ground_truth is not None:\n",
        "        ground_truth = ground_truth.cpu().numpy()\n",
        "\n",
        "    # Plot the images - 1í–‰ 3ì—´ì˜ subplot ë§Œë“¤ê¸° (ì´ë¯¸ì§€, ì˜ˆì¸¡, ì •ë‹µ)\n",
        "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    # ì²« ë²ˆì§¸: ì›ë³¸ ì´ë¯¸ì§€ ë³´ì—¬ì£¼ê¸°\n",
        "    ax[0].imshow(input_image)\n",
        "    ax[0].set_title(\"Input Image\")\n",
        "    ax[0].axis(\"off\")\n",
        "\n",
        "    # ë‘ ë²ˆì§¸: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¶„í•  ê²°ê³¼ (í´ë˜ìŠ¤ë³„ ìƒ‰) ë³´ì—¬ì£¼ê¸°\n",
        "    ax[1].imshow(output_prediction, cmap=\"jet\")\n",
        "    ax[1].set_title(\"Model Prediction\")\n",
        "    ax[1].axis(\"off\")\n",
        "    if ground_truth is not None: # ì„¸ ë²ˆì§¸: ì •ë‹µ ë ˆì´ë¸”ì´ ìˆëŠ” ê²½ìš° ê°™ì´ ë¹„êµí•´ë³´ê¸°\n",
        "        ax[2].imshow(ground_truth, cmap=\"jet\")\n",
        "        ax[2].set_title(\"Ground Truth\")\n",
        "        ax[2].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LUQfiFNIRm79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create synthetic data\n",
        "    input_image, ground_truth = create_image_with_shapes_and_labels()\n",
        "    input_image = input_image.unsqueeze(0)  # Add batch dimension - PyTorchëŠ” (Batch, Channel, Height, Width) ìˆœì„œë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ unsqueeze(0)ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì› ì¶”ê°€ â†’ (1, 3, 256, 256)\n",
        "    ground_truth = ground_truth  # (H, W)\n",
        "    # Instantiate U-Net model\n",
        "    num_classes = 3  # Background, Circle, Rectangle\n",
        "    #model = UNet(in_channels=3, out_channels=num_classes)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # ì…ë ¥ ì±„ë„ì€ RGB(3), ì¶œë ¥ ì±„ë„ì€ í´ë˜ìŠ¤ ìˆ˜(ë°°ê²½, ì›, ì‚¬ê°í˜• = 3)\n",
        "    model = UNet(in_channels=3, out_channels=num_classes).to(device)\n",
        "    input_image = input_image.to(device)\n",
        "    ground_truth = ground_truth.to(device)\n",
        "\n",
        "    # Define loss and opt\n",
        "    criterion = nn.CrossEntropyLoss() # CrossEntropyLoss: ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì‚¬ìš©\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train the model\n",
        "    train_model(model, optimizer, criterion, num_epochs=10, input_image=input_image, ground_truth=ground_truth)\n",
        "\n",
        "    # Evaluate the model - .eval()ì€ ë“œë¡­ì•„ì›ƒ/ë°°ì¹˜ì •ê·œí™” ë“±ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output_prediction = model(input_image)\n",
        "    # Visualize results\n",
        "    visualize_results(input_image.squeeze(), output_prediction, ground_truth) #squeeze()ëŠ” (1, 3, H, W) â†’ (3, H, W)ë¡œ ë°°ì¹˜ ì°¨ì› ì œê±°"
      ],
      "metadata": {
        "id": "Qru-hNOMRxuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eWnLLTdknHDk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERYM778FRzTH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
