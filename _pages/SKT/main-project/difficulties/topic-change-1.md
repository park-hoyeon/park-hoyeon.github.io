---
title: "어려움 · 주제 변경 #1"
layout: single
permalink: /SKT/main-project/difficulties/topic-change-1/
author_profile: true
sidebar:
  nav: "sidebar-category"
  enabled: true
---

## 미세먼지 예측 → 시각장애인 터치스크린 도우미

> **결론 요약**  
> 초반에는 **Findust(24시간 후 미세먼지 예측 프로젝트)** 를 준비했으나,  
> 데이터 접근성과 서비스 임팩트 측면의 리스크가 커서 **시각장애인을 위한 터치스크린 도우미 Hover AI**로 전환했다.  
> 전환 근거는 아래와 같다:  
> ① 공공/민간 **CCTV 데이터 접근 제한**
> ② **동 단위 예측의 체감 가치 한계**  
> ③ **사용자 행동 변화 유도 어려움 ** - 서비스화 시키기 어려움


---

## 1) 원래 기획: Findust (미세먼지 24h 예측)

- **목표:** 기상·환경 데이터와 공공 CCTV 영상을 이용해서 **24시간 후 PM2.5/PM10 예측**   
- **문제점:**  
  - CCTV 데이터 확보 불가 → 데이터 가용성 한계  
  - 예측 정확도 ~70% 수준 → 실제 유저의 행동 변화를 설득하기 어려움  
  - 동 단위 예측 → 체감 임팩트 낮음  
  - 다수 팀이 유사 아이디어 선택 → 차별화 난이도↑
  - '24시간 후 미세먼지 수치 제공 서비스'로 사업화하기 어려움

---

## 2) 전환 판단 근거

- **데이터 리스크:** CCTV 등 핵심 데이터 접근 불가 → 장기 리스크  
- **서비스 설득력:** 낮은 정확도로는 실제 사용자 행동 유도 어려움  
- **차별성 부족:** 다수의 팀이 동일 솔루션 선택  
- **사용자 타깃:** 광범위 타깃 대신, **명확한 페르소나(시각장애인)** 필요하다고 생각함  

따라서, **데이터 확보가 용이하고**, **즉시성 높은 피드백 제공**이 가능한 문제로 피벗.

---

## 3) 새 방향: 시각장애인 터치스크린 도우미 **Hover AI**

### 문제 정의
- 시각장애인은 터치스크린 사용 시 **심리적 두려움**과 **실수 가능성**이 높음.  
- 가전제품 조작에서 **버튼 위치를 기억**하거나 **실수 없이 입력**하는 것이 큰 어려움.
- 요즘 시대의 가전제품은 대부분 버튼형 조작이 아니라 터치스크린(터치패널) 사용임. 

### 제안 솔루션
- **손가락이 닿기 전**, AI가 버튼을 인식하고 **음성으로 미리 안내**  
- **YOLO** 기반 손가락 위치 탐지 + **OCR(OpenCV/EasyOCR)** 기반 버튼 인식  
- 인식된 버튼을 **TTS(음성 안내)**로 사용자에게 전달 → 조작 실수 감소  

### 기술 구조
- Fingertip Detection (YOLO) → Optical Character Recognition (EasyOCR) → Voice 안내  
- Optical Character Recognition (EasyOCR) → LED Detection (OpenCV) → Voice 안내  

### 기대효과
- **사용자 편의성 강화:** 직관적인 음성 안내로 조작 부담 감소  
- **사회적 가치:** 디지털 접근성 향상, 시각장애인의 생활 자립도 향상  
- **기술적 확장성:** 다양한 가전제품 인터페이스 및 웨어러블 기기로 확장 가능  

---

## 4) 당시 어려움 & 해결방안

### 어려움
- **데이터 측면:** 미세먼지 예측에서는 데이터 접근성 문제 → 지속 불가능  
- **서비스 측면:** 예측 정확도와 체감 임팩트 부족으로 사용자 설득 한계  
- **기획 측면:** 타깃이 모호해 서비스 방향성이 불명확  

### 해결방안
- **명확한 타깃(시각장애인)**으로 문제 정의를 다시 세움  
- **데이터 접근성 용이한 영역**(가전제품 UI, 손가락 탐지, OCR)으로 전환  
- **즉시성 있는 서비스 가치**(음성 안내 → 두려움 해소)로 방향 재설정  




