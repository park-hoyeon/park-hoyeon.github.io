---
title: "Hover AI: 프로젝트 내용"
layout: single
permalink: /SKT/main-project/contents/
author_profile: true
sidebar:
  nav: "sidebar-category"
  enabled: true
---


# 조작모드
https://github.com/user-attachments/assets/816693b3-ccc9-481f-a690-d8a1ff196863


## 1) 손가락 탐지

### 주요 설명 내용
- YOLO의 빠르고 정확한 탐지 (초록색 점)
- 폴백 함수 동작 확인 (분홍색 점)

: 정확하고 끊김 없는 추적을 위해 이중 추적 시스템을 구현했다. 1차적으로는 YOLO 모델을 사용하여 실시간으로 손가락 끝의 위치를 탐지한다.
현재 초록색 점으로 시각화되는 모습이 YOLO 모델이 손가락 끝을 성공적으로 탐지했음을 의미한다. <br>
2차적으로는 포인트 트래킹을 활용한 폴백 함수를 구현했다. YOLO 모델만으로 손가락을 탐지한다면, 탐지에 실패하는 경우 이후 작업이 진행되지 않기 때문에 사용자 경험의 품질이 매우 떨어지게 된다.
이를 해결하기 위해 YOLO가 탐지한 손가락 끝의 주변 점들을 KLT 알고리즘을 사용하여 추적하고, YOLO의 탐지가 실패하였을 때 이 점들의 좌표 중앙값을 손가락 끝의 위치로 사용한다.



## 2-1) OCR 탐지 설명
- 전체 프레임 X, ROI 에서만 OCR 연산
- 매 프레임 X, 간격을 두고 OCR 연산
- 유사도 점수 기반 결과 보정

: 손가락끝 주변 ROI 영역에서만 OCR 연산을 진행한다. 여러 번의 실험을 통해, ROI 면적이 넓을 수록 연산량이 많아져 끊김 현상이 심해진다는 점을 확인할 수 있었으며 최종적으로 실시간성이 보장되는 한도 내에서 최대한의 ROI 면적 값을 설정했다. 
또한, OCR은 연산량 감소를 위해 일정한 시간 간격을 두고 실행된다. 간격은 기본적으로 1.5초이며, 손가락을 빠르게 움직이거나 텍스트 정보가 오래되어 불확실할 때 등 해당 영역의 정보를 빠르게 얻어올 필요가 있을 때는 0.6초의 짧은 간격으로 연산을 수행한다. 
OCR 정확도를 보완하기 위해서 사용한 방법은 유사도 점수를 기반으로 한 단어 보정이다. OCR의 결과를 미리 정의된 사전의 단어와 비교하고, 비슷하다고 판단되는 경우 해당 단어로 변환한다. 판단 기준은 편집 횟수를 기반으로 한 유사도 점수이다. 

## 2-2) 동적 OCR (카메라 이동)
- 특징점들의 움직임을 통해 만든 유사 변환 행렬을 적용하여 적은 연산 비용으로 정확도 높은 텍스트 이동

: 1.5초의 간격을 두고 OCR 연산을 수행하기 때문에, 각 연산 사이에 카메라가 이동한다면 인식한 텍스트들의 좌표를 그에 맞게 이동시킬 필요가 있다. 
이를 구현하기 위해 프레임으로부터 특징점들을 뽑고, 해당 점들의 움직임을 기존 텍스트 좌표에 적용함으로써, 새로운 프레임에서 OCR 연산을 하지 않고도 텍스트를 알맞은 위치로 옮길 수 있다.



## 2-3) 손가락이 특정 텍스트 위에 있는 모습
- OCR 결과는 좌표를 유지하여 손가락 아래의 텍스트를 잃지 않음

: 손가락이 텍스트를 가리는 경우에도 해당 텍스트를 음성으로 안내하기 위해 기존 OCR의 결과를 저장하고 있다. 이 때, 중복을 방지하기 위해 기존 결과와 새로운 결과를 병합하는 알고리즘을 고안했다. 

## 2-4) 정적 OCR (merging 확인)
- 새로운 OCR 결과와 Merging 하여 시간이 지날 수록 더 좋은 결과로 업데이트
- Merging은 자모 분해 후 유사도 점수로 결정하기 때문에 완벽하지 못한 OCR 정확도를 보정

: 새로운 OCR 결과의 위치가 기존 OCR 결과와 같다고 판단되는 경우, 두 텍스트를 비교하여 더 좋은 텍스트를 선택한다. 이 때 좋음의 기준은 사전 단어와의 유사도 점수와 OCR 신뢰도 점수를 사용한다. 이를 통해, 유저는 시간이 지날수록 더 정확한 정보를 제공받는다.  

---

# 보기모드
https://github.com/user-attachments/assets/1c0f7d83-c94d-426d-aaec-94b28643edab

- 일정 간격으로 프레임을 받아서 LED 위치를 탐지하고 OCR 결과와 매칭해 현재 상태 묘사

: 보기 모드에서는 5초 간격으로 프레임 받아와 현재 가전 제품의 상태를 설명하기 위하여 OCR과 OpenCV를 활용한 이미지 분석을 진행한다.
먼저, 프레임에 대한 OCR을 통하여 터치 패널에 어떤 텍스트가 있는 지 분석한다.
이후, 활성화된 LED의 위치를 탐지하기 위하여 프레임의 색공간을 BGR에서 HSV로 변환하고 명도 값을 활용하여 LED의 위치를 탐지한다.
탐지한 LED의 위치를 기반으로 앞서 OCR로 탐지한 텍스트 중 가장 가까운 텍스트와 매치하여 가전 제품이 어떤 상태인지를 음성으로 안내한다.
