{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM2oS8mmXA9vOzw0bgCSKuj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_08_OpenCV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  코너(Corner)란 무엇인가\n",
        ": 코너(Corner)는 영상에서 두 개 이상의 에지가 교차하거나, 픽셀 집합의 방향성이 갑자기 변하는 지점을 의미\n"
      ],
      "metadata": {
        "id": "jgcKu7FYUe-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python numpy matplotlib --quiet\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"OpenCV version:\", cv.__version__)\n"
      ],
      "metadata": {
        "id": "fJoSef73UnYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/samples/data/left01.jpg -O chessboard.jpg\n",
        "import os\n",
        "if not os.path.exists('chessboard.jpg'):\n",
        "    print(\"이미지 다운로드 실패. 직접 이미지를 업로드하세요.\")\n",
        "else:\n",
        "    print(\"chessboard.jpg 다운로드 완료.\")"
      ],
      "metadata": {
        "id": "dtD08YY0Uo8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = 'chessboard.jpg'\n",
        "img = cv.imread(img_path)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(f\"이미지를 불러올 수 없습니다: {img_path}\")\n",
        "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "plt.title('Original Chessboard')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZCW1WwnOUrDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "blockSize = 2  # 주변 윈도우 크기\n",
        "ksize = 3      # Sobel 마스크 크기\n",
        "k = 0.04       # Harris 파라미터\n",
        "harris_resp = cv.cornerHarris(img_gray, blockSize, ksize, k)\n",
        "# 응답값을 보기 좋게 정규화\n",
        "harris_norm = cv.normalize(harris_resp, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX)\n",
        "harris_norm = np.uint8(harris_norm)\n",
        "thresh = 130\n",
        "img_harris = img.copy()\n",
        "for y in range(harris_norm.shape[0]):\n",
        "    for x in range(harris_norm.shape[1]):\n",
        "        if harris_norm[y, x] > thresh:\n",
        "            cv.circle(img_harris, (x, y), 2, (0, 0, 255), -1)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cv.cvtColor(img_harris, cv.COLOR_BGR2RGB))\n",
        "plt.title('Harris Corner Detection')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XnIL5Of9Uti7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_corners = 100  # 검출할 코너 최대 개수\n",
        "quality_level = 0.01  # 코너 품질(0~1)\n",
        "min_distance = 10     # 코너들 간 최소 거리\n",
        "corners = cv.goodFeaturesToTrack(\n",
        "    img_gray,\n",
        "    maxCorners=max_corners,\n",
        "    qualityLevel=quality_level,\n",
        "    minDistance=min_distance,\n",
        "    blockSize=3,\n",
        "    useHarrisDetector=False\n",
        ")\n",
        "img_shi = img.copy()\n",
        "if corners is not None:\n",
        "    for pt in corners:\n",
        "        x, y = pt.ravel()\n",
        "        cv.circle(img_shi, (int(x), int(y)), 3, (0,255,0), -1)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(cv.cvtColor(img_shi, cv.COLOR_BGR2RGB))\n",
        "plt.title('Shi-Tomasi Corner Detection')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1pVpFqofVDK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 이미지를 약간 변형(회전+스케일+이동)하여 두 번째 이미지 생성\n",
        "rows, cols = img_gray.shape\n",
        "M = cv.getRotationMatrix2D((cols/2, rows/2), 5, 1.05)  # 중심, 각도=5, 스케일=1.05\n",
        "M[0,2] += 10  # x방향 이동\n",
        "M[1,2] += 15  # y방향 이동\n",
        "img2 = cv.warpAffine(img, M, (cols, rows))\n",
        "img2_gray = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "plt.title('Frame 1')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(cv.cvtColor(img2, cv.COLOR_BGR2RGB))\n",
        "plt.title('Frame 2 (transformed)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "949cuIYFVhT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lucas-Kanade 옵티컬 플로우 (Pyramidal)"
      ],
      "metadata": {
        "id": "GhArhw4LVmmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_params = dict(\n",
        "    maxCorners = 100,\n",
        "    qualityLevel = 0.01,\n",
        "    minDistance = 10,\n",
        "    blockSize = 3\n",
        ")\n",
        "lk_params = dict(\n",
        "    winSize = (15,15),\n",
        "    maxLevel = 2,\n",
        "    criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        ")\n",
        "# 첫 번째 프레임의 코너 검출\n",
        "p0 = cv.goodFeaturesToTrack(img_gray, mask=None, **feature_params)\n",
        "# calcOpticalFlowPyrLK: (img_gray -> img2_gray)\n",
        "p1, st, err = cv.calcOpticalFlowPyrLK(img_gray, img2_gray, p0, None, **lk_params)\n",
        "# st=1인 점만 추출(추적 성공)\n",
        "good_new = p1[st==1]\n",
        "good_old = p0[st==1]\n",
        "img_flow = img2.copy()\n",
        "for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "    x_new, y_new = new.ravel()\n",
        "    x_old, y_old = old.ravel()\n",
        "    cv.circle(img_flow, (int(x_new), int(y_new)), 5, (0,255,0), -1)\n",
        "    cv.line(img_flow, (int(x_old), int(y_old)), (int(x_new), int(y_new)), (0,0,255), 2)\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.imshow(cv.cvtColor(img_flow, cv.COLOR_BGR2RGB))\n",
        "plt.title('Optical Flow (Frame1 -> Frame2)')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "To3YEFriVjmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 종합실습\n",
        "## 동영상 예시 코\n"
      ],
      "metadata": {
        "id": "qlxGj31ZVsNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import gdown\n",
        "from google.colab.patches import cv2_imshow\n",
        "# 비디오 URL 및 로컬 저장 경로 설정\n",
        "video_url = \"https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\"\n",
        "local_video_path = \"slow_traffic_small.mp4\"\n",
        "output_video_path = \"optical_flow_output.mp4\" # 저장할 비디오 파일 경로\n",
        "# gdown을 사용하여 비디오 파일 다운로드\n",
        "gdown.download(video_url, local_video_path, quiet=False)\n",
        "# 비디오 캡처 객체 생성\n",
        "cap = cv.VideoCapture(local_video_path)\n",
        "if not cap.isOpened():\n",
        "    print(\"비디오 파일을 열 수 없습니다.\")\n",
        "else:\n",
        "    # Lucas-Kanade 광학 흐름 파라미터 설정\n",
        "    lk_params = dict(\n",
        "        winSize=(15, 15),\n",
        "        maxLevel=2,\n",
        "        criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        "    )\n",
        "    # 첫 번째 프레임 읽기\n",
        "    ret, old_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"첫 프레임을 읽을 수 없습니다.\")\n",
        "    else:\n",
        "        old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
        "        # Shi-Tomasi 코너 검출 파라미터 설정\n",
        "        feature_params = dict(\n",
        "            maxCorners=100,\n",
        "            qualityLevel=0.01,\n",
        "            minDistance=10,\n",
        "            blockSize=3\n",
        "        )\n",
        "        p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "        # 비디오 저장을 위한 VideoWriter 객체 설정\n",
        "        fourcc = cv.VideoWriter_fourcc(*'mp4v') # 코덱 설정 (mp4)\n",
        "        fps = int(cap.get(cv.CAP_PROP_FPS)) # 원본 비디오의 FPS 가져오기\n",
        "        width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
        "        out = cv.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "        print(f\"원본 비디오 FPS: {fps}\")\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "            # Lucas-Kanade Optical Flow 계산\n",
        "            p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "            if p1 is not None:\n",
        "                good_new = p1[st == 1]\n",
        "                good_old = p0[st == 1]\n",
        "                # 시각화용 마스크 생성 및 업데이트\n",
        "                mask = np.zeros_like(frame) # 각 프레임마다 마스크 초기화\n",
        "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "                    x_new, y_new = new.ravel()\n",
        "                    x_old, y_old = old.ravel()\n",
        "                    cv.line(mask, (int(x_new), int(y_new)), (int(x_old), int(y_old)), (0, 255, 0), 2)\n",
        "                    cv.circle(frame, (int(x_new), int(y_new)), 5, (0, 0, 255), -1)\n",
        "                img_flow = cv.add(frame, mask)\n",
        "                out.write(img_flow) # 처리된 프레임을 비디오 파일에 쓰기\n",
        "\n",
        "            # 다음 프레임을 위해 현재 프레임과 추적된 좋은 특징점 업데이트\n",
        "            old_gray = frame_gray.copy()\n",
        "            if p1 is not None: # p1이 None이 아닐 때만 good_new를 업데이트\n",
        "                 p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "        # 비디오 처리 완료 후 객체 해제\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f\"처리된 비디오가 '{output_video_path}'로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "sqzpqeyyVp59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c66zJX1cV0_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ec16c8b"
      },
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import gdown\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# 비디오 URL 및 로컬 저장 경로 설정\n",
        "video_url = \"https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4\"\n",
        "local_video_path = \"slow_traffic_small.mp4\"\n",
        "\n",
        "# gdown을 사용하여 비디오 파일 다운로드\n",
        "gdown.download(video_url, local_video_path, quiet=False)\n",
        "\n",
        "# 비디오 캡처 객체 생성\n",
        "cap = cv.VideoCapture(local_video_path)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"비디오 파일을 열 수 없습니다.\")\n",
        "else:\n",
        "    # Lucas-Kanade Optical Flow 파라미터\n",
        "    lk_params = dict(\n",
        "        winSize=(15, 15),\n",
        "        maxLevel=2,\n",
        "        criteria=(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03)\n",
        "    )\n",
        "\n",
        "    # 첫 번째 프레임 읽기\n",
        "    ret, old_frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"첫 프레임을 읽을 수 없습니다.\")\n",
        "    else:\n",
        "        old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Shi-Tomasi 코너 검출 파라미터\n",
        "        feature_params = dict(\n",
        "            maxCorners=100,\n",
        "            qualityLevel=0.01,\n",
        "            minDistance=10,\n",
        "            blockSize=3\n",
        "        )\n",
        "        p0 = cv.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "\n",
        "        # 시각화용 마스크 생성\n",
        "        mask = np.zeros_like(old_frame)\n",
        "\n",
        "        frame_count = 0  # 너무 많은 프레임 출력 방지용\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret or frame_count > 100:\n",
        "                break\n",
        "\n",
        "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Lucas-Kanade Optical Flow 계산\n",
        "            p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
        "\n",
        "            if p1 is not None:\n",
        "                good_new = p1[st == 1]\n",
        "                good_old = p0[st == 1]\n",
        "\n",
        "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "                    x_new, y_new = new.ravel()\n",
        "                    x_old, y_old = old.ravel()\n",
        "                    cv.line(mask, (int(x_new), int(y_new)), (int(x_old), int(y_old)), (0, 255, 0), 2)\n",
        "                    cv.circle(frame, (int(x_new), int(y_new)), 5, (0, 0, 255), -1)\n",
        "\n",
        "                img_flow = cv.add(frame, mask)\n",
        "                cv2_imshow(img_flow)\n",
        "\n",
        "            # 상태 갱신\n",
        "            old_gray = frame_gray.copy()\n",
        "            p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "            frame_count += 1  # 출력 제한을 위한 카운트 증가\n",
        "\n",
        "        cap.release()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python opencv-contrib-python numpy matplotlib --quiet\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(\"OpenCV version:\", cv.__version__)"
      ],
      "metadata": {
        "id": "AYyEOi5NcYAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://docs.opencv.org/4.x/water_coins.jpg -O coins.png\n",
        "import os\n",
        "if not os.path.exists('coins.png'):\n",
        "    print('coins.png 다운로드 실패. 다른 이미지를 직접 업로드하세요.')\n",
        "else:\n",
        "    print('coins.png 다운로드 완료.')"
      ],
      "metadata": {
        "id": "rDC7k-Ezhd33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"coins.png\"\n",
        "img = cv.imread(img_path)\n",
        "if img is None:\n",
        "    raise FileNotFoundError(\"이미지를 불러올 수 없습니다.\")\n",
        "# BGR -> RGB\n",
        "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "# 픽셀을 2차원으로 펼치기\n",
        "Z = img_rgb.reshape((-1, 3))\n",
        "Z = np.float32(Z)\n",
        "# K-means 설정\n",
        "K = 3\n",
        "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
        "attempts = 10  # 다른 초기값 시도 횟수\n",
        "flags = cv.KMEANS_PP_CENTERS  # K-means++ 초기화\n",
        "compactness, labels, centers = cv.kmeans(Z, K, None, criteria, attempts, flags)\n",
        "\n",
        "# centers: (K, 3) 형태의 클러스터 중심\n",
        "centers = np.uint8(centers)\n",
        "segmented = centers[labels.flatten()]\n",
        "segmented_img = segmented.reshape(img_rgb.shape)\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_rgb)\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(segmented_img)\n",
        "plt.title('K-means K=3')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GwNb96z5hfU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from cv2.ximgproc import segmentation as xseg\n",
        "# 1. 세그먼테이션 객체 생성\n",
        "sigma = 0.5\n",
        "k = 300\n",
        "min_size = 100\n",
        "graph_seg = xseg.createGraphSegmentation(sigma=sigma, k=k, min_size=min_size)\n",
        "# 2. 이미지 처리\n",
        "labels = graph_seg.processImage(img)  # BGR 이미지 입력\n",
        "num_segments = labels.max() + 1\n",
        "print(\"Number of segments:\", num_segments)\n",
        "# 3. 세그먼트 별 랜덤 컬러로 시각화\n",
        "seg_img = np.zeros_like(img)\n",
        "colors = [np.random.randint(0,255,3, dtype=np.uint8) for _ in range(num_segments)]\n",
        "for seg_val in range(num_segments):\n",
        "    seg_img[labels == seg_val] = colors[seg_val]\n",
        "seg_img_rgb = cv.cvtColor(seg_img, cv.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "plt.title('Original')\n",
        "plt.axis('off')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(seg_img_rgb)\n",
        "plt.title('Graph-based Segmentation')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AoySWOp4higz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "# 1. 이진화 (Otsu + Inverse)\n",
        "ret, thresh = cv.threshold(gray, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
        "# 2. 노이즈 제거 -> 침식/팽창(열림)\n",
        "kernel = np.ones((3,3), np.uint8)\n",
        "opening = cv.morphologyEx(thresh, cv.MORPH_OPEN, kernel, iterations=2)\n",
        "# 3. 확실한 배경\n",
        "sure_bg = cv.dilate(opening, kernel, iterations=3)\n",
        "# 4. 확실한 전경 -> Distance Transform 후, 임계값\n",
        "dist_transform = cv.distanceTransform(opening, cv.DIST_L2, 5)\n",
        "ret, sure_fg = cv.threshold(dist_transform, 0.7*dist_transform.max(), 255, 0)\n",
        "sure_fg = np.uint8(sure_fg)\n",
        "# 5. 불확실 영역\n",
        "unknown = cv.subtract(sure_bg, sure_fg)\n",
        "# 6. 전경을 Connected Components로 라벨\n",
        "ret, markers = cv.connectedComponents(sure_fg)\n",
        "markers = markers + 1  # 배경을 1, 나머지는 2,3,...\n",
        "markers[unknown==255] = 0\n",
        "# 7. Watershed\n",
        "watershed_img = img.copy()\n",
        "markers = cv.watershed(watershed_img, markers)\n",
        "watershed_img[markers == -1] = [0,0,255]  # 경계 표시\n",
        "# 시각화\n",
        "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
        "axs[0].imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
        "axs[0].set_title('Original')\n",
        "axs[0].axis('off')\n",
        "axs[1].imshow(thresh, cmap='gray')\n",
        "axs[1].set_title('Threshold')\n",
        "axs[1].axis('off')\n",
        "axs[2].imshow(cv.cvtColor(watershed_img, cv.COLOR_BGR2RGB))\n",
        "axs[2].set_title('Watershed Result')\n",
        "axs[2].axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "160zC5Euhkhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenCV와 KNN을 활용한 이미지 분류"
      ],
      "metadata": {
        "id": "nCfr916Kyyv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless\n"
      ],
      "metadata": {
        "id": "MJL2nLeMj8KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "print(\"OpenCV version:\", cv2.__version__)"
      ],
      "metadata": {
        "id": "h4PK8CIWzErQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = cv2.ml.KNearest_create()\n",
        "\n",
        "# knn 모델 훈련 (trainData와 trainLabels는 이전에 준비되어야 합니다)\n",
        "# 아래 Agt5TXaZzHcg 셀에서 train과 train_labels를 사용합니다.\n",
        "# Agt5TXaZzHcg 셀이 먼저 실행되어 train과 train_labels가 정의되어 있어야 합니다.\n",
        "if 'train' not in globals() or 'train_labels' not in globals():\n",
        "    print(\"오류: 'train' 또는 'train_labels' 변수가 정의되지 않았습니다.\")\n",
        "    print(\"이전 셀(Agt5TXaZzHcg)을 먼저 실행하여 훈련 데이터를 로드하고 준비해주세요.\")\n",
        "else:\n",
        "    trainData = train # Agt5TXaZzHcg 셀에서 정의된 train 사용\n",
        "    trainLabels = train_labels # Agt5TXaZzHcg 셀에서 정의된 train_labels 사용\n",
        "\n",
        "    knn.train(trainData, cv2.ml.ROW_SAMPLE, trainLabels)\n",
        "\n",
        "    # 분류할 샘플 데이터 준비\n",
        "    # 여기서는 digits.png 이미지의 일부를 테스트 데이터로 사용합니다.\n",
        "    # 실제 사용 시에는 분류하고자 하는 새로운 이미지 데이터로 대체해야 합니다.\n",
        "\n",
        "    # img_digits 변수가 정의되었는지 확인\n",
        "    if 'img_digits' not in globals() or img_digits is None:\n",
        "         print(\"오류: 'img_digits' 변수가 정의되지 않았거나 이미지를 불러오지 못했습니다.\")\n",
        "         print(\"이전 셀(Agt5TXaZzHcg)을 먼저 실행하여 digits.png 이미지를 로드해주세요.\")\n",
        "    else:\n",
        "        # digits.png 이미지에서 일부 셀을 테스트 데이터로 사용 (예: 각 숫자 500개 중 마지막 100개)\n",
        "        test_cells = [np.hsplit(row, 100)[40:50] for row in np.vsplit(img_digits, 50)] # 각 숫자당 10개씩 사용\n",
        "        test_x = np.array(test_cells) # shape (50, 10, 20, 20)\n",
        "        sampleData = test_x.reshape(-1, 400).astype(np.float32) # (50*10, 400) = (500, 400)\n",
        "\n",
        "        # 테스트 데이터에 대한 실제 레이블 (검증용)\n",
        "        test_labels = np.repeat(np.arange(10), 10)[:, np.newaxis] # (500, 1)\n",
        "\n",
        "        k = 5 # 가장 가까운 k개의 이웃 사용\n",
        "\n",
        "        # k개의 가장 가까운 이웃 찾기\n",
        "        # ret: 결과 레이블, result: 예측된 레이블, neighbours: 가장 가까운 이웃의 레이블, dist: 이웃까지의 거리\n",
        "        ret, result, neighbours, dist = knn.findNearest(sampleData, k)\n",
        "\n",
        "        # 예측 결과 평가 (테스트 레이블이 있는 경우)\n",
        "        if test_labels is not None:\n",
        "            # 예측 결과와 실제 레이블 비교\n",
        "            matches = result == test_labels\n",
        "            correct = np.count_nonzero(matches)\n",
        "            accuracy = correct * 100.0 / result.size\n",
        "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        # 결과 출력 (샘플 데이터가 비어있지 않으므로 이제 출력 가능)\n",
        "        # print(\"Result:\", result) # 예측된 레이블\n",
        "        # print(\"Neighbours:\", neighbours) # 가장 가까운 이웃의 레이블\n",
        "        # print(\"Distance:\", dist) # 이웃까지의 거리"
      ],
      "metadata": {
        "id": "e6Bbh3t6zGCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 digits.png 로드 (그레이스케일)\n",
        "# wget으로 파일 다운로드\n",
        "url = \"https://raw.githubusercontent.com/npinto/opencv/master/samples/python2/data/digits.png\"\n",
        "output_file = \"digits.png\"\n",
        "os.system(f\"wget -O {output_file} {url}\")\n",
        "# OpenCV로 이미지 읽기\n",
        "img_digits = cv2.imread(output_file, cv2.IMREAD_GRAYSCALE)\n",
        "if img_digits is None:\n",
        "    print(\"digits.png를 불러올 수 없습니다.\")\n",
        "else:\n",
        "    print(f\"Original Image Shape: {img_digits.shape}\")\n",
        "    plt.imshow(img_digits, cmap='gray')\n",
        "    plt.title(\"Original Digits Image\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    # 3.2 이미지 분할\n",
        "    # 세로 50줄, 가로 100줄로\n",
        "    cells = [np.hsplit(row, 100) for row in np.vsplit(img_digits, 50)]\n",
        "    x = np.array(cells)  # shape (50, 100, 20, 20)\n",
        "    # 각 셀(20x20)을 1x400 벡터로 변환\n",
        "    train = x.reshape(-1, 400).astype(np.float32)  # (50*100, 400)\n",
        "    # 레이블 생성 (0~9 각각 500번 = 5000)\n",
        "    k = np.arange(10)\n",
        "    train_labels = np.repeat(k, 500)[:, np.newaxis]\n",
        "      # 데이터 저장\n",
        "    np.savez(\"trained_opencv.npz\", train=train, train_labels=train_labels)\n",
        "    print(\"Training data saved.\")"
      ],
      "metadata": {
        "id": "Agt5TXaZzHcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 이미지 전처리 함수 (OpenCV 활용)\n"
      ],
      "metadata": {
        "id": "AR1QNjafzbAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_colab(image_path):\n",
        "    \"\"\"\n",
        "    테스트 이미지(예: 숫자 1장) 전처리:\n",
        "    1) GRAYSCALE 로드\n",
        "    2) 이진화\n",
        "    3) 외곽선 표시 (시각화용)\n",
        "    4) 20x20 크기로 리사이즈\n",
        "    5) 1x400 형태로 벡터화 (float32)\n",
        "    \"\"\"\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found at {image_path}\")\n",
        "    # 이진화\n",
        "    _, binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
        "    # 외곽선 검출\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    img_with_contours = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.drawContours(img_with_contours, contours, -1, (0,255,0), 2)\n",
        "    # 크기 조정(20x20)\n",
        "    resized = cv2.resize(binary, (20, 20))\n",
        "    # 시각화 (Colab)\n",
        "    print(\"[Original Grayscale]\")\n",
        "    cv2_imshow(img)\n",
        "    print(\"[Binary Inverted]\")\n",
        "    cv2_imshow(binary)\n",
        "    print(\"[Contours Drawn]\")\n",
        "    cv2_imshow(img_with_contours)\n",
        "    print(\"[Resized 20x20]\")\n",
        "    cv2_imshow(resized)\n",
        "    # reshape(1, 400), float32\n",
        "    vector_400 = resized.reshape(-1, 400).astype(np.float32)\n",
        "    return vector_400\n"
      ],
      "metadata": {
        "id": "7H1GS4KLzcoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_CG6MgQazfQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  5. KNN 알고리즘 및 테스트\n"
      ],
      "metadata": {
        "id": "bQumtIaGzgYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_train_and_test_colab(train_data, train_labels, test_image_path, k=3):\n",
        "    # 1) KNN 모델 생성\n",
        "    knn = cv2.ml.KNearest_create()\n",
        "    # 2) 모델 학습\n",
        "    # train_data.shape: (5000, 400), train_labels.shape: (5000,1)\n",
        "    knn.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)\n",
        "    # 3) 테스트 이미지 전처리\n",
        "    test_vector = preprocess_image_colab(test_image_path)  # (1, 400)\n",
        "    # 4) 예측\n",
        "    ret, result, neighbours, dist = knn.findNearest(test_vector, k)\n",
        "    predicted_label = int(result[0][0])\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "    print(f\"Neighbours: {neighbours}\")\n",
        "    print(f\"Distances: {dist}\")\n",
        "    return predicted_label, neighbours, dist\n"
      ],
      "metadata": {
        "id": "js87OtoyzhsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  5.1 학습 데이터 로드\n"
      ],
      "metadata": {
        "id": "vPUfq7TDz0kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 로드\n",
        "train_data = None\n",
        "train_labels = None\n",
        "try:\n",
        "    with np.load('trained_opencv.npz') as data:\n",
        "        train_data = data['train']\n",
        "        train_labels = data['train_labels']\n",
        "    print(f\"train_data.shape = {train_data.shape}, train_labels.shape = {train_labels.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"trained_opencv.npz 파일이 존재하지 않습니다. 앞 셀을 실행해주세요.\")\n",
        "\n",
        "    # 테스트 이미지 (예: test_digit_3.png) - digits.png의 한 셀을 잘라 저장했다고 가정\n",
        "test_image_path = 'test_digit_3.png'  # Colab 환경에 업로드된 테스트 이미지\n",
        "pred_label, neighbours, distances = None, None, None\n",
        "if train_data is not None and train_labels is not None:\n",
        "    pred_label, neighbours, distances = knn_train_and_test_colab(\n",
        "        train_data, train_labels, test_image_path, k=5\n",
        "    )\n"
      ],
      "metadata": {
        "id": "5ZliygjLzj3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 이미지 (예: test_digit_3.png) - digits.png의 한 셀을 잘라 저장했다고 가정\n",
        "test_image_path = '귀여움.jpg'  # Colab 환경에 업로드된 테스트 이미지\n",
        "pred_label, neighbours, distances = None, None, None\n",
        "if train_data is not None and train_labels is not None:\n",
        "    pred_label, neighbours, distances = knn_train_and_test_colab(\n",
        "        train_data, train_labels, test_image_path, k=5\n",
        "    )"
      ],
      "metadata": {
        "id": "nOzq_ew_z37T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 결과 시각화 (예측 결과 표시)"
      ],
      "metadata": {
        "id": "YQWK6tJg0RT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_result_colab(image_path, predicted_label):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found at {image_path}\")\n",
        "    output = img.copy()\n",
        "    text = f\"Predicted: {predicted_label}\"\n",
        "    cv2.putText(\n",
        "        output, text, (10,50),\n",
        "        cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
        "        (0,255,0), 2\n",
        "    )\n",
        "    print(\"[Test Image with Prediction]\")\n",
        "    cv2_imshow(output)\n"
      ],
      "metadata": {
        "id": "H3VdYm8s0T0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 시각화\n",
        "if pred_label is not None:\n",
        "    visualize_result_colab(test_image_path, pred_label)"
      ],
      "metadata": {
        "id": "VugaDEhD0XGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  7.1 과제 결과 예시 코드: K 값 루프\n"
      ],
      "metadata": {
        "id": "e9ApX8Z00aZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_knn_with_different_k(train_data, train_labels, test_image_data, k_values=[1,3,5,7,9]):\n",
        "    \"\"\"\n",
        "    여러 테스트 이미지 데이터에 대해 KNN 분류를 수행하고 결과를 반환합니다.\n",
        "    test_image_data는 (이미지 벡터, 실제 라벨) 튜플의 리스트입니다.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    for k_ in k_values:\n",
        "        print(f\"\\n=== K={k_} ===\")\n",
        "        knn = cv2.ml.KNearest_create()\n",
        "        knn.train(train_data, cv2.ml.ROW_SAMPLE, train_labels)\n",
        "        pred_labels = []\n",
        "        correct_count = 0\n",
        "        total_count = len(test_image_data)\n",
        "\n",
        "        for test_vec, true_label in test_image_data:\n",
        "            # preprocess_image_colab 함수는 파일 경로를 받으므로,\n",
        "            # 여기서는 이미 전처리된 벡터를 사용하도록 로직 변경\n",
        "            ret, result, neigh, dist = knn.findNearest(test_vec, k_)\n",
        "            plabel = int(result[0][0])\n",
        "            pred_labels.append(plabel)\n",
        "            # print(f\"True Label={true_label}, Predicted={plabel}\") # 개별 결과 출력 (선택 사항)\n",
        "\n",
        "            if plabel == true_label:\n",
        "                correct_count += 1\n",
        "\n",
        "        accuracy = (correct_count / total_count) * 100 if total_count > 0 else 0\n",
        "        print(f\"Accuracy for K={k_}: {accuracy:.2f}% ({correct_count}/{total_count})\")\n",
        "        results[k_] = {'predicted_labels': pred_labels, 'accuracy': accuracy}\n",
        "\n",
        "    return results\n",
        "\n",
        "## 예시 사용\n",
        "# digits.png 이미지에서 테스트 데이터 추출\n",
        "# img_digits 변수가 Agt5TXaZzHcg 셀에서 로드되었다고 가정\n",
        "if 'img_digits' in globals() and img_digits is not None:\n",
        "    # 각 숫자(0-9) 당 마지막 10개 샘플을 테스트 데이터로 사용\n",
        "    # cells = [np.hsplit(row, 100) for row in np.vsplit(img_digits, 50)]\n",
        "    # test_cells_raw = [cells[i][-10:] for i in range(50)] # 각 row의 마지막 10개\n",
        "    # test_cells_flat = [item for sublist in test_cells_raw for item in sublist] # flatten list\n",
        "    # test_x_raw = np.array(test_cells_flat) # shape (500, 20, 20)\n",
        "\n",
        "    # 좀 더 간단하게, train 데이터에서 일부를 test 데이터로 분리 (예: 마지막 1000개)\n",
        "    # 전체 5000개 데이터 중 마지막 1000개 (각 숫자당 100개씩)를 테스트 데이터로 사용\n",
        "    train_data_subset = train[-1000:]\n",
        "    train_labels_subset = train_labels[-1000:]\n",
        "\n",
        "    # 테스트 이미지 데이터 형식: (이미지 벡터, 실제 라벨) 튜플의 리스트\n",
        "    test_imgs_data = [(train_data_subset[i].reshape(1, -1), int(train_labels_subset[i][0])) for i in range(len(train_data_subset))]\n",
        "\n",
        "\n",
        "    if train_data is not None and train_labels is not None:\n",
        "        # k=1,3,5 등 루프\n",
        "        _results = test_knn_with_different_k(train_data, train_labels, test_imgs_data, k_values=[1,3,5])\n",
        "        print(\"\\nKNN test done!\")\n",
        "else:\n",
        "    print(\"오류: 'img_digits' 변수가 정의되지 않았거나 이미지를 불러오지 못했습니다.\")\n",
        "    print(\"이전 셀(Agt5TXaZzHcg)을 먼저 실행하여 digits.png 이미지를 로드해주세요.\")"
      ],
      "metadata": {
        "id": "42v3bzL20cEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
