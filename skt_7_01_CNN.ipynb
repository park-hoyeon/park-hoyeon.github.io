{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNE0Q0cj/2I/ahWXCYtuaOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park-hoyeon/park-hoyeon.github.io/blob/master/skt_7_01_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hA3mKFbhN1hF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이미지 확인\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover',\n",
        "               'Dress', 'Coat', 'Sandal',\n",
        "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "samples = np.random.randint(len(X_train), size=9)\n",
        "plt.figure(figsize = (8, 6))\n",
        "for i, idx in enumerate(samples):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X_train[idx], cmap = 'gray')\n",
        "  plt.title(class_names[y_train[idx]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8X0owUSjVFF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증용 데이터를 훈련용 데이터에서 분리한다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train, y_train, test_size = 0.3, random_state = 42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)"
      ],
      "metadata": {
        "id": "0-HTPy7qVTkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 데이터의 정규화\n",
        "import numpy as np\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_val = X_val.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "print(np.max(X_train), np.min(X_train))"
      ],
      "metadata": {
        "id": "1Ks3fX1fVan9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 Shape 확인\n",
        "print('X_train : ', X_train.shape)\n",
        "print('X_val : ', X_val.shape)\n",
        "print('X_test : ', X_test.shape)"
      ],
      "metadata": {
        "id": "BGRu3FWoWJGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 채널 축 추가\n",
        "import tensorflow as tf\n",
        "X_train = X_train[..., tf.newaxis]\n",
        "X_val = X_val[..., tf.newaxis]\n",
        "X_test = X_test[..., tf.newaxis]\n",
        "print('X_train : ', X_train.shape)\n",
        "print('X_val : ', X_val.shape)\n",
        "print('X_test : ', X_test.shape)"
      ],
      "metadata": {
        "id": "cy2z_EGzWhbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 만들기\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "def build_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Conv2D(filters=16, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu',\n",
        "        input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2)) #rgb이미지는 3차원이니까 2D로 안됨.\n",
        "  model.add(layers.Conv2D(filters=32, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation = 'relu'))\n",
        "  model.add(layers.Dense(10, activation = 'softmax'))\n",
        "  return model\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "XcXH5x4gWwWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 컴파일 - 다중 분류 모델의 학습은 손실함수로 'categorical_crossentropy'를 사용한다.\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=adam,\n",
        "       loss = 'categorical_crossentropy',\n",
        "       metrics=['acc'])\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "# Make sure to run the cell with one-hot encoding for y_train_oh and y_val_oh before this cell.\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "           epochs = EPOCHS,\n",
        "           batch_size = BATCH_SIZE,\n",
        "           validation_data = (X_val, y_val_oh),\n",
        "           verbose = 1)"
      ],
      "metadata": {
        "id": "x3pUHYI_XmUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a513f0fd"
      },
      "source": [
        "# 타겟 데이터의 원-핫 인코딩\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_val_oh = to_categorical(y_val)\n",
        "y_test_oh = to_categorical(y_test)\n",
        "\n",
        "print('y_train_oh : ', y_train_oh.shape)\n",
        "print('y_val_oh : ', y_val_oh.shape)\n",
        "print('y_test_oh : ', y_test_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "def plot_history(history):\n",
        " hist = pd.DataFrame(history.history)\n",
        " hist['epoch'] = history.epoch\n",
        " plt.figure(figsize=(16,8))\n",
        " plt.subplot(1,2,1)\n",
        " plt.xlabel('Epoch')\n",
        " plt.ylabel('Loss')\n",
        " plt.plot(hist['epoch'], hist['loss'], label='Train Loss')\n",
        " plt.plot(hist['epoch'], hist['val_loss'],label = 'Val Loss')\n",
        " plt.legend()\n",
        " plt.subplot(1,2,2)\n",
        " plt.xlabel('Epoch')\n",
        " plt.ylabel('Accuracy')\n",
        " plt.plot(hist['epoch'], hist['acc'], label='Train Accuracy')\n",
        " plt.plot(hist['epoch'], hist['val_acc'], label = 'Val Accuracy')\n",
        " plt.legend()\n",
        " plt.show() # Add plt.show() here\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "q3ob1a_nbJxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "왼쪽 그래프는 좋지 않은 결과."
      ],
      "metadata": {
        "id": "QoqxjMWFn0dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 드롭아웃(Dropout)"
      ],
      "metadata": {
        "id": "SgYHHDC-iJgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃 레리어를 추가한 모델 구성\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "def build_dropout_model():\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(filters=16, kernel_size= 3,\n",
        "         strides=(1, 1), padding='same', activation='relu',\n",
        "         input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(filters=32, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation = 'relu'))\n",
        "  model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "  return model\n",
        "model = build_dropout_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "KQ61MEfEkxPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "viSlhMozn42k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_argmax = np.argmax(y_pred, axis=1)\n",
        "y_pred_argmax[:10]\n"
      ],
      "metadata": {
        "id": "J0m23LyyoBe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 지표 계산\n",
        "from sklearn.metrics import accuracy_score, precision_score,\n",
        "recall_score, f1_score\n",
        "def print_score(y_test, y_pred):\n",
        " print('accuracy: %.3f' % (accuracy_score(y_test, y_pred)))\n",
        " print('precision: %.3f' % (precision_score(y_test, y_pred, average='macro')))\n",
        " print('recall_score: %.3f' % (recall_score(y_test, y_pred, average='macro')))\n",
        " print('f1_score: %.3f' % (f1_score(y_test, y_pred, average='macro')))"
      ],
      "metadata": {
        "id": "e7FZ7xXCoK6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1812da01"
      },
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0fca850"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 이미지 확인\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover',\n",
        "               'Dress', 'Coat', 'Sandal',\n",
        "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "samples = np.random.randint(len(X_train), size=9)\n",
        "plt.figure(figsize = (8, 6))\n",
        "for i, idx in enumerate(samples):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.imshow(X_train[idx], cmap = 'gray')\n",
        "  plt.title(class_names[y_train[idx]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ce84123"
      },
      "source": [
        "# 검증용 데이터를 훈련용 데이터에서 분리한다.\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train, y_train, test_size = 0.3, random_state = 42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9f33a45"
      },
      "source": [
        "# 이미지 데이터의 정규화\n",
        "import numpy as np\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "X_val = X_val.astype('float32') / 255.\n",
        "X_test = X_test.astype('float32') / 255.\n",
        "print(np.max(X_train), np.min(X_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94262879"
      },
      "source": [
        "# 채널 축 추가\n",
        "import tensorflow as tf\n",
        "X_train = X_train[..., tf.newaxis]\n",
        "X_val = X_val[..., tf.newaxis]\n",
        "X_test = X_test[..., tf.newaxis]\n",
        "print('X_train : ', X_train.shape)\n",
        "print('X_val : ', X_val.shape)\n",
        "print('X_test : ', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5f98349"
      },
      "source": [
        "# 타겟 데이터의 원-핫 인코딩\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_val_oh = to_categorical(y_val)\n",
        "y_test_oh = to_categorical(y_test)\n",
        "\n",
        "print('y_train_oh : ', y_train_oh.shape)\n",
        "print('y_val_oh : ', y_val_oh.shape)\n",
        "print('y_test_oh : ', y_test_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 드롭아웃 레리어를 추가한 모델 구성\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "def build_dropout_model():\n",
        "  model = keras.Sequential()\n",
        "\n",
        "  model.add(layers.Conv2D(filters=16, kernel_size= 3,\n",
        "         strides=(1, 1), padding='same', activation='relu',\n",
        "         input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(filters=32, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Conv2D(filters=64, kernel_size= 3,\n",
        "        strides=(1, 1), padding='same', activation='relu'))\n",
        "  model.add(layers.MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation = 'relu'))\n",
        "  model.add(layers.Dense(10, activation = 'softmax'))\n",
        "\n",
        "  return model\n",
        "model = build_dropout_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IRrZ-TRe1oAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컴파일 및 학습\n",
        "# Make sure to run cell KQ61MEfEkxPk to build the model before running this cell.\n",
        "model.compile(optimizer='adam',\n",
        "        loss = 'categorical_crossentropy',\n",
        "        metrics=['acc'])\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "           epochs = EPOCHS,\n",
        "           batch_size = BATCH_SIZE,\n",
        "           validation_data = (X_val, y_val_oh),\n",
        "           verbose = 1)"
      ],
      "metadata": {
        "id": "RCCiWryZ1pF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "I6XYPuiS2Qhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de545b7f"
      },
      "source": [
        "# 학습 곡선\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "def plot_history(history):\n",
        " hist = pd.DataFrame(history.history)\n",
        " hist['epoch'] = history.epoch\n",
        " plt.figure(figsize=(16,8))\n",
        " plt.subplot(1,2,1)\n",
        " plt.xlabel('Epoch')\n",
        " plt.ylabel('Loss')\n",
        " plt.plot(hist['epoch'], hist['loss'], label='Train Loss')\n",
        " plt.plot(hist['epoch'], hist['val_loss'],label = 'Val Loss')\n",
        " plt.legend()\n",
        " plt.subplot(1,2,2)\n",
        " plt.xlabel('Epoch')\n",
        " plt.ylabel('Accuracy')\n",
        " plt.plot(hist['epoch'], hist['acc'], label='Train Accuracy')\n",
        " plt.plot(hist['epoch'], hist['val_acc'], label = 'Val Accuracy')\n",
        " plt.legend()\n",
        " plt.show() # Add plt.show() here\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_argmax = np.argmax(y_pred, axis=1)\n",
        "y_pred_argmax[:10]"
      ],
      "metadata": {
        "id": "JmwzGC-p2fn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가지표계산\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def print_score(y_test, y_pred):\n",
        " print('accuracy: %.3f' % (accuracy_score(y_test, y_pred)))\n",
        " print('precision: %.3f' % (precision_score(y_test, y_pred,\n",
        "average='macro')))\n",
        " print('recall_score: %.3f' % (recall_score(y_test, y_pred,\n",
        "average='macro')))\n",
        " print('f1_score: %.3f' % (f1_score(y_test, y_pred,\n",
        "average='macro')))\n",
        "\n",
        "print_score(y_test, y_pred_argmax)"
      ],
      "metadata": {
        "id": "FHweudMb2mYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 컬러 이미지의 분류\n",
        "\n"
      ],
      "metadata": {
        "id": "BaWddLyU53fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "FSYYW3od58IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 표시\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "samples = np.random.randint(len(X_train), size=10)\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i, idx in enumerate(samples):\n",
        "  plt.subplot(2, 5, i+1, xticks=[], yticks=[])\n",
        "  plt.title((class_names[y_train[idx][0]]))\n",
        "  plt.imshow(X_train[idx])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vuiiw6LY5-Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화 처리 -    최소-최대\t정규화\t처리\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "fFWxtxJi6WYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증용 데이터 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "           X_train, y_train, test_size = 0.3,  random_state = 42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "nHcyFGT36dNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 데이터 shape 변경 - 레이블 데이터를 2차원에서 1차원으로 변경\n",
        "y_train = y_train.reshape(-1)\n",
        "y_val = y_val.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "tfAFwZMU6qhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원-핫 인코딩\n",
        "import tensorflow as tf\n",
        "y_train_oh = tf.one_hot(y_train, depth=10)\n",
        "y_val_oh = tf.one_hot(y_val, depth=10)\n",
        "y_test_oh = tf.one_hot(y_test, depth=10)\n",
        "print(y_train_oh.shape)\n",
        "y_train_oh[:5]"
      ],
      "metadata": {
        "id": "OcZpBISz6z-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#넘파이 배열로 변환\n",
        "y_train_oh = y_train_oh.numpy()\n",
        "y_val_oh = y_val_oh.numpy()\n",
        "y_test_oh = y_test_oh.numpy()\n",
        "print(y_train_oh.shape)\n",
        "print(y_val_oh.shape)\n",
        "print(y_test_oh.shape)"
      ],
      "metadata": {
        "id": "h2lEyxw2647G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 만들기\n",
        "from tensorflow.keras import layers\n",
        "def build_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Conv2D(32, 3, padding = 'same',\n",
        "        activation='relu', input_shape = (32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(64, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(256, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(256, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HIPOW-Bg69BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam,\n",
        "         loss = 'categorical_crossentropy',\n",
        "        metrics=['acc'])\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "          epochs = EPOCHS,\n",
        "          batch_size = BATCH_SIZE,\n",
        "          validation_data = (X_val, y_val_oh))"
      ],
      "metadata": {
        "id": "JayjkH1o7EpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 곡선\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "PUC2zh367JRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#예측\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_argmax = np.argmax(y_pred, axis=1)"
      ],
      "metadata": {
        "id": "HI_VQ39p7cNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 혼동행렬 시각화\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "def plot_matrix(y_test, y_pred):\n",
        "  plt.figure(figsize = (10, 8))\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  sns.heatmap(cm, annot = True, fmt = 'd',cmap = 'Blues')\n",
        "  plt.xlabel('predicted label', fontsize = 15)\n",
        "  plt.ylabel('true label', fontsize = 15)\n",
        "  plt.show()\n",
        "\n",
        "plot_matrix(y_test, y_pred_argmax)"
      ],
      "metadata": {
        "id": "abMi1sBr7fYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 콜백함수 적용"
      ],
      "metadata": {
        "id": "VC02Ix0tnz7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf # Import tensorflow as tf\n",
        "from tensorflow import keras # Import keras\n",
        "\n",
        "model = build_model()\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam,\n",
        "         loss = 'categorical_crossentropy',\n",
        "         metrics=['acc'])"
      ],
      "metadata": {
        "id": "KY1Kobaunyjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import callbacks\n",
        "checkpoint_path = 'temp/cifar_10.weights.h5'\n",
        "checkpoint = callbacks.ModelCheckpoint(checkpoint_path,\n",
        "               save_weights_only=True,\n",
        "               save_best_only=True,\n",
        "               monitor='val_loss')"
      ],
      "metadata": {
        "id": "CspdJ9FLn5WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "           epochs = EPOCHS,\n",
        "           batch_size = BATCH_SIZE,\n",
        "           validation_data = (X_val, y_val_oh),\n",
        "           callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "VU5e8ouLoxrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 위의 오류 해결법\n"
      ],
      "metadata": {
        "id": "WnxIoG_jpKue"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76adecb3"
      },
      "source": [
        "# Load CIFAR-10 dataset\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b90fb290"
      },
      "source": [
        "# Normalize image data\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e822e874"
      },
      "source": [
        "# Split validation data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "           X_train, y_train, test_size = 0.3,  random_state = 42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5f4a14e"
      },
      "source": [
        "# Reshape labels\n",
        "y_train = y_train.reshape(-1)\n",
        "y_val = y_val.reshape(-1)\n",
        "y_test = y_test.reshape(-1)\n",
        "print(y_train.shape)\n",
        "print(y_val.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5bc6887"
      },
      "source": [
        "# One-hot encode labels\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_val_oh = to_categorical(y_val)\n",
        "y_test_oh = to_categorical(y_test)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "y_train_oh[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "514bdd4c"
      },
      "source": [
        "# Build the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential()\n",
        "  model.add(layers.Conv2D(32, 3, padding = 'same',\n",
        "        activation='relu', input_shape = (32, 32, 3)))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(64, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(256, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Conv2D(256, 3, padding = 'same',\n",
        "        activation='relu'))\n",
        "  model.add(layers.MaxPooling2D(2))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(256, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "215ad210"
      },
      "source": [
        "# Define ModelCheckpoint callback\n",
        "from tensorflow.keras import callbacks\n",
        "checkpoint_path = 'temp/cifar_10.weights.h5'\n",
        "checkpoint = callbacks.ModelCheckpoint(checkpoint_path,\n",
        "               save_weights_only=True,\n",
        "               save_best_only=True,\n",
        "               monitor='val_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e19a3c73"
      },
      "source": [
        "# Compile and train the model\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam,\n",
        "         loss = 'categorical_crossentropy',\n",
        "        metrics=['acc'])\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "          epochs = EPOCHS,\n",
        "          batch_size = BATCH_SIZE,\n",
        "          validation_data = (X_val, y_val_oh),\n",
        "          callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상태 복원 - 파일로 저장되어 있는 최사으이 상태(가중치)를 모델에 복원한다.\n",
        "model.load_weights(checkpoint_path)\n"
      ],
      "metadata": {
        "id": "-IQ9QoaHqobo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 배치 정규화\n",
        "- 과대\t적합을\t방지하는\t효과"
      ],
      "metadata": {
        "id": "KWFO5gnQroYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 구성\n",
        "def build_model_bach_normalization():\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(layers.Conv2D(32, 3, padding = 'same', input_shape =\n",
        "(32, 32, 3)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "    model.add(layers.Conv2D(64, 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "    model.add(layers.Conv2D(256, 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(2))\n",
        "\n",
        "    model.add(layers.Conv2D(256, 3, padding = 'same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "z01NyKeQrsbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model_bach_normalization()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "F-sEsOxNr56v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=adam,\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "1TZZFzJMr9-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "history = model.fit(X_train, y_train_oh,\n",
        "                    epochs = EPOCHS,\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    validation_data = (X_val, y_val_oh))"
      ],
      "metadata": {
        "id": "YUFnaRTKsCIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "loss, acc = model.evaluate(X_test, y_test_oh)\n",
        "print('loss : ', loss)\n",
        "print('acc : ', acc)"
      ],
      "metadata": {
        "id": "DT8XzHSosPbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 증강\n",
        "- 기존의 데이터를 변형해서 데이터의 양을 늘리는 것\n"
      ],
      "metadata": {
        "id": "gdsS6jSqstPO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ROplzPRMsxYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전이학습 (Transfer Learning)\n",
        "- 대용량의\t데이터\t세트에서\t학습\t완료된\t모델(VGG16,\tResnet50\t등)을\t이용해서\t우리가\t해결하려\n",
        "는\t문제에\t적용하기\t위해\t미세\t조정(fine\ttuning)하는\t것"
      ],
      "metadata": {
        "id": "gBNpBeV1uiQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "CGpNuZSlurGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 완료된 모델 준비\n",
        "from tensorflow.keras.applications import VGG16\n",
        "vgg16 = VGG16(weights = 'imagenet',\n",
        "             input_shape = (32, 32, 3),\n",
        "             include_top = False)\n",
        "vgg16.trainable=False"
      ],
      "metadata": {
        "id": "JXF4vTb7uuQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 부분의 모델 구성\n",
        "model = keras.Sequential()\n",
        "model.add(vgg16)\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(10, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "8TFrb8mxu04s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 부분의 모델 구성\n",
        "model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
        "       loss = 'categorical_crossentropy',\n",
        "       metrics = ['acc'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "vJ3HMgOWu6St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 콜백 생성\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lrr = ReduceLROnPlateau(monitor='val_acc',\n",
        "             patience=3,\n",
        "             verbose=1,\n",
        "             factor=0.8,\n",
        "             min_lr=0.0001)"
      ],
      "metadata": {
        "id": "ft5IkBqRu_ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 바운딩 박스 근사\n"
      ],
      "metadata": {
        "id": "bco4eOWpwKoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 바운딩 박스 정보 추출\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd # Import pandas\n",
        "\n",
        "def xml_to_csv(path):\n",
        "  xml_list = []\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      bbx = member.find('bndbox')\n",
        "      xmin = int(bbx.find('xmin').text)\n",
        "      ymin = int(bbx.find('ymin').text)\n",
        "      xmax = int(bbx.find('xmax').text)\n",
        "      ymax = int(bbx.find('ymax').text)\n",
        "      label = member.find('name').text\n",
        "      value = (root.find('filename').text,\n",
        "            int(root.find('size')[0].text),\n",
        "            int(root.find('size')[1].text),\n",
        "            label, xmin, ymin, xmax, ymax)\n",
        "      xml_list.append(value)\n",
        "\n",
        "  column_name = ['filename', 'width', 'height',\n",
        "           'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "  return xml_df"
      ],
      "metadata": {
        "id": "FJwAN446vIGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define IMAGE_PATH - **Replace '/content/your_image_directory' with the actual path to your XML files**\n",
        "IMAGE_PATH = '/content/your_image_directory'\n",
        "\n",
        "xml_df = xml_to_csv(IMAGE_PATH)\n",
        "csv_path = os.path.join(IMAGE_PATH, 'labels_cats.csv')\n",
        "xml_df.to_csv(csv_path, index=None)\n",
        "print('csv path:', csv_path)"
      ],
      "metadata": {
        "id": "5gw_Uk6kwTmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 원래 파일명\n",
        "original_path = \"/content/(20')CCTV학습데이터셋(35,200장).egg\"\n",
        "\n",
        "# 새 이름으로 변경\n",
        "new_path = \"/content/cctv_dataset.egg\"\n",
        "os.rename(original_path, new_path)\n"
      ],
      "metadata": {
        "id": "CXsnt3QqweDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 우선 unzip 시도\n",
        "!unzip -q /content/cctv_dataset.egg -d /content/cctv_data\n"
      ],
      "metadata": {
        "id": "mDI4q8dGyYDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 압축 해제된 폴더 구조 확인\n",
        "for root, dirs, files in os.walk(\"/content/cctv_data\"):\n",
        "    print(f\"📁 {root}\")\n",
        "    for f in files[:10]:  # 처음 10개만 보기\n",
        "        print(\"  └─\", f)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "ZtwpiDPIyZHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}